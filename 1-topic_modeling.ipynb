{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1256c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### static variables\n",
    "\n",
    "COLUMNS_DOCS = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TEXTUAL = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_names\",\n",
    "    \"court_names\",\n",
    "    \"hospital_patient_names\",\n",
    "    \"original_doc_ids\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd890fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_documents() -> pd.DataFrame:\n",
    "    docs_original = pd.read_csv(\"data/DRAGONball/en/docs.csv\", usecols=[\"doc_id\", \"domain\", \"content\"])\n",
    "    docs_manipulated_single_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/textual_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    docs_manipulated_single_tabular = pd.read_csv(\n",
    "        \"data/additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_ids\"],\n",
    "        converters={\"original_doc_ids\": ast.literal_eval},\n",
    "    )\n",
    "    docs_manipulated_multi_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/multi_textual_manipulations.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    print(f\"# original docs: {len(docs_original)}\")\n",
    "    print(f\"# manipulated textual docs: {len(docs_manipulated_single_textual)}\")\n",
    "    print(f\"# manipulated tabular docs: {len(docs_manipulated_single_tabular)}\")\n",
    "    print(f\"# manipulated textual multi docs: {len(docs_manipulated_multi_textual)}\")\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            docs_original,\n",
    "            docs_manipulated_single_textual,\n",
    "            docs_manipulated_multi_textual,\n",
    "            docs_manipulated_single_tabular,\n",
    "        ],\n",
    "        sort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa26b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original docs: 108\n",
      "# manipulated textual docs: 30\n",
      "# manipulated tabular docs: 3\n",
      "# manipulated textual multi docs: 30\n",
      "Size of vocabulary: 7581\n"
     ]
    }
   ],
   "source": [
    "docs_df = get_documents()\n",
    "docs_list = docs_df[\"content\"].to_list()\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, stop_words=\"english\")\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(docs_list)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"Size of vocabulary: {len(tfidf_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd35bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NMF (perfect condictions)\n",
    "# nmf = NMF(n_components=108, init=\"nndsvda\", max_iter=400)\n",
    "# nmf = nmf.fit(tfidf_features[:108])\n",
    "# nmf_data = nmf.transform(tfidf_features)\n",
    "# nmf_data_normalised = normalize(nmf_data, norm=\"l1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc2286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NMF (only no. of topics known)\n",
    "nmf = NMF(n_components=108, init=\"nndsvda\", max_iter=400)\n",
    "nmf_data = nmf.fit_transform(tfidf_features)\n",
    "nmf_data_normalised = normalize(nmf_data, norm=\"l1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c35c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSA\n",
    "# lsa = TruncatedSVD(n_components=108)\n",
    "# lsa_data = lsa.fit_transform(tfidf_features)\n",
    "# lsa_data_normalised = normalize(lsa_data, norm=\"l2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6592352",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA\n",
    "# lda = LatentDirichletAllocation(n_components=108)\n",
    "# lda_data_normalised = lda.fit_transform(tfidf_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2553110",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (1/2)\n",
    "def merge_original_ids(row):\n",
    "    if isinstance(row[\"original_doc_ids_tmp\"], list):\n",
    "        return row[\"original_doc_ids_tmp\"]\n",
    "    elif pd.notna(row[\"original_doc_id_tmp\"]):\n",
    "        return [row[\"original_doc_id_tmp\"]]\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "def calc_topics(row):\n",
    "    if isinstance(row[\"original_doc_ids\"], list):\n",
    "        if len(row[\"original_doc_ids\"]) > 1:\n",
    "            return np.argsort(row[\"doc_vector\"])[-10:][::-1].tolist()\n",
    "    return [np.argmax(row[\"doc_vector\"])]\n",
    "\n",
    "\n",
    "def calc_topics_for_cumulative_threshold(row, threshold=0.9):\n",
    "    sorted_indices = np.argsort(row)[::-1]\n",
    "\n",
    "    # Sort the probabilities accordingly\n",
    "    sorted_probs = row[sorted_indices]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative = np.cumsum(sorted_probs)\n",
    "\n",
    "    # Find the cutoff index where cumulative sum first exceeds threshold\n",
    "    cutoff = np.searchsorted(cumulative, threshold)\n",
    "\n",
    "    # Select the indices up to and including that point\n",
    "    selected_indices = sorted_indices[: cutoff + 1]\n",
    "\n",
    "    return selected_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280b51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (2/2)\n",
    "def calc_topic_hitrate(row):\n",
    "    if not isinstance(row[\"original_doc_ids\"], list):\n",
    "        return None\n",
    "\n",
    "    original_doc_ids: List[int] = row[\"original_doc_ids\"]\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for id in original_doc_ids:\n",
    "        topics_row = set(row[\"topics\"])\n",
    "        original_row = docs.loc[docs[\"doc_id\"].astype(int) == int(id)].iloc[0]\n",
    "        topics_original = set(original_row[\"topics\"])\n",
    "        res.append(len(topics_row.intersection(topics_original)) > 0)\n",
    "\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b4cd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 56.67 %\n",
      "Recall on non-tabular docs: 85.0 %\n",
      "Average comparisons to make: 13.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_vector</th>\n",
       "      <th>original_doc_ids</th>\n",
       "      <th>topics</th>\n",
       "      <th>topics_hitrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>100134</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100136</td>\n",
       "      <td>[0.0, 0.0020720391791662052, 0.004018328717750...</td>\n",
       "      <td>[136]</td>\n",
       "      <td>[5, 11, 104, 94, 98, 9, 30, 78, 89]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>100139</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[139]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100046</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.170...</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>100047</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>400110</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>[110]</td>\n",
       "      <td>[45, 105, 54, 103]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>400116</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[116]</td>\n",
       "      <td>[70, 36, 105, 54]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>300001</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.004799967831828898, 0.0...</td>\n",
       "      <td>[46, 47, 52, 59, 66, 71, 72, 77, 78, 79]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>300002</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[134, 136, 139, 112, 114, 115, 119, 123, 125, ...</td>\n",
       "      <td>[37]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>300003</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[179, 181, 198, 199, 208, 209, 207, 205, 212, ...</td>\n",
       "      <td>[39]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                         doc_vector  \\\n",
       "108  100134  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "109  100136  [0.0, 0.0020720391791662052, 0.004018328717750...   \n",
       "110  100139  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "111  100046  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.170...   \n",
       "112  100047  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..      ...                                                ...   \n",
       "166  400110  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "167  400116  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "168  300001  [0.0, 0.0, 0.0, 0.0, 0.004799967831828898, 0.0...   \n",
       "169  300002  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "170  300003  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      original_doc_ids  \\\n",
       "108                                              [134]   \n",
       "109                                              [136]   \n",
       "110                                              [139]   \n",
       "111                                               [46]   \n",
       "112                                               [47]   \n",
       "..                                                 ...   \n",
       "166                                              [110]   \n",
       "167                                              [116]   \n",
       "168           [46, 47, 52, 59, 66, 71, 72, 77, 78, 79]   \n",
       "169  [134, 136, 139, 112, 114, 115, 119, 123, 125, ...   \n",
       "170  [179, 181, 198, 199, 208, 209, 207, 205, 212, ...   \n",
       "\n",
       "                                  topics  topics_hitrate  \n",
       "108                                  [9]             1.0  \n",
       "109  [5, 11, 104, 94, 98, 9, 30, 78, 89]             1.0  \n",
       "110                                 [11]             1.0  \n",
       "111                                 [23]             1.0  \n",
       "112                                 [10]             1.0  \n",
       "..                                   ...             ...  \n",
       "166                   [45, 105, 54, 103]             1.0  \n",
       "167                    [70, 36, 105, 54]             1.0  \n",
       "168                                 [26]             0.0  \n",
       "169                                 [37]             0.0  \n",
       "170                                 [39]             0.0  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### evaluate method\n",
    "import importlib\n",
    "from utils import evaluation\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "transformed_data = nmf_data_normalised\n",
    "\n",
    "docs = pd.DataFrame(\n",
    "    {\n",
    "        \"doc_id\": docs_df[\"doc_id\"].to_list(),\n",
    "        \"original_doc_id_tmp\": docs_df[\"original_doc_id\"].to_list(),\n",
    "        \"original_doc_ids_tmp\": docs_df[\"original_doc_ids\"].to_list(),\n",
    "        \"doc_vector\": list([doc for doc in transformed_data]),\n",
    "    }\n",
    ")\n",
    "\n",
    "docs[\"original_doc_ids\"] = docs.apply(merge_original_ids, axis=1)\n",
    "docs = docs.drop([\"original_doc_id_tmp\", \"original_doc_ids_tmp\"], axis=1)\n",
    "docs[\"topics\"] = docs[\"doc_vector\"].apply(calc_topics_for_cumulative_threshold, args=(0.95,))\n",
    "\n",
    "# docs[\"len(topics)\"] = docs[\"topics\"].apply(len)\n",
    "# docs[\"topic_hitrate\"] = docs.apply(calc_topic_hitrate, axis=1)\n",
    "# docs[\"num_non-zeros_in_vector\"] = docs[\"doc_vector\"].apply(lambda v: sum(i > 0 for i in v))\n",
    "\n",
    "# print(f\"Avg. number of topics: {round(docs[\"len(topics)\"].mean(), 2)}\")\n",
    "# docs[\"doc_vector\"] = docs[\"doc_vector\"].apply(lambda v: np.sort(v)[::-1]).apply(lambda v: [round(i, 4) for i in v])\n",
    "\n",
    "\n",
    "docs, recall = evaluation.evaluate_clusters(docs, \"topics\")\n",
    "filtered_docs = docs.loc[docs[\"original_doc_ids\"].notna()]\n",
    "print(f\"Recall: {round(recall * 100, 2)} %\")\n",
    "print(f\"Recall on non-tabular docs: {round(filtered_docs[\"topics_hitrate\"][:-3].mean() * 100, 2)} %\")\n",
    "print(f\"Average comparisons to make: {evaluation.count_avg_related_docs(docs, \"topics\"):.2f}\")\n",
    "filtered_docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
