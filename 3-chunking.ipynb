{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fc88c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import lancedb\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")\n",
    "\n",
    "# DB specifications\n",
    "LANCEDB_DIR = \"/Users/leon/Documents/study/MA/lancedb\"\n",
    "TABLE_NAME_DOCS = \"documents\"\n",
    "TABLE_NAME_CHUNKS = \"chunks\"\n",
    "\n",
    "db = lancedb.connect(LANCEDB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d334564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import io_helpers\n",
    "\n",
    "reload(io_helpers)\n",
    "\n",
    "\n",
    "def add_fictional_creation_date(row):\n",
    "    if str(row[\"doc_id\"]).startswith(\"400\"):\n",
    "        return pd.to_datetime(\"2010-01-01\")\n",
    "    if str(row[\"doc_id\"]).startswith(\"300\"):\n",
    "        return pd.to_datetime(\"2015-01-01\")\n",
    "    if str(row[\"doc_id\"]).startswith(\"100\"):\n",
    "        return pd.to_datetime(\"2005-01-01\")\n",
    "    return pd.to_datetime(\"2000-01-01\")\n",
    "\n",
    "\n",
    "def get_documents_with_creation_date() -> pd.DataFrame:\n",
    "    documents = io_helpers.get_documents(read_embeddings=True).drop(columns=\"original_doc_ids\")\n",
    "    documents[\"creation_date\"] = documents.apply(add_fictional_creation_date, axis=1)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a90a7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-06-10T21:55:37Z \u001b[33mWARN \u001b[0m lance::dataset::scanner\u001b[90m]\u001b[0m nprobes is not set because nearest has not been called yet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>creation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Acme Government Solutions is a government indu...</td>\n",
       "      <td>[0.035415836, 0.015197343, 0.08163272, 0.02999...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Entertainment Enterprises Inc. is an entertain...</td>\n",
       "      <td>[0.050379667, -0.0005295727, 0.04373168, 0.038...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Advanced Manufacturing Solutions Inc., establi...</td>\n",
       "      <td>[0.023992022, 0.011302027, 0.050733544, 0.0336...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>Finance</td>\n",
       "      <td>EcoGuard Solutions, established on April 15, 2...</td>\n",
       "      <td>[0.0594782, 0.01698723, 0.061538648, 0.0547162...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Green Fields Agriculture Ltd., established on ...</td>\n",
       "      <td>[0.017018009, 0.014309261, 0.082911275, 0.0502...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>400116</td>\n",
       "      <td>Law</td>\n",
       "      <td>In a significant legal proceeding at the Cedar...</td>\n",
       "      <td>[0.028841885, -0.034240857, 0.044584155, 0.031...</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>400059</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Retail Emporium, a well-established retail gia...</td>\n",
       "      <td>[0.03652241, 0.02207698, 0.021544848, 0.039533...</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>300001</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Changes that occurred in senior management of ...</td>\n",
       "      <td>[-0.004240031, -0.007925675, 0.018725948, 0.03...</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>300002</td>\n",
       "      <td>Law</td>\n",
       "      <td>Chief judge according to the court judgment of...</td>\n",
       "      <td>[-0.0014971758, 0.015988875, 0.023612805, 0.02...</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>300003</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Past disease history of Y. Evans according to ...</td>\n",
       "      <td>[-0.003927286, -0.017222933, 0.008311565, 0.01...</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id   domain                                            content  \\\n",
       "0        40  Finance  Acme Government Solutions is a government indu...   \n",
       "1        41  Finance  Entertainment Enterprises Inc. is an entertain...   \n",
       "2        42  Finance  Advanced Manufacturing Solutions Inc., establi...   \n",
       "3        43  Finance  EcoGuard Solutions, established on April 15, 2...   \n",
       "4        44  Finance  Green Fields Agriculture Ltd., established on ...   \n",
       "..      ...      ...                                                ...   \n",
       "166  400116      Law  In a significant legal proceeding at the Cedar...   \n",
       "167  400059  Finance  Retail Emporium, a well-established retail gia...   \n",
       "168  300001  Finance  Changes that occurred in senior management of ...   \n",
       "169  300002      Law  Chief judge according to the court judgment of...   \n",
       "170  300003  Medical  Past disease history of Y. Evans according to ...   \n",
       "\n",
       "                                             embedding creation_date  \n",
       "0    [0.035415836, 0.015197343, 0.08163272, 0.02999...    2000-01-01  \n",
       "1    [0.050379667, -0.0005295727, 0.04373168, 0.038...    2000-01-01  \n",
       "2    [0.023992022, 0.011302027, 0.050733544, 0.0336...    2000-01-01  \n",
       "3    [0.0594782, 0.01698723, 0.061538648, 0.0547162...    2000-01-01  \n",
       "4    [0.017018009, 0.014309261, 0.082911275, 0.0502...    2000-01-01  \n",
       "..                                                 ...           ...  \n",
       "166  [0.028841885, -0.034240857, 0.044584155, 0.031...    2010-01-01  \n",
       "167  [0.03652241, 0.02207698, 0.021544848, 0.039533...    2010-01-01  \n",
       "168  [-0.004240031, -0.007925675, 0.018725948, 0.03...    2015-01-01  \n",
       "169  [-0.0014971758, 0.015988875, 0.023612805, 0.02...    2015-01-01  \n",
       "170  [-0.003927286, -0.017222933, 0.008311565, 0.01...    2015-01-01  \n",
       "\n",
       "[171 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = get_documents_with_creation_date()\n",
    "\n",
    "table = db.create_table(TABLE_NAME_DOCS, data=documents, exist_ok=True)\n",
    "db[TABLE_NAME_DOCS].head(1)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0eaf72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-06-10T21:55:37Z \u001b[33mWARN \u001b[0m lance::dataset::scanner\u001b[90m]\u001b[0m nprobes is not set because nearest has not been called yet\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "table_data: pd.DataFrame = table.search().to_pandas()\n",
    "\n",
    "loader = DataFrameLoader(table_data, page_content_column=\"content\")\n",
    "lc_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60ed7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "lc_chunks = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], chunk_size=1024, chunk_overlap=128, strip_whitespace=True, keep_separator=False\n",
    ").split_documents(lc_documents)\n",
    "\n",
    "\n",
    "print(len(lc_chunks))\n",
    "for i in range(len(lc_chunks)):\n",
    "    lc_chunks[i].metadata[\"chunk_id\"] = i\n",
    "    lc_chunks[i].id = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "445b1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "import string\n",
    "\n",
    "\n",
    "def normalize_string(input: str) -> str:\n",
    "    translator = str.maketrans({p: \"\" for p in string.punctuation})\n",
    "    return input.lower().strip().translate(translator)\n",
    "\n",
    "\n",
    "def flag_outdated_chunk(data: pd.Series, chunks: List[Document]) -> List[Document]:\n",
    "    documents = get_documents_with_creation_date()\n",
    "    creation_date1 = documents[documents[\"doc_id\"] == data[\"id1\"]].squeeze()[\"creation_date\"]\n",
    "    creation_date2 = documents[documents[\"doc_id\"] == data[\"id2\"]].squeeze()[\"creation_date\"]\n",
    "\n",
    "    if creation_date1 < creation_date2:  # doc2 is newer\n",
    "        doc_id_old = data[\"id1\"]\n",
    "        doc_id_new = data[\"id2\"]\n",
    "        passage_old = data[\"conflicting_passage_doc1\"]\n",
    "        passage_new = data[\"conflicting_passage_doc2\"]\n",
    "    else:  # doc1 is newer\n",
    "        doc_id_old = data[\"id2\"]\n",
    "        doc_id_new = data[\"id1\"]\n",
    "        passage_old = data[\"conflicting_passage_doc2\"]\n",
    "        passage_new = data[\"conflicting_passage_doc1\"]\n",
    "\n",
    "    chunk_ids_old = []\n",
    "    chunk_ids_new = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if chunk.metadata[\"doc_id\"] not in [doc_id_old, doc_id_new]:\n",
    "            continue\n",
    "        if normalize_string(passage_old) in normalize_string(chunk.page_content):\n",
    "            chunk_ids_old.append(chunk.metadata[\"chunk_id\"])\n",
    "        elif normalize_string(passage_new) in normalize_string(chunk.page_content):\n",
    "            chunk_ids_new.append(chunk.metadata[\"chunk_id\"])\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if chunk.metadata[\"chunk_id\"] in chunk_ids_old:\n",
    "            chunk.metadata[\"outdated_by_chunk_ids\"] = chunk_ids_new\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "conflicts = pd.read_csv(\n",
    "    \"data/additional_data/docs/_conflicts.csv\",\n",
    "    usecols=[\"id1\", \"id2\", \"model\", \"conflicting_passage_doc1\", \"conflicting_passage_doc2\"],\n",
    "    dtype={\"id1\": \"Int64\", \"id2\": \"Int64\"},\n",
    ")\n",
    "\n",
    "for _, data in conflicts.iterrows():\n",
    "    lc_chunks = flag_outdated_chunk(data, lc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ff877e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import LanceDB\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from openai import RateLimitError\n",
    "from tenacity import retry, retry_if_exception_type, wait_random, stop_after_attempt\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "try:\n",
    "    vector_store = LanceDB(uri=LANCEDB_DIR, embedding=embeddings, table=db.open_table(TABLE_NAME_CHUNKS))\n",
    "except ValueError:\n",
    "    print(\"Table not existent\")\n",
    "    vector_store = LanceDB(uri=LANCEDB_DIR, embedding=embeddings, table_name=TABLE_NAME_CHUNKS)\n",
    "\n",
    "ids_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0418bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_id': 40, 'domain': 'Finance', 'embedding': array([ 0.03541584,  0.01519734,  0.08163272, ..., -0.01773023,\n",
      "        0.01715001, -0.00257613]), 'creation_date': Timestamp('2000-01-01 00:00:00'), 'chunk_id': 0, 'outdated_by_chunk_ids': [1652]}\n",
      "{'doc_id': 40, 'domain': 'Finance', 'embedding': array([ 0.03541584,  0.01519734,  0.08163272, ..., -0.01773023,\n",
      "        0.01715001, -0.00257613]), 'creation_date': Timestamp('2000-01-01 00:00:00'), 'chunk_id': 1}\n"
     ]
    }
   ],
   "source": [
    "print(lc_chunks[0].metadata)\n",
    "print(lc_chunks[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c8ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ID '0'\n",
      "Skipping ID '1'\n",
      "Skipping ID '2'\n"
     ]
    }
   ],
   "source": [
    "@retry(\n",
    "    retry=retry_if_exception_type(RateLimitError),\n",
    "    wait=wait_random(min=30, max=60),\n",
    "    stop=stop_after_attempt(6),\n",
    ")\n",
    "def add_chunk_to_vector_store(id, text, metadata):\n",
    "    if id in ids_processed:\n",
    "        print(f\"Skipping ID '{id}'\")\n",
    "    vector_store.add_texts([text], [metadata], [id])\n",
    "    ids_processed.append(id)\n",
    "\n",
    "\n",
    "for chunk in lc_chunks:\n",
    "    id = chunk.metadata[\"chunk_id\"]\n",
    "    text = chunk.page_content\n",
    "    metadata = chunk.metadata.copy()\n",
    "    if metadata.get(\"outdated_by_chunk_ids\", None) is None:\n",
    "        metadata[\"outdated_by_chunk_ids\"] = []\n",
    "    try:\n",
    "        del metadata[\"embedding\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        del metadata[\"chunk_id\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    # add_chunk_to_vector_store(id, text, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fdd7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[Document(metadata={'creation_date': datetime.datetime(2015, 1, 1, 0, 0), 'doc_id': 300003, 'domain': 'Medical', 'outdated_by_chunk_ids': []}, page_content='Chief complaint of J. Reyes according to the hospitalization records of Bridgewater General Hospital | Severe headaches and dizziness for 3 months.\\nAdmission time for X. Price according to the hospitalization records of Tremont City Hospital | 15th, February')]\n"
     ]
    }
   ],
   "source": [
    "result = vector_store.similarity_search(\"Medical\", k=5)\n",
    "\n",
    "print(len(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e490932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "                                              vector    id  \\\n",
      "0  [-0.016182736, -0.0001533637, 0.0136298835, 0....  1726   \n",
      "\n",
      "                                                text  \\\n",
      "0  Chief complaint of J. Reyes according to the h...   \n",
      "\n",
      "                                            metadata  \n",
      "0  {'creation_date': 2015-01-01 00:00:00, 'doc_id...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-06-10T22:28:05Z \u001b[33mWARN \u001b[0m lance::dataset::scanner\u001b[90m]\u001b[0m nprobes is not set because nearest has not been called yet\n"
     ]
    }
   ],
   "source": [
    "chunks_table = db[\"chunks\"].search().to_pandas()\n",
    "print(len(chunks_table))\n",
    "print(chunks_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad33d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lancedb.table.LanceTable'>\n"
     ]
    }
   ],
   "source": [
    "print(type(db[TABLE_NAME_CHUNKS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    wait_random_exponential,\n",
    "    retry_if_exception_type,\n",
    "    stop_after_attempt,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
