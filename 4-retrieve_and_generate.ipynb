{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import importlib\n",
    "from langchain.vectorstores import LanceDB\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# DB specifications\n",
    "LANCEDB_DIR = \"...\"  # Set database path\n",
    "TABLE_NAME_DOCS = \"documents\"\n",
    "TABLE_NAME_CHUNKS = \"chunks\"\n",
    "\n",
    "db = lancedb.connect(LANCEDB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b6f8e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = LanceDB(\n",
    "    uri=LANCEDB_DIR,\n",
    "    embedding=embeddings,\n",
    "    table=db.open_table(TABLE_NAME_CHUNKS),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "244b0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def retrieve_newer_chunks(retrieved_chunks) -> List:\n",
    "    while True:\n",
    "        outdated_by_ids = {\n",
    "            id_ for chunk in retrieved_chunks for id_ in chunk.metadata.get(\"outdated_by_chunk_ids\", [])\n",
    "        }\n",
    "        chunk_ids = {chunk.metadata[\"chunk_id\"] for chunk in retrieved_chunks}\n",
    "        outdated_by_ids -= chunk_ids\n",
    "\n",
    "        if len(outdated_by_ids) == 0:\n",
    "            break\n",
    "\n",
    "        table = db.open_table(TABLE_NAME_CHUNKS)\n",
    "        if len(outdated_by_ids) == 1:\n",
    "            table_data = table.search().where(f\"id == {next(iter(outdated_by_ids))}\").to_pandas()\n",
    "        else:\n",
    "            table_data = table.search().where(f\"id IN {tuple(outdated_by_ids)}\").to_pandas()\n",
    "\n",
    "        # Flatten metadata column into top-level columns\n",
    "        metadata_df = table_data[\"metadata\"].apply(pd.Series)\n",
    "\n",
    "        # Drop the original nested metadata column\n",
    "        table_data = table_data.drop(columns=[\"metadata\"])\n",
    "\n",
    "        # Merge the expanded metadata back\n",
    "        flattened_df = pd.concat([table_data, metadata_df], axis=1)\n",
    "        loader = DataFrameLoader(flattened_df, page_content_column=\"text\")\n",
    "        additional_chunks = loader.load()\n",
    "        retrieved_chunks.extend(additional_chunks)\n",
    "\n",
    "    return retrieved_chunks\n",
    "\n",
    "\n",
    "def filter_outdated_chunks(chunks: List) -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    - (chunks_current, chunks_outdated)\n",
    "    \"\"\"\n",
    "    chunks_outdated = []\n",
    "    chunks_current = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk.metadata[\"outdated_by_chunk_ids\"]) != 0:\n",
    "            chunks_outdated.append(chunk)\n",
    "        else:\n",
    "            chunks_current.append(chunk)\n",
    "    return (chunks_current, chunks_outdated)\n",
    "\n",
    "\n",
    "def sort_chunks(chunks: List) -> List:\n",
    "    chunks.sort(reverse=True, key=lambda c: c.metadata[\"creation_date\"])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "74c8deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k=5):\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=k)\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48748e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate retrieval\n",
    "from utils import io_helpers\n",
    "import pandas as pd\n",
    "from langchain_core.load import dumps, loads, load, serializable\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "\n",
    "queries_manipulated = io_helpers.get_queries(\"manipulated_only\")\n",
    "\n",
    "\n",
    "def retrieve_context(query_entry: pd.Series, top_k: int, with_dq: bool = True):\n",
    "    \"\"\"Retrieves context from lancedb and saves it to csv\"\"\"\n",
    "    filename = (\n",
    "        f\"evaluation/_queries_with_context_with_DQ_{top_k}.csv\"\n",
    "        if with_dq\n",
    "        else f\"evaluation/_queries_with_context_without_DQ_{top_k}.csv\"\n",
    "    )\n",
    "\n",
    "    chunks = retrieve(query_entry[\"query.content\"], k=top_k)\n",
    "    if with_dq:\n",
    "        chunks = retrieve_newer_chunks(chunks)\n",
    "        chunks = sort_chunks(chunks)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata.pop(\"creation_date\", None)\n",
    "        chunk.metadata.pop(\"vector\", None)\n",
    "        chunk.metadata[\"outdated_by_chunk_ids\"] = list(chunk.metadata[\"outdated_by_chunk_ids\"])  # np.array not allowed\n",
    "        chunk.metadata[\"outdated_by_chunk_ids\"] = [int(id) for id in chunk.metadata[\"outdated_by_chunk_ids\"]]\n",
    "\n",
    "    chunks_s = [dumps(chunk) for chunk in chunks]\n",
    "\n",
    "    query_entry[\"context\"] = chunks_s\n",
    "    try:\n",
    "        data = pd.read_csv(filename)\n",
    "        data = pd.concat([data, pd.DataFrame([query_entry])], sort=False)\n",
    "    except FileNotFoundError:\n",
    "        data = pd.DataFrame([query_entry])\n",
    "    data.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "_ = queries_manipulated.apply(retrieve_context, args=(5, False), axis=1)\n",
    "_ = queries_manipulated.apply(retrieve_context, args=(5, True), axis=1)\n",
    "\n",
    "# query = queries_manipulated.sample(n=100, random_state=1)\n",
    "# _ = query.apply(retrieve_context, args=(3, False), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(3, True), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(5, False), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(5, True), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(7, False), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(7, True), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(10, False), axis=1)\n",
    "# _ = query.apply(retrieve_context, args=(10, True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e52dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leon/miniconda3/envs/ma/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import importlib\n",
    "from utils import io_helpers, llm\n",
    "from langchain_core.load import loads\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "importlib.reload(llm)\n",
    "\n",
    "\n",
    "def generate(row, with_dq_assesment: bool = True, model: str = \"gpt-4.1\"):\n",
    "    question = row[\"query.content\"]\n",
    "\n",
    "    context_chunks = [loads(c) for c in row[\"context\"]]\n",
    "    context = \"\\n\\n-- new chunk --\\n\".join([c.page_content for c in context_chunks])\n",
    "\n",
    "    if with_dq_assesment:\n",
    "        system_prompt, user_prompt = io_helpers.get_prompts(\"qa/qa_with_dq\")\n",
    "    else:\n",
    "        system_prompt, user_prompt = io_helpers.get_prompts(\"qa/qa_without_dq\")\n",
    "\n",
    "    user_prompt = llm.format_user_prompt_qa(user_prompt, question=question, context=context)\n",
    "    response = llm.call_any_llm(system_prompt, user_prompt, model=model, response_format_pydantic=llm.LLMQAResponse)\n",
    "\n",
    "    return response.answer\n",
    "\n",
    "\n",
    "def produce_generations(queries_path: str):\n",
    "    queries = pd.read_csv(queries_path, converters={\"context\": ast.literal_eval})\n",
    "    queries[\"generated_response\"] = queries.apply(generate, axis=1)\n",
    "    queries.to_csv(f\"{queries_path.split(\".\")[0]}_generations.csv\", index=False)\n",
    "\n",
    "\n",
    "# produce_generations(\"evaluation/_queries_with_context_with_DQ_5.csv\")\n",
    "# produce_generations(\"evaluation/_queries_with_context_without_DQ_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c5a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth.keypoints</th>\n",
       "      <th>query.content</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>keypoint_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"JetWing Aviation's total liabilities amounte...</td>\n",
       "      <td>What was the total amount of JetWing Aviation'...</td>\n",
       "      <td>$250 million</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Mr. John Doe was appointed as CEO of ABC Edu...</td>\n",
       "      <td>Who was appointed as CEO of ABC Education Corp...</td>\n",
       "      <td>Mr. John Doe was appointed as CEO of ABC Educa...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"V. Lewis's chief complaint is fever, cough, ...</td>\n",
       "      <td>According to the hospitalization records of Ne...</td>\n",
       "      <td>Fever, cough, and chest pain for 5 days.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"H. Walker's birthdate is 19th July, 1964 acc...</td>\n",
       "      <td>According to the court judgment of Riverton, H...</td>\n",
       "      <td>19th July, 1964</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['The residence of Z. Torres was 22, Maple Ave...</td>\n",
       "      <td>According to the court judgment of Sterling, Q...</td>\n",
       "      <td>22, Maple Avenue, Quarryville</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>['Retail Emporium uses a risk management syste...</td>\n",
       "      <td>What system does Retail Emporium have in place...</td>\n",
       "      <td>Retail Emporium conducts regular audits and ri...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>['Retail Emporium was established in November ...</td>\n",
       "      <td>When was Retail Emporium established?</td>\n",
       "      <td>December 2005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>['Retail Emporium distributed a dividend of $4...</td>\n",
       "      <td>How much dividend did Retail Emporium distribu...</td>\n",
       "      <td>$4 million</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>['Retail Emporium opened three new stores in M...</td>\n",
       "      <td>How many new stores did Retail Emporium open i...</td>\n",
       "      <td>Retail Emporium opened three new stores in Mar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>[\"Retail Emporium's operating income in 2020 w...</td>\n",
       "      <td>What was Retail Emporium's operating income in...</td>\n",
       "      <td>Retail Emporium's operating income in 2020 was...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ground_truth.keypoints  \\\n",
       "0    [\"JetWing Aviation's total liabilities amounte...   \n",
       "1    ['Mr. John Doe was appointed as CEO of ABC Edu...   \n",
       "2    [\"V. Lewis's chief complaint is fever, cough, ...   \n",
       "3    [\"H. Walker's birthdate is 19th July, 1964 acc...   \n",
       "4    ['The residence of Z. Torres was 22, Maple Ave...   \n",
       "..                                                 ...   \n",
       "199  ['Retail Emporium uses a risk management syste...   \n",
       "200  ['Retail Emporium was established in November ...   \n",
       "201  ['Retail Emporium distributed a dividend of $4...   \n",
       "202  ['Retail Emporium opened three new stores in M...   \n",
       "203  [\"Retail Emporium's operating income in 2020 w...   \n",
       "\n",
       "                                         query.content  \\\n",
       "0    What was the total amount of JetWing Aviation'...   \n",
       "1    Who was appointed as CEO of ABC Education Corp...   \n",
       "2    According to the hospitalization records of Ne...   \n",
       "3    According to the court judgment of Riverton, H...   \n",
       "4    According to the court judgment of Sterling, Q...   \n",
       "..                                                 ...   \n",
       "199  What system does Retail Emporium have in place...   \n",
       "200              When was Retail Emporium established?   \n",
       "201  How much dividend did Retail Emporium distribu...   \n",
       "202  How many new stores did Retail Emporium open i...   \n",
       "203  What was Retail Emporium's operating income in...   \n",
       "\n",
       "                                    generated_response  keypoint_coverage  \n",
       "0                                         $250 million                1.0  \n",
       "1    Mr. John Doe was appointed as CEO of ABC Educa...                1.0  \n",
       "2             Fever, cough, and chest pain for 5 days.                1.0  \n",
       "3                                      19th July, 1964                1.0  \n",
       "4                        22, Maple Avenue, Quarryville                1.0  \n",
       "..                                                 ...                ...  \n",
       "199  Retail Emporium conducts regular audits and ri...                1.0  \n",
       "200                                      December 2005                0.0  \n",
       "201                                         $4 million                1.0  \n",
       "202  Retail Emporium opened three new stores in Mar...                1.0  \n",
       "203  Retail Emporium's operating income in 2020 was...                1.0  \n",
       "\n",
       "[204 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare for completeness evaluation\n",
    "filepath = \"evaluation/keypoint_eval/_queries_with_context_with_DQ_5_generations.csv\"\n",
    "filepath_new = \"evaluation/keypoint_eval/with_DQ.csv\"\n",
    "\n",
    "data = pd.read_csv(\n",
    "    filepath,\n",
    "    usecols=[\"query.content\", \"ground_truth.keypoints\", \"generated_response\", \"keypoint_coverage\"],\n",
    ")\n",
    "\n",
    "data.to_csv(\n",
    "    filepath_new,\n",
    "    index=False,\n",
    "    columns=[\"query.content\", \"ground_truth.keypoints\", \"generated_response\", \"keypoint_coverage\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
