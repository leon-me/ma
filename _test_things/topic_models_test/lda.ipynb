{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- uni_ulm_aspo_2017.md ---\n",
      "Topic 0: 0.01 %\n",
      "x Topic 1: 99.97 %\n",
      "Topic 2: 0.01 %\n",
      "Topic 3: 0.01 %\n",
      "Topic 4: 0.01 %\n",
      "\n",
      "--- uni_ulm_aspo_2022.md ---\n",
      "Topic 0: 0.01 %\n",
      "x Topic 1: 99.97 %\n",
      "Topic 2: 0.01 %\n",
      "Topic 3: 0.01 %\n",
      "Topic 4: 0.01 %\n",
      "\n",
      "--- hsa_fspo_informatik_bachelor_2019.md ---\n",
      "x Topic 0: 99.90 %\n",
      "Topic 1: 0.02 %\n",
      "Topic 2: 0.02 %\n",
      "Topic 3: 0.02 %\n",
      "Topic 4: 0.02 %\n",
      "\n",
      "--- uni_ulm_FSPO_Biologie_bachelor_master_2022.md ---\n",
      "Topic 0: 0.03 %\n",
      "x Topic 1: 99.90 %\n",
      "Topic 2: 0.03 %\n",
      "Topic 3: 0.03 %\n",
      "Topic 4: 0.03 %\n",
      "\n",
      "--- uni_ulm_fspo_informatikstudiengaenge_bachelor_master_2021.md ---\n",
      "Topic 0: 0.01 %\n",
      "x Topic 1: 99.94 %\n",
      "Topic 2: 0.01 %\n",
      "Topic 3: 0.01 %\n",
      "Topic 4: 0.01 %\n",
      "\n",
      "--- uni_ulm_fspo_innovations_wissenschaftsmanagement_ma_2017.md ---\n",
      "Topic 0: 0.03 %\n",
      "x Topic 1: 99.87 %\n",
      "Topic 2: 0.03 %\n",
      "Topic 3: 0.03 %\n",
      "Topic 4: 0.03 %\n",
      "\n",
      "--- uni_ulm_fspo_Informatikstudiengaenge_bachelor_master_2022.md ---\n",
      "Topic 0: 0.01 %\n",
      "x Topic 1: 99.95 %\n",
      "Topic 2: 0.01 %\n",
      "Topic 3: 0.01 %\n",
      "Topic 4: 0.01 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"german\")\n",
    "\n",
    "train_dir = os.path.join(\"..\", \"data\", \"md\", \"train\")\n",
    "test_dir = os.path.join(\"..\", \"data\", \"md\", \"test\")\n",
    "\n",
    "doc_names = [doc for doc in os.listdir(train_dir)]\n",
    "doc_names += [doc for doc in os.listdir(test_dir)]\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx) + \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "def document_generator(folder_path, print_names=False):\n",
    "    \"\"\"Yield content of each text file in the specified folder.\"\"\"\n",
    "    for i, filename in enumerate(os.listdir(folder_path), start=1):\n",
    "        if(print_names):\n",
    "            print(f\"{i}. {filename}\")\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                yield file.read()\n",
    "\n",
    "# change cwd to folder where file is in\n",
    "os.chdir(globals()['_dh'][0])\n",
    "\n",
    "train_documents = document_generator(train_dir)\n",
    "all_documents = itertools.chain(document_generator(train_dir), document_generator(test_dir))\n",
    "\n",
    "no_features = 10000\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop_words)\n",
    "tf_train = tf_vectorizer.fit_transform(train_documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "no_topics = 5\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=20, learning_method='online', learning_offset=50.,random_state=0).fit(tf_train)\n",
    "\n",
    "no_top_words = 10\n",
    "# display_topics(lda, tf_feature_names, no_top_words)\n",
    "\n",
    "classification = lda.transform(tf_vectorizer.transform(all_documents), normalize=True)\n",
    "\n",
    "for id, doc in enumerate(classification):\n",
    "    print(f\"\\n--- {doc_names[id]} ---\")\n",
    "    for i in range(no_topics):\n",
    "        if(doc[i] == max(doc)):\n",
    "            print(\"x \", end=\"\")\n",
    "        print(f\"Topic {i}: {doc[i]*100:.2f} %\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
