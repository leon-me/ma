{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- uni_ulm_fspo_Informatikstudiengaenge_bachelor_master_2022.md ---\n",
      "Topic 0: 1.31 %\n",
      "Topic 1: 1.31 %\n",
      "Topic 2: 1.31 %\n",
      "Topic 3: 1.31 %\n",
      "Topic 4: 93.45 %\n",
      "Topic 5: 1.31 %\n",
      "\n",
      "--- uni_ulm_aspo_2017.md ---\n",
      "Topic 0: 1.11 %\n",
      "Topic 1: 1.11 %\n",
      "Topic 2: 1.11 %\n",
      "Topic 3: 1.11 %\n",
      "Topic 4: 94.47 %\n",
      "Topic 5: 1.11 %\n",
      "\n",
      "--- uni_ulm_aspo_2022.md ---\n",
      "Topic 0: 1.07 %\n",
      "Topic 1: 1.07 %\n",
      "Topic 2: 1.07 %\n",
      "Topic 3: 1.07 %\n",
      "Topic 4: 94.66 %\n",
      "Topic 5: 1.07 %\n",
      "\n",
      "--- hsa_fspo_informatik_bachelor_2019.md ---\n",
      "Topic 0: 1.05 %\n",
      "Topic 1: 1.05 %\n",
      "Topic 2: 1.05 %\n",
      "Topic 3: 1.05 %\n",
      "Topic 4: 94.74 %\n",
      "Topic 5: 1.05 %\n",
      "\n",
      "--- uni_ulm_FSPO_Biologie_bachelor_master_2022.md ---\n",
      "Topic 0: 1.21 %\n",
      "Topic 1: 1.21 %\n",
      "Topic 2: 1.21 %\n",
      "Topic 3: 1.21 %\n",
      "Topic 4: 93.97 %\n",
      "Topic 5: 1.21 %\n",
      "\n",
      "--- uni_ulm_fspo_informatikstudiengaenge_bachelor_master_2021.md ---\n",
      "Topic 0: 1.24 %\n",
      "Topic 1: 1.24 %\n",
      "Topic 2: 1.24 %\n",
      "Topic 3: 1.24 %\n",
      "Topic 4: 93.81 %\n",
      "Topic 5: 1.24 %\n",
      "\n",
      "--- uni_ulm_fspo_innovations_wissenschaftsmanagement_ma_2017.md ---\n",
      "Topic 0: 1.16 %\n",
      "Topic 1: 1.16 %\n",
      "Topic 2: 1.16 %\n",
      "Topic 3: 1.16 %\n",
      "Topic 4: 94.22 %\n",
      "Topic 5: 1.16 %\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Load Dataset\n",
    "md_dir = os.path.join(\"..\", \"data\", \"md\")\n",
    "doc_names = [doc for doc in os.listdir(md_dir)]\n",
    "documents_list = []\n",
    "for doc in doc_names:\n",
    "    with open(os.path.join(md_dir, doc)) as f:\n",
    "        content = f.read()\n",
    "        documents_list.append(content)  \n",
    "\n",
    "\n",
    "# Initialize regex tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Vectorize document using TF-IDF\n",
    "tfidf = TfidfVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,1),\n",
    "                        tokenizer = tokenizer.tokenize)\n",
    "\n",
    "# Fit and Transform the documents\n",
    "train_data = tfidf.fit_transform(documents_list)\n",
    "\n",
    "# Define the number of topics or components\n",
    "num_components=6\n",
    "\n",
    "# Create LDA object\n",
    "model=LatentDirichletAllocation(n_components=num_components)\n",
    "\n",
    "# Fit and Transform SVD model on data\n",
    "lda_matrix = model.fit_transform(train_data)\n",
    "\n",
    "# Get Components \n",
    "lda_components=model.components_\n",
    "\n",
    "\n",
    "# Print the topics with their terms\n",
    "# terms = tfidf.get_feature_names()\n",
    "# for index, component in enumerate(lda_components):\n",
    "    # zipped = zip(terms, component)\n",
    "    # top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:5]\n",
    "    # top_terms_list=list(dict(top_terms_key).keys())\n",
    "    # print(\"Topic \"+str(index)+\": \",top_terms_list)\n",
    "\n",
    "for id, doc in enumerate(doc_names):\n",
    "    print(f\"\\n--- {doc} ---\")\n",
    "    for i in range(num_components):\n",
    "        print(f\"Topic {i}: {lda_matrix[id][i]*100:.2f} %\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
