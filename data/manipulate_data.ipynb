{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6703517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5ce678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### static variables\n",
    "\n",
    "COLUMNS_DOCS = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TEXTUAL = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR_ROW = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "    \"query.original_query_id\",\n",
    "    \"ground_truth.content\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_names\",\n",
    "    \"court_names\",\n",
    "    \"hospital_patient_names\",\n",
    "    \"original_doc_ids\",\n",
    "]\n",
    "\n",
    "COLUMNS_QUERIES = [\n",
    "    \"domain\",\n",
    "    \"ground_truth.content\",\n",
    "    \"ground_truth.doc_ids\",\n",
    "    \"ground_truth.keypoints\",\n",
    "    \"ground_truth.references\",\n",
    "    \"language\",\n",
    "    \"prediction\",\n",
    "    \"query.content\",\n",
    "    \"query.query_id\",\n",
    "    \"query.query_type\",\n",
    "]\n",
    "\n",
    "COLUMNS_QUERIES_MANIPULATED = [*COLUMNS_QUERIES, \"query.original_query_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a800bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions/classes for manipulation\n",
    "from typing import Tuple, List, Dict\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "from typing import Literal\n",
    "import sys\n",
    "import json\n",
    "\n",
    "DOCUMENTS = pd.read_csv(\"DRAGONball/en/docs.csv\")\n",
    "QUERIES = pd.read_csv(\n",
    "    \"DRAGONball/en/queries_flattened.csv\",\n",
    "    converters={\n",
    "        \"ground_truth.doc_ids\": ast.literal_eval,\n",
    "        \"ground_truth.keypoints\": ast.literal_eval,\n",
    "        \"ground_truth.references\": ast.literal_eval,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "class SingleTextualManipulationResponse(BaseModel):\n",
    "    text_new: str\n",
    "    answer_new: str\n",
    "    references_new: list[str]\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    references: List[str]\n",
    "\n",
    "class MultiTextualManipulationResponse(BaseModel):\n",
    "    text_new: str\n",
    "    qa_pairs_new: List[QAPair]\n",
    "\n",
    "class SingleTabularManipulationResponse(BaseModel):\n",
    "    answer_new: str\n",
    "    description: str\n",
    "    value: str\n",
    "\n",
    "def read_prompt(path: str | os.PathLike) -> Dict:\n",
    "    \"\"\"Reads from JSON-file\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def format_user_prompt_single_textual(user_prompt: str, text: str, question: str, answer: str, references: str) -> str:\n",
    "    return user_prompt.format(text=text, question=question, answer=answer, references=references)\n",
    "\n",
    "\n",
    "def format_user_prompt_single_tabular(user_prompt: str, question: str, answer: str, entity: str) -> str:\n",
    "    return user_prompt.format(question=question, answer=answer, entity=entity)\n",
    "\n",
    "def format_user_prompt_multi_textual(user_prompt: str, text: str, qa_pairs: List[Dict]) -> str:\n",
    "    \"\"\"qa_pairs must be of format: [ { question: '...', answer: '...' }, ... ]\"\"\"\n",
    "    questions_str = \"\"\n",
    "    for id, qa in enumerate(qa_pairs, start=1):\n",
    "        questions_str += f\"question{id}: {qa[\"question\"]}\\n\"\n",
    "        questions_str += f\"answer{id}: {qa[\"answer\"]}\\n\"\n",
    "\n",
    "    return user_prompt.format(text=text, questions=questions_str)\n",
    "\n",
    "\n",
    "def get_query_ids_for_doc(doc_id: int | str, query_types: list[str] = [\"Factual Question\"]) -> list[int]:\n",
    "    \"\"\"Selects query_ids for queries related to that doc and with a specified type.\"\"\"\n",
    "    return QUERIES[\n",
    "        QUERIES[\"ground_truth.doc_ids\"].apply(lambda doc_ids: int(doc_id) in doc_ids)\n",
    "        & QUERIES[\"query.query_type\"].isin(query_types)\n",
    "    ][\"query.query_id\"].to_list()\n",
    "\n",
    "\n",
    "def get_doc_query_mapping_single(target: Literal[\"textual\", \"tabular\"]) -> List[Dict[str, int]]:\n",
    "    with open(\"doc_query_mapping_single.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [\n",
    "            {\n",
    "                \"doc_id\": int(row[\"doc_id\"]),\n",
    "                \"query_id\": int(row[\"query_id_single\"]) if target == \"textual\" else int(row[\"query_id_multi\"]),\n",
    "            }\n",
    "            for row in reader\n",
    "        ]\n",
    "\n",
    "def get_doc_query_mapping_multi() -> List[Dict]:\n",
    "    with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        doc_ids = [row[\"doc_id\"] for row in reader if int(row[\"multi_textual_manipulation\"]) == 1]\n",
    "    mapping = []\n",
    "    for id in doc_ids: \n",
    "        entry = {\n",
    "            \"doc_id\": id,\n",
    "            \"query_ids\": get_query_ids_for_doc(id, query_types=[\"Factual Question\"])\n",
    "            }\n",
    "        mapping.append(entry)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_query_properties(\n",
    "    query_id,\n",
    "    properties: list = [\"ground_truth.content\", \"ground_truth.keypoints\", \"ground_truth.references\", \"query.content\"],\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for query_id from queries dataframe.\"\"\"\n",
    "    row = QUERIES[QUERIES[\"query.query_id\"] == query_id]\n",
    "    return tuple(row[prop].iloc[0] for prop in properties)\n",
    "\n",
    "\n",
    "def get_doc_properties(\n",
    "    doc_id,\n",
    "    properties,\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for doc_id from docs dataframe.\"\"\"\n",
    "    row: pd.DataFrame = DOCUMENTS[DOCUMENTS[\"doc_id\"] == doc_id].dropna(axis=1)\n",
    "    return tuple(row[prop].iloc[0] for prop in properties if prop in row.columns)\n",
    "\n",
    "\n",
    "def get_doc_text(doc_id: int | str) -> str:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"] == int(doc_id)][\"content\"].iloc[0]\n",
    "\n",
    "\n",
    "def get_query_by_id(query_id: int) -> pd.Series:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int) == query_id].iloc[0]\n",
    "\n",
    "\n",
    "def get_queries_by_id(query_ids: List[int]) -> pd.DataFrame:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int).isin(query_ids)]\n",
    "\n",
    "\n",
    "def get_doc_by_id(doc_id: int | str) -> pd.Series:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"].astype(int) == int(doc_id)].iloc[0]\n",
    "\n",
    "\n",
    "def openai_interface(system_prompt, user_prompt, response_format_pydantic=SingleTextualManipulationResponse):\n",
    "    \"\"\"execute openai LLM call\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI()\n",
    "    print(\"DEBUG: Attempting LLM call\")\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        response_format=response_format_pydantic,\n",
    "        temperature=0,\n",
    "    ).choices[0]\n",
    "    print(\"DEBUG: Finished LLM call\")\n",
    "    return completion.message.parsed\n",
    "\n",
    "\n",
    "def get_prompts_for_textual_single(doc_id: int, query_id: int) -> Tuple:\n",
    "    PROMPT_TYPE = \"manipulation_factual\"\n",
    "    prompt = [\n",
    "        prompt for prompt in read_prompt(\"prompts/json/manipulate_docs.json\") if prompt[\"prompt_type\"] == PROMPT_TYPE\n",
    "    ][0]\n",
    "    text = get_doc_text(doc_id)\n",
    "    answer, keypoints, references, question = get_query_properties(query_id)\n",
    "    system_prompt = prompt[\"system_prompt\"]\n",
    "    user_prompt = format_user_prompt_single_textual(\n",
    "        user_prompt=prompt[\"user_prompt\"], text=text, answer=answer, question=question, references=references\n",
    "    )\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_for_tabular_single(query_id: int, doc_id: int) -> Tuple:\n",
    "    prompt_obj = read_prompt(\"prompts/json/manipulation_tabular.json\")\n",
    "    system_prompt = prompt_obj[\"system_prompt\"]\n",
    "    user_prompt = prompt_obj[\"user_prompt\"]\n",
    "    answer, question = get_query_properties(query_id, properties=[\"ground_truth.content\", \"query.content\"])\n",
    "    (entity,) = get_doc_properties(doc_id, [\"hospital_patient_name\", \"company_name\", \"court_name\"])\n",
    "    user_prompt = format_user_prompt_single_tabular(user_prompt, question, answer, entity)\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_for_textual_multi(doc_id: int, query_ids: List[int]) -> Tuple:\n",
    "    prompt_obj = read_prompt(\"../prompts/json/manipulation_multi_textual.json\")\n",
    "    text = get_doc_text(doc_id)\n",
    "    qa_pairs = []\n",
    "    for query_id in query_ids:\n",
    "        question, answer = get_query_properties(query_id, [\"query.content\",\"ground_truth.content\"])\n",
    "        qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "    \n",
    "    system_prompt = prompt_obj[\"system_prompt\"]\n",
    "    user_prompt = format_user_prompt_multi_textual(user_prompt=prompt_obj[\"user_prompt\"], text=text, qa_pairs=qa_pairs)\n",
    "    \n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_id_for_manipulated_doc_or_query(original_doc_id: int, prefix_number=1) -> int:\n",
    "    id_str = str(prefix_number) + str(original_doc_id).zfill(5)\n",
    "    return int(id_str)\n",
    "\n",
    "\n",
    "def save_manipulated_doc(filename: os.PathLike | str, fieldnames: List[str], **kwargs):\n",
    "    \"\"\"Saves a manipulated doc to csv.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        raise RuntimeError(\"Must specify a filename!\")\n",
    "    \n",
    "    print(f\"Saving Doc with ID '{kwargs[\"doc_id\"]}'\")\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=fieldnames)\n",
    "            ids_present = {int(row[\"doc_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(kwargs[\"doc_id\"]) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {kwargs[\"doc_id\"]} already exists. Did not write new document to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(kwargs)\n",
    "\n",
    "\n",
    "def save_manipulated_query(\n",
    "    filename: os.PathLike | str,\n",
    "    fieldnames: List[str],\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Saves a manipulated query to csv.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        raise RuntimeError(\"Must specify a filename!\")\n",
    "    \n",
    "    print(f\"Saving Query with ID '{kwargs[\"query.query_id\"]}'\")\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=fieldnames)\n",
    "            ids_present = {int(row[\"query.query_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(kwargs[\"query.query_id\"]) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {kwargs[\"query.query_id\"]} already exists. Did not write new query to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ef2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents:\n",
      " Index(['hospital_patient_name', 'language', 'doc_id', 'domain', 'content',\n",
      "       'company_name', 'court_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Queries:\n",
      " Index(['domain', 'ground_truth.content', 'ground_truth.doc_ids',\n",
      "       'ground_truth.keypoints', 'ground_truth.references', 'language',\n",
      "       'prediction', 'query.content', 'query.query_id', 'query.query_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### describe documents and queries\n",
    "\n",
    "print(\"Documents:\\n\", DOCUMENTS.columns)\n",
    "print()\n",
    "print(\"Queries:\\n\", QUERIES.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205f0e4",
   "metadata": {},
   "source": [
    "## Single Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents (textual)\n",
    "def save_single_textual(doc_entry, query_entry, completion_parsed):\n",
    "    # -- doc\n",
    "    original_doc_id = doc_entry.doc_id\n",
    "    manipulated_doc_entry = doc_entry.copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(original_doc_id)\n",
    "    manipulated_doc_entry.content = completion_parsed.text_new\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([original_doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)\n",
    "\n",
    "    # -- query\n",
    "    original_query_id = query_entry[\"query.query_id\"]\n",
    "    manipulated_query_entry = query_entry.copy()\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = completion_parsed.answer_new\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = completion_parsed.references_new\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "    manipulated_query_entry.index = manipulated_query_entry.index.str.replace(\".\", \"__\", regex=False)\n",
    "\n",
    "    save_manipulated_query(**manipulated_query_entry)\n",
    "\n",
    "\n",
    "doc_query_mapping = get_doc_query_mapping_single()\n",
    "\n",
    "for mapping in doc_query_mapping:\n",
    "    doc_id = mapping[\"doc_id\"]\n",
    "    query_id = mapping[\"query_id\"]\n",
    "\n",
    "    doc_entry = get_doc_by_id(doc_id)\n",
    "    query_entry = get_query_by_id(query_id)\n",
    "\n",
    "    system_prompt, user_prompt = get_prompts_for_textual_single(doc_id, query_id)\n",
    "\n",
    "    # call openai\n",
    "    completion_parsed = openai_interface(system_prompt, user_prompt)\n",
    "\n",
    "    save_single_textual(doc_entry, query_entry, completion_parsed)\n",
    "    print(f\"Finished processing doc {doc_id} and query {query_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd70e1",
   "metadata": {},
   "source": [
    "## Single Tabular Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents (tabular) and save rows\n",
    "mapping = get_doc_query_mapping_single(\"tabular\")\n",
    "\n",
    "doc_entries = []\n",
    "\n",
    "for id_pair in mapping:\n",
    "    doc_id = id_pair[\"doc_id\"]\n",
    "    query_id = id_pair[\"query_id\"]\n",
    "    system_prompt, user_prompt = get_prompts_for_tabular_single(query_id, doc_id)\n",
    "\n",
    "    response: SingleTabularManipulationResponse = openai_interface(\n",
    "        system_prompt, user_prompt, SingleTabularManipulationResponse\n",
    "    )\n",
    "\n",
    "    manipulated_doc_entry = get_doc_by_id(doc_id).copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(doc_id, prefix_number=2)\n",
    "    manipulated_doc_entry.content = \" | \".join([response.description, response.value])\n",
    "    additional_fields = pd.Series(\n",
    "        [doc_id, query_id, response.answer_new],\n",
    "        index=[\"original_doc_id\", \"query.original_query_id\", \"ground_truth.content\"],\n",
    "    )\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, additional_fields])\n",
    "\n",
    "    save_manipulated_doc(\n",
    "        filename=\"additional_data/docs/tabular_manipulations_result_rows.csv\",\n",
    "        fieldnames=COLUMNS_DOCS_MANIPULATED_TABULAR_ROW,\n",
    "        **manipulated_doc_entry,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate tabular rows and save docs\n",
    "tabular_docs = pd.read_csv(\"additional_data/docs/tabular_manipulations_result_rows.csv\")\n",
    "\n",
    "\n",
    "def list_or_none(series):\n",
    "    if series.dropna().empty:\n",
    "        return None\n",
    "    return series.tolist()\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    "    \"doc_id\": lambda x: 0,\n",
    "    \"language\": \"first\",\n",
    "    \"content\": \"\\n\".join,\n",
    "    \"company_name\": list_or_none,\n",
    "    \"court_name\": list_or_none,\n",
    "    \"hospital_patient_name\": list_or_none,\n",
    "    \"original_doc_id\": list_or_none,\n",
    "    \"query.original_query_id\": lambda x: None,\n",
    "    \"ground_truth.content\": lambda x: None,\n",
    "}\n",
    "\n",
    "aggregation = tabular_docs.groupby(\"domain\").agg(agg_funcs).reset_index()\n",
    "aggregation[\"doc_id\"] = [get_id_for_manipulated_doc_or_query(id, prefix_number=3) for id in [1, 2, 3]]\n",
    "aggregation.rename(\n",
    "    columns={\n",
    "        \"company_name\": \"company_names\",\n",
    "        \"court_name\": \"court_names\",\n",
    "        \"hospital_patient_name\": \"hospital_patient_names\",\n",
    "        \"original_doc_id\": \"original_doc_ids\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "for row_dict in aggregation.to_dict(orient=\"records\"):\n",
    "    save_manipulated_doc(\n",
    "        \"additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        fieldnames=COLUMNS_DOCS_MANIPULATED_TABULAR,\n",
    "        **row_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d16476",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save manipulated queries for aggregated tabular docs\n",
    "tabular_docs = pd.read_csv(\"additional_data/docs/tabular_manipulations_result_rows.csv\")\n",
    "\n",
    "mapping_domain_doc_id = pd.read_csv(\n",
    "    \"additional_data/docs/tabular_manipulations_result.csv\", usecols=[\"domain\", \"doc_id\"]\n",
    ")\n",
    "mapping_dict = mapping_domain_doc_id.set_index(\"domain\")[\"doc_id\"].to_dict()\n",
    "\n",
    "for row_dict in tabular_docs.to_dict(orient=\"records\"):\n",
    "    original_query_id = row_dict[\"query.original_query_id\"]\n",
    "    manipulated_query_entry = get_query_by_id(original_query_id).copy()\n",
    "\n",
    "    manipulated_query_entry[\"ground_truth.doc_ids\"] = [mapping_dict[row_dict[\"domain\"]]]\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = row_dict[\"ground_truth.content\"]\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = row_dict[\"content\"]\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id, prefix_number=3)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "\n",
    "    save_manipulated_query(\n",
    "        filename=\"additional_data/queries/tabular_manipulations_result.csv\",\n",
    "        fieldnames=COLUMNS_QUERIES_MANIPULATED,\n",
    "        **manipulated_query_entry\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4244b02",
   "metadata": {},
   "source": [
    "## Multi Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "afac5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multi_textual(doc_entry, query_entries: pd.DataFrame, text_new: str, qa_pairs: List[QAPair]):\n",
    "    # -- doc\n",
    "    original_doc_id = doc_entry[\"doc_id\"]\n",
    "    manipulated_doc_entry = doc_entry.copy()\n",
    "    manipulated_doc_entry[\"doc_id\"] = get_id_for_manipulated_doc_or_query(original_doc_id, prefix_number=4)\n",
    "    manipulated_doc_entry[\"content\"] = text_new\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([original_doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(\n",
    "        filename=\"additional_data/docs/multi_textual_manipulations.csv\",\n",
    "        fieldnames=COLUMNS_DOCS_MANIPULATED_TEXTUAL,\n",
    "        **manipulated_doc_entry,\n",
    "    )\n",
    "\n",
    "    # -- queries\n",
    "    for qa_pair in qa_pairs:\n",
    "        try:\n",
    "            query_entry = query_entries[\n",
    "                query_entries[\"query.content\"].apply(str.strip).apply(str.lower) == qa_pair.question.strip().lower()\n",
    "            ].iloc[0]\n",
    "        except IndexError:\n",
    "            raise RuntimeError(\"No matching question found!\")\n",
    "\n",
    "        original_query_id = query_entry[\"query.query_id\"]\n",
    "        manipulated_query_entry = query_entry.copy()\n",
    "        manipulated_query_entry[\"ground_truth.content\"] = qa_pair.answer\n",
    "        manipulated_query_entry[\"ground_truth.references\"] = qa_pair.references\n",
    "        manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "        manipulated_query_entry[\"ground_truth.doc_ids\"] = [manipulated_doc_entry[\"doc_id\"]]\n",
    "        manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(\n",
    "            original_query_id, prefix_number=4\n",
    "        )\n",
    "        manipulated_query_entry = pd.concat(\n",
    "            [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "        )\n",
    "\n",
    "        save_manipulated_query(\n",
    "            filename=\"additional_data/queries/multi_textual_manipulations.csv\",\n",
    "            fieldnames=COLUMNS_QUERIES_MANIPULATED,\n",
    "            **manipulated_query_entry,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6c6a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/30 Start processing document with ID '128' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400128'\n",
      "WARN: Row with ID 400128 already exists. Did not write new document to 'additional_data/docs/multi_textual_manipulations.csv'.\n",
      "Saving Query with ID '404558'\n",
      "WARN: Row with ID 404558 already exists. Did not write new query to 'additional_data/queries/multi_textual_manipulations.csv'.\n",
      "Saving Query with ID '404559'\n",
      "WARN: Row with ID 404559 already exists. Did not write new query to 'additional_data/queries/multi_textual_manipulations.csv'.\n",
      "Finished processing document with ID '128'. Changed 2 queries.\n",
      "--- 2/30 Start processing document with ID '128' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400132'\n",
      "Saving Query with ID '404566'\n",
      "Saving Query with ID '404567'\n",
      "Saving Query with ID '404568'\n",
      "Saving Query with ID '404569'\n",
      "Saving Query with ID '404570'\n",
      "Finished processing document with ID '132'. Changed 5 queries.\n",
      "--- 3/30 Start processing document with ID '132' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400133'\n",
      "Saving Query with ID '404579'\n",
      "Saving Query with ID '404580'\n",
      "Saving Query with ID '404581'\n",
      "Saving Query with ID '404582'\n",
      "Saving Query with ID '404583'\n",
      "Finished processing document with ID '133'. Changed 5 queries.\n",
      "--- 4/30 Start processing document with ID '133' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400134'\n",
      "Saving Query with ID '404620'\n",
      "Saving Query with ID '404621'\n",
      "Saving Query with ID '404622'\n",
      "Saving Query with ID '404623'\n",
      "Finished processing document with ID '134'. Changed 4 queries.\n",
      "--- 5/30 Start processing document with ID '134' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400136'\n",
      "Saving Query with ID '404609'\n",
      "Saving Query with ID '404610'\n",
      "Saving Query with ID '404611'\n",
      "Saving Query with ID '404612'\n",
      "Finished processing document with ID '136'. Changed 4 queries.\n",
      "--- 6/30 Start processing document with ID '136' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400205'\n",
      "Saving Query with ID '406189'\n",
      "Saving Query with ID '406190'\n",
      "Saving Query with ID '406191'\n",
      "Saving Query with ID '406192'\n",
      "Finished processing document with ID '205'. Changed 4 queries.\n",
      "--- 7/30 Start processing document with ID '205' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400139'\n",
      "Saving Query with ID '404642'\n",
      "Saving Query with ID '404643'\n",
      "Saving Query with ID '404644'\n",
      "Saving Query with ID '404645'\n",
      "Finished processing document with ID '139'. Changed 4 queries.\n",
      "--- 8/30 Start processing document with ID '139' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400040'\n",
      "Saving Query with ID '402300'\n",
      "Saving Query with ID '402311'\n",
      "Saving Query with ID '402313'\n",
      "Saving Query with ID '402314'\n",
      "Saving Query with ID '402315'\n",
      "Saving Query with ID '402316'\n",
      "Finished processing document with ID '40'. Changed 6 queries.\n",
      "--- 9/30 Start processing document with ID '40' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400042'\n",
      "Saving Query with ID '402739'\n",
      "Saving Query with ID '402740'\n",
      "Saving Query with ID '402750'\n",
      "Saving Query with ID '402751'\n",
      "Saving Query with ID '402752'\n",
      "Saving Query with ID '402753'\n",
      "Finished processing document with ID '42'. Changed 6 queries.\n",
      "--- 10/30 Start processing document with ID '42' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400052'\n",
      "Saving Query with ID '402509'\n",
      "Saving Query with ID '402510'\n",
      "Saving Query with ID '402511'\n",
      "Saving Query with ID '402512'\n",
      "Saving Query with ID '402523'\n",
      "Saving Query with ID '402525'\n",
      "Saving Query with ID '402526'\n",
      "Saving Query with ID '402527'\n",
      "Saving Query with ID '402528'\n",
      "Saving Query with ID '402529'\n",
      "Finished processing document with ID '52'. Changed 10 queries.\n",
      "--- 11/30 Start processing document with ID '52' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400053'\n",
      "Saving Query with ID '403154'\n",
      "Saving Query with ID '403155'\n",
      "Saving Query with ID '403163'\n",
      "Saving Query with ID '403164'\n",
      "Saving Query with ID '403165'\n",
      "Saving Query with ID '403166'\n",
      "Finished processing document with ID '53'. Changed 6 queries.\n",
      "--- 12/30 Start processing document with ID '53' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400183'\n",
      "Saving Query with ID '405993'\n",
      "Saving Query with ID '405994'\n",
      "Saving Query with ID '405995'\n",
      "Saving Query with ID '405996'\n",
      "Finished processing document with ID '183'. Changed 4 queries.\n",
      "--- 13/30 Start processing document with ID '183' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400059'\n",
      "Saving Query with ID '402679'\n",
      "Saving Query with ID '402682'\n",
      "Saving Query with ID '402688'\n",
      "Saving Query with ID '402696'\n",
      "Saving Query with ID '402698'\n",
      "Saving Query with ID '402699'\n",
      "Saving Query with ID '402700'\n",
      "Finished processing document with ID '59'. Changed 7 queries.\n",
      "--- 14/30 Start processing document with ID '59' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400188'\n",
      "Saving Query with ID '406050'\n",
      "Saving Query with ID '406051'\n",
      "Saving Query with ID '406052'\n",
      "Saving Query with ID '406053'\n",
      "Finished processing document with ID '188'. Changed 4 queries.\n",
      "--- 15/30 Start processing document with ID '188' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400192'\n",
      "Saving Query with ID '406094'\n",
      "Saving Query with ID '406095'\n",
      "Saving Query with ID '406096'\n",
      "Saving Query with ID '406097'\n",
      "Finished processing document with ID '192'. Changed 4 queries.\n",
      "--- 16/30 Start processing document with ID '192' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400065'\n",
      "Saving Query with ID '402159'\n",
      "Saving Query with ID '402160'\n",
      "Saving Query with ID '402171'\n",
      "Saving Query with ID '402172'\n",
      "Saving Query with ID '402173'\n",
      "Saving Query with ID '402174'\n",
      "Saving Query with ID '402175'\n",
      "Saving Query with ID '402176'\n",
      "Saving Query with ID '402178'\n",
      "Saving Query with ID '402179'\n",
      "Saving Query with ID '402180'\n",
      "Finished processing document with ID '65'. Changed 11 queries.\n",
      "--- 17/30 Start processing document with ID '65' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400194'\n",
      "Saving Query with ID '406110'\n",
      "Saving Query with ID '406111'\n",
      "Saving Query with ID '406112'\n",
      "Saving Query with ID '406113'\n",
      "Finished processing document with ID '194'. Changed 4 queries.\n",
      "--- 18/30 Start processing document with ID '194' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400198'\n",
      "Saving Query with ID '406140'\n",
      "Saving Query with ID '406141'\n",
      "Saving Query with ID '406142'\n",
      "Saving Query with ID '406143'\n",
      "Finished processing document with ID '198'. Changed 4 queries.\n",
      "--- 19/30 Start processing document with ID '198' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400199'\n",
      "Saving Query with ID '406148'\n",
      "Saving Query with ID '406149'\n",
      "Saving Query with ID '406150'\n",
      "Finished processing document with ID '199'. Changed 3 queries.\n",
      "--- 20/30 Start processing document with ID '199' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400074'\n",
      "Saving Query with ID '403025'\n",
      "Saving Query with ID '403026'\n",
      "Saving Query with ID '403025'\n",
      "WARN: Row with ID 403025 already exists. Did not write new query to 'additional_data/queries/multi_textual_manipulations.csv'.\n",
      "Saving Query with ID '403034'\n",
      "Saving Query with ID '403035'\n",
      "Saving Query with ID '403036'\n",
      "Finished processing document with ID '74'. Changed 6 queries.\n",
      "--- 21/30 Start processing document with ID '74' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400202'\n",
      "Saving Query with ID '406174'\n",
      "Saving Query with ID '406175'\n",
      "Saving Query with ID '406176'\n",
      "Saving Query with ID '406177'\n",
      "Finished processing document with ID '202'. Changed 4 queries.\n",
      "--- 22/30 Start processing document with ID '202' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400204'\n",
      "Saving Query with ID '406197'\n",
      "Saving Query with ID '406198'\n",
      "Saving Query with ID '406199'\n",
      "Saving Query with ID '406200'\n",
      "Finished processing document with ID '204'. Changed 4 queries.\n",
      "--- 23/30 Start processing document with ID '204' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400075'\n",
      "Saving Query with ID '403129'\n",
      "Saving Query with ID '403130'\n",
      "Saving Query with ID '403131'\n",
      "Saving Query with ID '403132'\n",
      "Saving Query with ID '403141'\n",
      "Saving Query with ID '403142'\n",
      "Saving Query with ID '403143'\n",
      "Saving Query with ID '403144'\n",
      "Saving Query with ID '403145'\n",
      "Finished processing document with ID '75'. Changed 9 queries.\n",
      "--- 24/30 Start processing document with ID '75' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400078'\n",
      "Saving Query with ID '402817'\n",
      "Saving Query with ID '402818'\n",
      "Saving Query with ID '402831'\n",
      "Saving Query with ID '402832'\n",
      "Saving Query with ID '402833'\n",
      "Finished processing document with ID '78'. Changed 5 queries.\n",
      "--- 25/30 Start processing document with ID '78' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400079'\n",
      "Saving Query with ID '402710'\n",
      "Saving Query with ID '402711'\n",
      "Saving Query with ID '402727'\n",
      "Saving Query with ID '402728'\n",
      "Saving Query with ID '402729'\n",
      "Saving Query with ID '402730'\n",
      "Finished processing document with ID '79'. Changed 6 queries.\n",
      "--- 26/30 Start processing document with ID '79' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400207'\n",
      "Saving Query with ID '406213'\n",
      "Saving Query with ID '406214'\n",
      "Saving Query with ID '406215'\n",
      "Saving Query with ID '406216'\n",
      "Finished processing document with ID '207'. Changed 4 queries.\n",
      "--- 27/30 Start processing document with ID '207' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400213'\n",
      "Saving Query with ID '406257'\n",
      "Saving Query with ID '406258'\n",
      "Saving Query with ID '406259'\n",
      "Saving Query with ID '406260'\n",
      "Finished processing document with ID '213'. Changed 4 queries.\n",
      "--- 28/30 Start processing document with ID '213' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400214'\n",
      "Saving Query with ID '406283'\n",
      "Saving Query with ID '406284'\n",
      "Saving Query with ID '406285'\n",
      "Saving Query with ID '406286'\n",
      "Finished processing document with ID '214'. Changed 4 queries.\n",
      "--- 29/30 Start processing document with ID '214' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400110'\n",
      "Saving Query with ID '404380'\n",
      "Saving Query with ID '404381'\n",
      "Saving Query with ID '404382'\n",
      "Finished processing document with ID '110'. Changed 3 queries.\n",
      "--- 30/30 Start processing document with ID '110' ---\n",
      "DEBUG: Attempting LLM call\n",
      "DEBUG: Finished LLM call\n",
      "Saving Doc with ID '400116'\n",
      "Saving Query with ID '404435'\n",
      "Saving Query with ID '404436'\n",
      "Saving Query with ID '404437'\n",
      "Saving Query with ID '404438'\n",
      "Finished processing document with ID '116'. Changed 4 queries.\n"
     ]
    }
   ],
   "source": [
    "doc_queries_mapping = get_doc_query_mapping_multi()\n",
    "\n",
    "for index, mapping in enumerate(doc_queries_mapping, start=1):\n",
    "    print(f\"--- {index}/{len(doc_queries_mapping)} Start processing document with ID '{doc_id}' ---\")\n",
    "    doc_id = mapping[\"doc_id\"]\n",
    "    query_ids = mapping[\"query_ids\"]\n",
    "\n",
    "    doc_entry = get_doc_by_id(doc_id)\n",
    "    query_entries = QUERIES.loc[QUERIES[\"query.query_id\"].isin(query_ids)]\n",
    "\n",
    "    system_prompt, user_prompt = get_prompts_for_textual_multi(doc_id, query_ids)\n",
    "\n",
    "    # call openai\n",
    "    completion_parsed: MultiTextualManipulationResponse = openai_interface(\n",
    "        system_prompt, user_prompt, MultiTextualManipulationResponse\n",
    "    )\n",
    "\n",
    "    save_multi_textual(\n",
    "        doc_entry, query_entries, text_new=completion_parsed.text_new, qa_pairs=completion_parsed.qa_pairs_new\n",
    "    )\n",
    "    print(f\"Finished processing document with ID '{doc_id}'. Changed {len(query_ids)} queries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
