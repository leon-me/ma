{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6703517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import ast\n",
    "import importlib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205f0e4",
   "metadata": {},
   "source": [
    "## Single Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import io_helpers, data_helpers, llm\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "\n",
    "FILENAME = \"single_textual_manipulations\"\n",
    "\n",
    "doc_ids = io_helpers.get_documents_to_manipulate(\"single_textual_manipulation\")\n",
    "doc_query_mapping: pd.DataFrame = io_helpers.get_doc_query_mapping(\"textual\")\n",
    "\n",
    "if len(set(doc_ids).symmetric_difference(set(doc_query_mapping[\"doc_id\"]))) > 0:\n",
    "    raise RuntimeError(\"Doc IDs don't match!\")\n",
    "\n",
    "documents = io_helpers.get_documents()\n",
    "queries = io_helpers.get_queries()\n",
    "\n",
    "\n",
    "def execute_manipulation(df_row):\n",
    "    doc_id = df_row[\"doc_id\"]\n",
    "    query_id = df_row[\"query_id\"]\n",
    "\n",
    "    doc_id_new = data_helpers.get_id_for_manipulated_doc_or_query(doc_id, prefix_number=1)\n",
    "    query_id_new = data_helpers.get_id_for_manipulated_doc_or_query(query_id, prefix_number=1)\n",
    "\n",
    "    if io_helpers.file_has_been_manipulated(\"doc\", FILENAME, doc_id_new) or io_helpers.file_has_been_manipulated(\n",
    "        \"query\", FILENAME, query_id_new\n",
    "    ):\n",
    "        print(f\"Doc with ID '{doc_id} has been manipulated before.\")\n",
    "        return None\n",
    "\n",
    "    doc_entry = documents.loc[documents[\"doc_id\"] == doc_id].squeeze()\n",
    "    query_entry = queries.loc[queries[\"query.query_id\"] == query_id].squeeze()\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_single_textual\")\n",
    "    user_prompt = llm.format_user_prompt_single_textual(\n",
    "        user_prompt,\n",
    "        text=doc_entry[\"content\"],\n",
    "        question=query_entry[\"query.content\"],\n",
    "        answer=query_entry[\"ground_truth.content\"],\n",
    "        references=query_entry[\"ground_truth.references\"],\n",
    "    )\n",
    "    response = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4.1\",\n",
    "        response_format_pydantic=llm.SingleTextualManipulationResponse,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    doc_entry_new = doc_entry.copy()\n",
    "    doc_entry_new.update({\"doc_id\": doc_id_new, \"content\": response.text_new})\n",
    "    doc_entry_new[\"original_doc_ids\"] = [doc_id]\n",
    "\n",
    "    query_entry_new = query_entry.copy()\n",
    "    query_entry_new.update(\n",
    "        {\n",
    "            \"query.query_id\": query_id_new,\n",
    "            \"ground_truth.content\": response.answer_new,\n",
    "            \"ground_truth.doc_ids\": [doc_id_new],\n",
    "            \"ground_truth.references\": response.references_new,\n",
    "            \"ground_truth.keypoints\": [],\n",
    "        }\n",
    "    )\n",
    "    query_entry_new[\"query.original_query_id\"] = query_id\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, doc_entry_new)\n",
    "    io_helpers.easy_save_manipulated_query(FILENAME, query_entry_new)\n",
    "\n",
    "\n",
    "# _ = doc_query_mapping.apply(func=execute_manipulation, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd70e1",
   "metadata": {},
   "source": [
    "## Single Tabular Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents and save rows and queries\n",
    "from utils import io_helpers, data_helpers, llm\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "FILENAME = \"single_tabular_manipulations_rows\"\n",
    "\n",
    "DOMAIN_TO_ID = {\"Medical\": 300001, \"Finance\": 300002, \"Law\": 300003}\n",
    "\n",
    "doc_ids = io_helpers.get_documents_to_manipulate(\"single_tabular_manipulation\")\n",
    "doc_query_mapping: pd.DataFrame = io_helpers.get_doc_query_mapping(\"tabular\")\n",
    "\n",
    "if len(set(doc_ids).symmetric_difference(set(doc_query_mapping[\"doc_id\"]))) > 0:\n",
    "    raise RuntimeError(\"Doc IDs don't match!\")\n",
    "\n",
    "documents = io_helpers.get_documents()\n",
    "queries = io_helpers.get_queries()\n",
    "\n",
    "\n",
    "new_documents = pd.DataFrame()\n",
    "\n",
    "\n",
    "def execute_manipulation(df_row):\n",
    "    doc_id = df_row[\"doc_id\"]\n",
    "    query_id = df_row[\"query_id\"]\n",
    "\n",
    "    doc_entry = documents.loc[documents[\"doc_id\"] == doc_id].squeeze()\n",
    "    query_entry = queries.loc[queries[\"query.query_id\"] == query_id].squeeze()\n",
    "\n",
    "    doc_id_new = DOMAIN_TO_ID[doc_entry[\"domain\"]]\n",
    "    query_id_new = data_helpers.get_id_for_manipulated_doc_or_query(query_id, prefix_number=3)\n",
    "\n",
    "    if io_helpers.file_has_been_manipulated(\"query\", \"single_tabular_manipulations\", query_id_new):\n",
    "        print(f\"Doc with ID '{doc_id} has been manipulated before.\")\n",
    "        return None\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_single_tabular\")\n",
    "    entity = data_helpers.get_entity_by_doc_id(doc_id, documents)\n",
    "    user_prompt = llm.format_user_prompt_single_tabular(\n",
    "        user_prompt=user_prompt,\n",
    "        question=query_entry[\"query.content\"],\n",
    "        answer=query_entry[\"ground_truth.content\"],\n",
    "        entity=entity,\n",
    "    )\n",
    "\n",
    "    response: llm.SingleTabularManipulationResponse = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4o\",\n",
    "        response_format_pydantic=llm.SingleTabularManipulationResponse,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    reference = f\"{response.description} | {response.value}\"\n",
    "\n",
    "    doc_entry_new = doc_entry.copy()\n",
    "    doc_entry_new.update({\"doc_id\": doc_id_new, \"content\": reference})\n",
    "    doc_entry_new[\"original_doc_ids\"] = [doc_id]\n",
    "\n",
    "    query_entry_new = query_entry.copy()\n",
    "    query_entry_new.update(\n",
    "        {\n",
    "            \"query.query_id\": query_id_new,\n",
    "            \"ground_truth.content\": response.answer_new,\n",
    "            \"ground_truth.doc_ids\": [doc_id_new],\n",
    "            \"ground_truth.references\": [reference],\n",
    "            \"ground_truth.keypoints\": [],\n",
    "        }\n",
    "    )\n",
    "    query_entry_new[\"query.original_query_id\"] = query_id\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, doc_entry_new)\n",
    "    io_helpers.easy_save_manipulated_query(\"single_tabular_manipulations\", query_entry_new)\n",
    "\n",
    "\n",
    "_ = doc_query_mapping.apply(func=execute_manipulation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83fa5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate tabular rows and save docs\n",
    "import ast\n",
    "\n",
    "tabular_docs = pd.read_csv(\n",
    "    \"additional_data/docs/single_tabular_manipulations_rows.csv\", converters={\"original_doc_ids\": ast.literal_eval}\n",
    ")\n",
    "\n",
    "\n",
    "def to_list(series):\n",
    "    if series.dropna().empty:\n",
    "        return []\n",
    "    return series.tolist()\n",
    "\n",
    "\n",
    "def flatten_lists(series):\n",
    "    return [item for sublist in series if isinstance(sublist, list) for item in sublist]\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    "    \"doc_id\": \"first\",\n",
    "    \"content\": \"\\n\".join,\n",
    "    \"company_name\": to_list,\n",
    "    \"court_name\": to_list,\n",
    "    \"hospital_patient_name\": to_list,\n",
    "    \"original_doc_ids\": flatten_lists,\n",
    "}\n",
    "\n",
    "aggregation = tabular_docs.groupby(\"domain\").agg(agg_funcs).reset_index()\n",
    "aggregation.rename(\n",
    "    columns={\n",
    "        \"company_name\": \"company_names\",\n",
    "        \"court_name\": \"court_names\",\n",
    "        \"hospital_patient_name\": \"hospital_patient_names\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "aggregation.to_csv(\"additional_data/docs/single_tabular_manipulations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4244b02",
   "metadata": {},
   "source": [
    "## Multi Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4facae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### helper methods\n",
    "from utils import data_helpers\n",
    "\n",
    "reload(data_helpers)\n",
    "\n",
    "\n",
    "def make_manipulated_query(query, qa_pairs):\n",
    "    manipulated_query = query.copy()\n",
    "    qa_pair = next(\n",
    "        pair for pair in qa_pairs if pair.question.lower().strip() == query[\"query.content\"].lower().strip()\n",
    "    )\n",
    "    manipulated_query.update(\n",
    "        {\n",
    "            \"query.query_id\": data_helpers.get_id_for_manipulated_doc_or_query(query[\"query.query_id\"], 4),\n",
    "            \"ground_truth.content\": qa_pair.answer,\n",
    "            \"ground_truth.references\": [qa_pair.quote],\n",
    "        }\n",
    "    )\n",
    "    manipulated_query[\"query.original_query_id\"] = query[\"query.query_id\"]\n",
    "    return manipulated_query\n",
    "\n",
    "\n",
    "def make_manipulated_doc(doc: pd.Series, text_new: str):\n",
    "    manipulated_doc = doc.copy()\n",
    "    manipulated_doc.update(\n",
    "        {\n",
    "            \"doc_id\": data_helpers.get_id_for_manipulated_doc_or_query(doc[\"doc_id\"], 4),\n",
    "            \"content\": text_new,\n",
    "        }\n",
    "    )\n",
    "    manipulated_doc[\"original_doc_ids\"] = [doc[\"doc_id\"]]\n",
    "    return manipulated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8e4c545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulate and save\n",
    "from utils import io_helpers, data_helpers, llm\n",
    "from importlib import reload\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "\n",
    "FILENAME = \"multi_textual_manipulations\"\n",
    "\n",
    "reload(io_helpers)\n",
    "reload(data_helpers)\n",
    "reload(llm)\n",
    "\n",
    "\n",
    "# for doc_id in doc_ids:\n",
    "def manipulate_and_save(doc_id: int, on_exist: Literal[\"skip\", \"override\"] = \"skip\"):\n",
    "    documents = io_helpers.get_documents()\n",
    "    queries = io_helpers.get_queries()\n",
    "\n",
    "    doc_has_been_manipulated = io_helpers.file_has_been_manipulated(\n",
    "        \"doc\", FILENAME, data_helpers.get_id_for_manipulated_doc_or_query(doc_id, 4)\n",
    "    )\n",
    "    if doc_has_been_manipulated & (on_exist == \"skip\"):\n",
    "        print(f\"Document with ID '{doc_id}' has been manipulated and saved before. Skipping this one.\")\n",
    "        return\n",
    "\n",
    "    doc: pd.Series = data_helpers.get_doc_by_id(doc_id, documents)\n",
    "    entity = data_helpers.get_entity_by_doc_id(doc_id, documents)\n",
    "    text = doc[\"content\"]\n",
    "\n",
    "    related_queries: pd.DataFrame = data_helpers.get_queries_by_doc_id(doc_id, queries)\n",
    "    qa_pairs = data_helpers.make_qa_pairs(related_queries)\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_multi_textual_v03\")\n",
    "    user_prompt = llm.format_user_prompt_multi_textual_v02(user_prompt, entity, text, qa_pairs)\n",
    "\n",
    "    llm_response: llm.MultiTextualManipulationResponseV02 = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4o\",\n",
    "        response_format_pydantic=llm.MultiTextualManipulationResponseV02,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "\n",
    "    manipulated_doc: pd.Series = make_manipulated_doc(doc, llm_response.text_new)\n",
    "    manipulated_queries: pd.DataFrame = related_queries.apply(\n",
    "        make_manipulated_query, args=(llm_response.qa_pairs_new,), axis=1\n",
    "    )\n",
    "\n",
    "    if doc_has_been_manipulated & (on_exist == \"override\"):\n",
    "        # delete existing doc and queries\n",
    "        doc_id_new = data_helpers.get_id_for_manipulated_doc_or_query(doc_id, 4)\n",
    "        query_ids_new = [\n",
    "            data_helpers.get_id_for_manipulated_doc_or_query(id, 4)\n",
    "            for id in related_queries[\"query.query_id\"].to_list()\n",
    "        ]\n",
    "        io_helpers.delete_existing_doc_and_queries(doc_id_new, query_ids_new, FILENAME)\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, manipulated_doc)\n",
    "    for _, manipulated_query in manipulated_queries.iterrows():\n",
    "        io_helpers.easy_save_manipulated_query(FILENAME, manipulated_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c739498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_iter = iter(io_helpers.get_documents_to_manipulate(\"multi_textual_manipulation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e64e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with ID '128' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '132' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '133' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '134' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '136' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '205' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '139' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '40' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '42' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '52' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '53' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '183' has been manipulated and saved before. Skipping this one.\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Document with ID '188' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '192' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '65' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '194' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '198' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '199' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '74' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '202' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '204' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '75' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '78' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '79' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '207' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '213' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '214' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '110' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '116' has been manipulated and saved before. Skipping this one.\n"
     ]
    }
   ],
   "source": [
    "# for doc_id in id_iter:\n",
    "#     manipulate_and_save(doc_id, on_exist=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df89dd5",
   "metadata": {},
   "source": [
    "## Generate Keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import importlib\n",
    "from utils import io_helpers, llm\n",
    "\n",
    "importlib.reload(llm)\n",
    "importlib.reload(io_helpers)\n",
    "\n",
    "\n",
    "def keypoints_for_row(data):\n",
    "    question = data[\"query.content\"]\n",
    "    answer = data[\"ground_truth.content\"]\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/keypoints\")\n",
    "    user_prompt = llm.format_user_prompt_keypoints(user_prompt, question=question, answer=answer)\n",
    "\n",
    "    model = \"gpt-4.1\"\n",
    "\n",
    "    response: llm.KeypointsGenerationResponse = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=model,\n",
    "        response_format_pydantic=llm.KeypointsGenerationResponse,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.keypoints\n",
    "\n",
    "\n",
    "def generate_keypoints(queries_path):\n",
    "    queries = pd.read_csv(queries_path, converters={\"ground_truth.keypoints\": ast.literal_eval})\n",
    "    queries[\"ground_truth.keypoints\"] = queries.apply(keypoints_for_row, axis=1)\n",
    "    queries.to_csv(queries_path, index=False)\n",
    "\n",
    "\n",
    "queries = generate_keypoints(\"additional_data/queries/single_textual_manipulations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99758ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>ground_truth.content</th>\n",
       "      <th>ground_truth.doc_ids</th>\n",
       "      <th>ground_truth.keypoints</th>\n",
       "      <th>ground_truth.references</th>\n",
       "      <th>query.content</th>\n",
       "      <th>query.query_id</th>\n",
       "      <th>query.query_type</th>\n",
       "      <th>query.original_query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finance</td>\n",
       "      <td>$250 million.</td>\n",
       "      <td>[100046]</td>\n",
       "      <td>[JetWing Aviation's total liabilities amounted...</td>\n",
       "      <td>[\"Total liabilities for JetWing Aviation amoun...</td>\n",
       "      <td>What was the total amount of JetWing Aviation'...</td>\n",
       "      <td>102856</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finance</td>\n",
       "      <td>Mr. John Doe.</td>\n",
       "      <td>[100071]</td>\n",
       "      <td>[Mr. John Doe was appointed as CEO of ABC Educ...</td>\n",
       "      <td>['In terms of senior management changes, Mr. J...</td>\n",
       "      <td>Who was appointed as CEO of ABC Education Corp...</td>\n",
       "      <td>102538</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medical</td>\n",
       "      <td>Fever, cough, and chest pain for 5 days.</td>\n",
       "      <td>[100208]</td>\n",
       "      <td>[V. Lewis's chief complaint is fever, cough, a...</td>\n",
       "      <td>['Chief Complaint: Fever, cough, and chest pai...</td>\n",
       "      <td>According to the hospitalization records of Ne...</td>\n",
       "      <td>106225</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law</td>\n",
       "      <td>19th July, 1964</td>\n",
       "      <td>[100119]</td>\n",
       "      <td>[H. Walker's birthdate is 19th July, 1964 acco...</td>\n",
       "      <td>['Date of Birth: 19th July, 1964']</td>\n",
       "      <td>According to the court judgment of Riverton, H...</td>\n",
       "      <td>104466</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Law</td>\n",
       "      <td>22, Maple Avenue, Quarryville</td>\n",
       "      <td>[100123]</td>\n",
       "      <td>[The residence of Z. Torres was 22, Maple Aven...</td>\n",
       "      <td>['- Residence: 22, Maple Avenue, Quarryville']</td>\n",
       "      <td>According to the court judgment of Sterling, Q...</td>\n",
       "      <td>104480</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law</td>\n",
       "      <td>Project Manager at Sterling Public Works Depar...</td>\n",
       "      <td>[100111]</td>\n",
       "      <td>[N. Adams was a Project Manager., N. Adams wor...</td>\n",
       "      <td>['- **Occupation:** Project Manager at Sterlin...</td>\n",
       "      <td>According to the court judgment of Brighton, S...</td>\n",
       "      <td>104361</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Law</td>\n",
       "      <td>30th June 2023.</td>\n",
       "      <td>[100113]</td>\n",
       "      <td>[The date of the court judgment was 30th June ...</td>\n",
       "      <td>['Under the provisions of Article 232 and rela...</td>\n",
       "      <td>According to the court judgment of Preston, La...</td>\n",
       "      <td>104411</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Law</td>\n",
       "      <td>25th March 2023</td>\n",
       "      <td>[100122]</td>\n",
       "      <td>[The judgment date was 25th March 2023.]</td>\n",
       "      <td>['**Judgment Issued on 25th March 2023**']</td>\n",
       "      <td>According to the court judgment of Trenton, Va...</td>\n",
       "      <td>104502</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Law</td>\n",
       "      <td>D. Morgan</td>\n",
       "      <td>[100124]</td>\n",
       "      <td>[The defendant in the court judgment of Norwoo...</td>\n",
       "      <td>['- **Defendant Name**: D. Morgan']</td>\n",
       "      <td>According to the court judgment of Norwood, Un...</td>\n",
       "      <td>104490</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Law</td>\n",
       "      <td>Six years of fixed-term imprisonment</td>\n",
       "      <td>[100129]</td>\n",
       "      <td>[G. Torres was sentenced to six years of fixed...</td>\n",
       "      <td>['Consequently, this court sentences G. Torres...</td>\n",
       "      <td>According to the court judgment of Vandalia, B...</td>\n",
       "      <td>104540</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Law</td>\n",
       "      <td>S. Taylor.</td>\n",
       "      <td>[100131]</td>\n",
       "      <td>[The defendant in the court judgment of Rivers...</td>\n",
       "      <td>['**Defendant**: S. Taylor']</td>\n",
       "      <td>According to the court judgment of Riverside, ...</td>\n",
       "      <td>104590</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law</td>\n",
       "      <td>20th May 2023.</td>\n",
       "      <td>[100135]</td>\n",
       "      <td>[The judgment date of the Ashton, Clarksville,...</td>\n",
       "      <td>['**Date of Judgment:**', '20th May 2023']</td>\n",
       "      <td>According to the court judgment of Ashton, Cla...</td>\n",
       "      <td>104600</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Law</td>\n",
       "      <td>One year of fixed-term imprisonment</td>\n",
       "      <td>[100138]</td>\n",
       "      <td>[F. James was sentenced to one year of fixed-t...</td>\n",
       "      <td>['The defendant is hereby sentenced to one yea...</td>\n",
       "      <td>According to the court judgment of Summerville...</td>\n",
       "      <td>104633</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>4633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Medical</td>\n",
       "      <td>Benign Esophageal Stricture.</td>\n",
       "      <td>[100178]</td>\n",
       "      <td>[Q. Reyes's initial diagnosis is Benign Esopha...</td>\n",
       "      <td>['Biopsy confirmed esophageal stricture.', 'Bi...</td>\n",
       "      <td>According to the hospitalization records of Le...</td>\n",
       "      <td>105965</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>5965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Medical</td>\n",
       "      <td>Local redness, swelling, heat, and pain on the...</td>\n",
       "      <td>[100182]</td>\n",
       "      <td>[The patient's chief complaint is local rednes...</td>\n",
       "      <td>['Chief Complaint: Local redness, swelling, he...</td>\n",
       "      <td>According to the hospitalization records of Gr...</td>\n",
       "      <td>106003</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Medical</td>\n",
       "      <td>12.</td>\n",
       "      <td>[100185]</td>\n",
       "      <td>[The patient's age is 12, according to the hos...</td>\n",
       "      <td>['Age: 12']</td>\n",
       "      <td>According to the hospitalization records of Br...</td>\n",
       "      <td>106012</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Medical</td>\n",
       "      <td>Headache and dizziness for 2 weeks.</td>\n",
       "      <td>[100191]</td>\n",
       "      <td>[O. Myers' chief complaint is headache and diz...</td>\n",
       "      <td>['Chief Complaint', 'Headache and dizziness fo...</td>\n",
       "      <td>According to the hospitalization records of Cl...</td>\n",
       "      <td>106076</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Medical</td>\n",
       "      <td>10th, October</td>\n",
       "      <td>[100195]</td>\n",
       "      <td>[The patient was admitted on 10th October acco...</td>\n",
       "      <td>['Admission Time: 10th, October']</td>\n",
       "      <td>According to the hospitalization records of Fa...</td>\n",
       "      <td>106102</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Medical</td>\n",
       "      <td>Shortness of breath and chest pain for 2 months.</td>\n",
       "      <td>[100197]</td>\n",
       "      <td>[O. Richardson's chief complaint is shortness ...</td>\n",
       "      <td>['Chief Complaint:', 'Shortness of breath and ...</td>\n",
       "      <td>According to the hospitalization records of La...</td>\n",
       "      <td>106131</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Medical</td>\n",
       "      <td>42.</td>\n",
       "      <td>[100201]</td>\n",
       "      <td>[The patient's age is 42 according to the hosp...</td>\n",
       "      <td>['Age: 42']</td>\n",
       "      <td>According to the hospitalization records of Pr...</td>\n",
       "      <td>106166</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Medical</td>\n",
       "      <td>66.</td>\n",
       "      <td>[100206]</td>\n",
       "      <td>[O. Price's age is 66 according to the hospita...</td>\n",
       "      <td>['Age: 66']</td>\n",
       "      <td>According to the hospitalization records of Vi...</td>\n",
       "      <td>106206</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Medical</td>\n",
       "      <td>80/min</td>\n",
       "      <td>[100210]</td>\n",
       "      <td>[J. Alvarez's pulse rate is 80 per minute acco...</td>\n",
       "      <td>['Pulse: 80/min']</td>\n",
       "      <td>According to the hospitalization records of Cl...</td>\n",
       "      <td>106251</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>6251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Finance</td>\n",
       "      <td>David Lee</td>\n",
       "      <td>[100041]</td>\n",
       "      <td>[David Lee was appointed as the new Chief Exec...</td>\n",
       "      <td>['Finally, in December 2019, Entertainment Ent...</td>\n",
       "      <td>Who was appointed as the new Chief Executive O...</td>\n",
       "      <td>102574</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Finance</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>[100044]</td>\n",
       "      <td>[Significant ethical or integrity violations o...</td>\n",
       "      <td>['In September 2021, the company faced signifi...</td>\n",
       "      <td>When did significant ethical or integrity viol...</td>\n",
       "      <td>102135</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Finance</td>\n",
       "      <td>$20 million</td>\n",
       "      <td>[100049]</td>\n",
       "      <td>[Capital Finance Group distributed a dividend ...</td>\n",
       "      <td>['In February 2018, the company decided to dis...</td>\n",
       "      <td>How much dividend did Capital Finance Group di...</td>\n",
       "      <td>102962</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Finance</td>\n",
       "      <td>$200 million</td>\n",
       "      <td>[100054]</td>\n",
       "      <td>[HealthPro Innovations raised $200 million in ...</td>\n",
       "      <td>['Firstly, in February 2021, the company condu...</td>\n",
       "      <td>How much funding did HealthPro Innovations rai...</td>\n",
       "      <td>102423</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Finance</td>\n",
       "      <td>DataLink Systems</td>\n",
       "      <td>[100055]</td>\n",
       "      <td>[InnovaTech Solutions acquired DataLink System...</td>\n",
       "      <td>['In April 2017, the company acquired DataLink...</td>\n",
       "      <td>Which company did InnovaTech Solutions acquire...</td>\n",
       "      <td>102636</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Finance</td>\n",
       "      <td>75%</td>\n",
       "      <td>[100062]</td>\n",
       "      <td>[Fabrikon Manufacturing Ltd. acquired 75% equi...</td>\n",
       "      <td>['In May 2021, Fabrikon completed the acquisit...</td>\n",
       "      <td>What percentage of equity did Fabrikon Manufac...</td>\n",
       "      <td>102776</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Finance</td>\n",
       "      <td>December, 2017.</td>\n",
       "      <td>[100067]</td>\n",
       "      <td>[Compliance and regulatory updates were proact...</td>\n",
       "      <td>['In December 2017, SkyQuest Airlines proactiv...</td>\n",
       "      <td>When were compliance and regulatory updates pr...</td>\n",
       "      <td>102867</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Finance</td>\n",
       "      <td>$5.2 billion</td>\n",
       "      <td>[100069]</td>\n",
       "      <td>[The shareholder equity value of Innovate Tech...</td>\n",
       "      <td>[\"The dividend distribution has further streng...</td>\n",
       "      <td>What was the shareholder equity value of Innov...</td>\n",
       "      <td>102498</td>\n",
       "      <td>Factual Question</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     domain                               ground_truth.content  \\\n",
       "0   Finance                                      $250 million.   \n",
       "1   Finance                                      Mr. John Doe.   \n",
       "2   Medical           Fever, cough, and chest pain for 5 days.   \n",
       "3       Law                                    19th July, 1964   \n",
       "4       Law                      22, Maple Avenue, Quarryville   \n",
       "5       Law  Project Manager at Sterling Public Works Depar...   \n",
       "6       Law                                    30th June 2023.   \n",
       "7       Law                                    25th March 2023   \n",
       "8       Law                                          D. Morgan   \n",
       "9       Law               Six years of fixed-term imprisonment   \n",
       "10      Law                                         S. Taylor.   \n",
       "11      Law                                     20th May 2023.   \n",
       "12      Law                One year of fixed-term imprisonment   \n",
       "13  Medical                       Benign Esophageal Stricture.   \n",
       "14  Medical  Local redness, swelling, heat, and pain on the...   \n",
       "15  Medical                                                12.   \n",
       "16  Medical                Headache and dizziness for 2 weeks.   \n",
       "17  Medical                                      10th, October   \n",
       "18  Medical   Shortness of breath and chest pain for 2 months.   \n",
       "19  Medical                                                42.   \n",
       "20  Medical                                                66.   \n",
       "21  Medical                                             80/min   \n",
       "22  Finance                                          David Lee   \n",
       "23  Finance                                     September 2021   \n",
       "24  Finance                                        $20 million   \n",
       "25  Finance                                       $200 million   \n",
       "26  Finance                                   DataLink Systems   \n",
       "27  Finance                                                75%   \n",
       "28  Finance                                    December, 2017.   \n",
       "29  Finance                                       $5.2 billion   \n",
       "\n",
       "   ground_truth.doc_ids                             ground_truth.keypoints  \\\n",
       "0              [100046]  [JetWing Aviation's total liabilities amounted...   \n",
       "1              [100071]  [Mr. John Doe was appointed as CEO of ABC Educ...   \n",
       "2              [100208]  [V. Lewis's chief complaint is fever, cough, a...   \n",
       "3              [100119]  [H. Walker's birthdate is 19th July, 1964 acco...   \n",
       "4              [100123]  [The residence of Z. Torres was 22, Maple Aven...   \n",
       "5              [100111]  [N. Adams was a Project Manager., N. Adams wor...   \n",
       "6              [100113]  [The date of the court judgment was 30th June ...   \n",
       "7              [100122]           [The judgment date was 25th March 2023.]   \n",
       "8              [100124]  [The defendant in the court judgment of Norwoo...   \n",
       "9              [100129]  [G. Torres was sentenced to six years of fixed...   \n",
       "10             [100131]  [The defendant in the court judgment of Rivers...   \n",
       "11             [100135]  [The judgment date of the Ashton, Clarksville,...   \n",
       "12             [100138]  [F. James was sentenced to one year of fixed-t...   \n",
       "13             [100178]  [Q. Reyes's initial diagnosis is Benign Esopha...   \n",
       "14             [100182]  [The patient's chief complaint is local rednes...   \n",
       "15             [100185]  [The patient's age is 12, according to the hos...   \n",
       "16             [100191]  [O. Myers' chief complaint is headache and diz...   \n",
       "17             [100195]  [The patient was admitted on 10th October acco...   \n",
       "18             [100197]  [O. Richardson's chief complaint is shortness ...   \n",
       "19             [100201]  [The patient's age is 42 according to the hosp...   \n",
       "20             [100206]  [O. Price's age is 66 according to the hospita...   \n",
       "21             [100210]  [J. Alvarez's pulse rate is 80 per minute acco...   \n",
       "22             [100041]  [David Lee was appointed as the new Chief Exec...   \n",
       "23             [100044]  [Significant ethical or integrity violations o...   \n",
       "24             [100049]  [Capital Finance Group distributed a dividend ...   \n",
       "25             [100054]  [HealthPro Innovations raised $200 million in ...   \n",
       "26             [100055]  [InnovaTech Solutions acquired DataLink System...   \n",
       "27             [100062]  [Fabrikon Manufacturing Ltd. acquired 75% equi...   \n",
       "28             [100067]  [Compliance and regulatory updates were proact...   \n",
       "29             [100069]  [The shareholder equity value of Innovate Tech...   \n",
       "\n",
       "                              ground_truth.references  \\\n",
       "0   [\"Total liabilities for JetWing Aviation amoun...   \n",
       "1   ['In terms of senior management changes, Mr. J...   \n",
       "2   ['Chief Complaint: Fever, cough, and chest pai...   \n",
       "3                  ['Date of Birth: 19th July, 1964']   \n",
       "4      ['- Residence: 22, Maple Avenue, Quarryville']   \n",
       "5   ['- **Occupation:** Project Manager at Sterlin...   \n",
       "6   ['Under the provisions of Article 232 and rela...   \n",
       "7          ['**Judgment Issued on 25th March 2023**']   \n",
       "8                 ['- **Defendant Name**: D. Morgan']   \n",
       "9   ['Consequently, this court sentences G. Torres...   \n",
       "10                       ['**Defendant**: S. Taylor']   \n",
       "11         ['**Date of Judgment:**', '20th May 2023']   \n",
       "12  ['The defendant is hereby sentenced to one yea...   \n",
       "13  ['Biopsy confirmed esophageal stricture.', 'Bi...   \n",
       "14  ['Chief Complaint: Local redness, swelling, he...   \n",
       "15                                        ['Age: 12']   \n",
       "16  ['Chief Complaint', 'Headache and dizziness fo...   \n",
       "17                  ['Admission Time: 10th, October']   \n",
       "18  ['Chief Complaint:', 'Shortness of breath and ...   \n",
       "19                                        ['Age: 42']   \n",
       "20                                        ['Age: 66']   \n",
       "21                                  ['Pulse: 80/min']   \n",
       "22  ['Finally, in December 2019, Entertainment Ent...   \n",
       "23  ['In September 2021, the company faced signifi...   \n",
       "24  ['In February 2018, the company decided to dis...   \n",
       "25  ['Firstly, in February 2021, the company condu...   \n",
       "26  ['In April 2017, the company acquired DataLink...   \n",
       "27  ['In May 2021, Fabrikon completed the acquisit...   \n",
       "28  ['In December 2017, SkyQuest Airlines proactiv...   \n",
       "29  [\"The dividend distribution has further streng...   \n",
       "\n",
       "                                        query.content  query.query_id  \\\n",
       "0   What was the total amount of JetWing Aviation'...          102856   \n",
       "1   Who was appointed as CEO of ABC Education Corp...          102538   \n",
       "2   According to the hospitalization records of Ne...          106225   \n",
       "3   According to the court judgment of Riverton, H...          104466   \n",
       "4   According to the court judgment of Sterling, Q...          104480   \n",
       "5   According to the court judgment of Brighton, S...          104361   \n",
       "6   According to the court judgment of Preston, La...          104411   \n",
       "7   According to the court judgment of Trenton, Va...          104502   \n",
       "8   According to the court judgment of Norwood, Un...          104490   \n",
       "9   According to the court judgment of Vandalia, B...          104540   \n",
       "10  According to the court judgment of Riverside, ...          104590   \n",
       "11  According to the court judgment of Ashton, Cla...          104600   \n",
       "12  According to the court judgment of Summerville...          104633   \n",
       "13  According to the hospitalization records of Le...          105965   \n",
       "14  According to the hospitalization records of Gr...          106003   \n",
       "15  According to the hospitalization records of Br...          106012   \n",
       "16  According to the hospitalization records of Cl...          106076   \n",
       "17  According to the hospitalization records of Fa...          106102   \n",
       "18  According to the hospitalization records of La...          106131   \n",
       "19  According to the hospitalization records of Pr...          106166   \n",
       "20  According to the hospitalization records of Vi...          106206   \n",
       "21  According to the hospitalization records of Cl...          106251   \n",
       "22  Who was appointed as the new Chief Executive O...          102574   \n",
       "23  When did significant ethical or integrity viol...          102135   \n",
       "24  How much dividend did Capital Finance Group di...          102962   \n",
       "25  How much funding did HealthPro Innovations rai...          102423   \n",
       "26  Which company did InnovaTech Solutions acquire...          102636   \n",
       "27  What percentage of equity did Fabrikon Manufac...          102776   \n",
       "28  When were compliance and regulatory updates pr...          102867   \n",
       "29  What was the shareholder equity value of Innov...          102498   \n",
       "\n",
       "    query.query_type  query.original_query_id  \n",
       "0   Factual Question                     2856  \n",
       "1   Factual Question                     2538  \n",
       "2   Factual Question                     6225  \n",
       "3   Factual Question                     4466  \n",
       "4   Factual Question                     4480  \n",
       "5   Factual Question                     4361  \n",
       "6   Factual Question                     4411  \n",
       "7   Factual Question                     4502  \n",
       "8   Factual Question                     4490  \n",
       "9   Factual Question                     4540  \n",
       "10  Factual Question                     4590  \n",
       "11  Factual Question                     4600  \n",
       "12  Factual Question                     4633  \n",
       "13  Factual Question                     5965  \n",
       "14  Factual Question                     6003  \n",
       "15  Factual Question                     6012  \n",
       "16  Factual Question                     6076  \n",
       "17  Factual Question                     6102  \n",
       "18  Factual Question                     6131  \n",
       "19  Factual Question                     6166  \n",
       "20  Factual Question                     6206  \n",
       "21  Factual Question                     6251  \n",
       "22  Factual Question                     2574  \n",
       "23  Factual Question                     2135  \n",
       "24  Factual Question                     2962  \n",
       "25  Factual Question                     2423  \n",
       "26  Factual Question                     2636  \n",
       "27  Factual Question                     2776  \n",
       "28  Factual Question                     2867  \n",
       "29  Factual Question                     2498  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
