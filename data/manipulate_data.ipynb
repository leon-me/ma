{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6703517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ce678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### static variables\n",
    "\n",
    "COLUMNS_DOCS = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TEXTUAL = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR_ROW = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "    \"query.original_query_id\",\n",
    "    \"ground_truth.content\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_names\",\n",
    "    \"court_names\",\n",
    "    \"hospital_patient_names\",\n",
    "    \"original_doc_ids\",\n",
    "]\n",
    "\n",
    "COLUMNS_QUERIES = [\n",
    "    \"domain\",\n",
    "    \"ground_truth.content\",\n",
    "    \"ground_truth.doc_ids\",\n",
    "    \"ground_truth.keypoints\",\n",
    "    \"ground_truth.references\",\n",
    "    \"language\",\n",
    "    \"prediction\",\n",
    "    \"query.content\",\n",
    "    \"query.query_id\",\n",
    "    \"query.query_type\",\n",
    "]\n",
    "\n",
    "COLUMNS_QUERIES_MANIPULATED = [*COLUMNS_QUERIES, \"query.original_query_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a800bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions/classes for manipulation\n",
    "from typing import Tuple, List, Dict\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "from typing import Literal\n",
    "import sys\n",
    "import json\n",
    "from utils import llm\n",
    "\n",
    "\n",
    "reload(llm)\n",
    "\n",
    "DOCUMENTS = pd.read_csv(\"DRAGONball/en/docs.csv\")\n",
    "QUERIES = pd.read_csv(\n",
    "    \"DRAGONball/en/queries_flattened.csv\",\n",
    "    converters={\n",
    "        \"ground_truth.doc_ids\": ast.literal_eval,\n",
    "        \"ground_truth.keypoints\": ast.literal_eval,\n",
    "        \"ground_truth.references\": ast.literal_eval,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def get_query_ids_for_doc(doc_id: int | str, query_types: list[str] = [\"Factual Question\"]) -> list[int]:\n",
    "    \"\"\"Selects query_ids for queries related to that doc and with a specified type.\"\"\"\n",
    "    return QUERIES[\n",
    "        QUERIES[\"ground_truth.doc_ids\"].apply(lambda doc_ids: int(doc_id) in doc_ids)\n",
    "        & QUERIES[\"query.query_type\"].isin(query_types)\n",
    "    ][\"query.query_id\"].to_list()\n",
    "\n",
    "\n",
    "def get_doc_query_mapping_single(target: Literal[\"textual\", \"tabular\"]) -> List[Dict[str, int]]:\n",
    "    with open(\"doc_query_mapping_single.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [\n",
    "            {\n",
    "                \"doc_id\": int(row[\"doc_id\"]),\n",
    "                \"query_id\": int(row[\"query_id_single\"]) if target == \"textual\" else int(row[\"query_id_multi\"]),\n",
    "            }\n",
    "            for row in reader\n",
    "        ]\n",
    "\n",
    "\n",
    "def get_doc_query_mapping_multi() -> List[Dict]:\n",
    "    with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        doc_ids = [row[\"doc_id\"] for row in reader if int(row[\"multi_textual_manipulation\"]) == 1]\n",
    "    mapping = []\n",
    "    for id in doc_ids:\n",
    "        entry = {\"doc_id\": id, \"query_ids\": get_query_ids_for_doc(id, query_types=[\"Factual Question\"])}\n",
    "        mapping.append(entry)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_query_properties(\n",
    "    query_id,\n",
    "    properties: list = [\"ground_truth.content\", \"ground_truth.keypoints\", \"ground_truth.references\", \"query.content\"],\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for query_id from queries dataframe.\"\"\"\n",
    "    row = QUERIES[QUERIES[\"query.query_id\"] == query_id]\n",
    "    return tuple(row[prop].iloc[0] for prop in properties)\n",
    "\n",
    "\n",
    "def get_doc_properties(\n",
    "    doc_id,\n",
    "    properties,\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for doc_id from docs dataframe.\"\"\"\n",
    "    row: pd.DataFrame = DOCUMENTS[DOCUMENTS[\"doc_id\"] == doc_id].dropna(axis=1)\n",
    "    return tuple(row[prop].iloc[0] for prop in properties if prop in row.columns)\n",
    "\n",
    "\n",
    "def get_doc_text(doc_id: int | str) -> str:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"] == int(doc_id)][\"content\"].iloc[0]\n",
    "\n",
    "\n",
    "def get_query_by_id(query_id: int) -> pd.Series:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int) == query_id].iloc[0]\n",
    "\n",
    "\n",
    "def get_queries_by_id(query_ids: List[int]) -> pd.DataFrame:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int).isin(query_ids)]\n",
    "\n",
    "\n",
    "def get_doc_by_id(doc_id: int | str) -> pd.Series:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"].astype(int) == int(doc_id)].iloc[0]\n",
    "\n",
    "\n",
    "def get_entity_by_doc_id(doc_id: int) -> str:\n",
    "    doc = get_doc_by_id(doc_id)\n",
    "    if isinstance(doc[\"hospital_patient_name\"], str):\n",
    "        return doc[\"hospital_patient_name\"]\n",
    "    if isinstance(doc[\"court_name\"], str):\n",
    "        return doc[\"court_name\"]\n",
    "    if isinstance(doc[\"company_name\"], str):\n",
    "        return doc[\"company_name\"]\n",
    "\n",
    "\n",
    "def get_prompts_for_textual_single(doc_id: int, query_id: int) -> Tuple:\n",
    "    PROMPT_TYPE = \"manipulation_factual\"\n",
    "    prompt = [\n",
    "        prompt for prompt in read_prompt(\"prompts/json/manipulate_docs.json\") if prompt[\"prompt_type\"] == PROMPT_TYPE\n",
    "    ][0]\n",
    "    text = get_doc_text(doc_id)\n",
    "    answer, keypoints, references, question = get_query_properties(query_id)\n",
    "    system_prompt = prompt[\"system_prompt\"]\n",
    "    user_prompt = format_user_prompt_single_textual(\n",
    "        user_prompt=prompt[\"user_prompt\"], text=text, answer=answer, question=question, references=references\n",
    "    )\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_for_tabular_single(query_id: int, doc_id: int) -> Tuple:\n",
    "    prompt_obj = read_prompt(\"prompts/json/manipulation_tabular.json\")\n",
    "    system_prompt = prompt_obj[\"system_prompt\"]\n",
    "    user_prompt = prompt_obj[\"user_prompt\"]\n",
    "    answer, question = get_query_properties(query_id, properties=[\"ground_truth.content\", \"query.content\"])\n",
    "    (entity,) = get_doc_properties(doc_id, [\"hospital_patient_name\", \"company_name\", \"court_name\"])\n",
    "    user_prompt = format_user_prompt_single_tabular(user_prompt, question, answer, entity)\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_for_textual_multi(doc_id: int, query_ids: List[int]) -> Tuple:\n",
    "    prompt_obj = read_prompt(\"../prompts/json/manipulation_multi_textual.json\")\n",
    "    text = get_doc_text(doc_id)\n",
    "    qa_pairs = []\n",
    "    for query_id in query_ids:\n",
    "        question, answer = get_query_properties(query_id, [\"query.content\", \"ground_truth.content\"])\n",
    "        qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    system_prompt = prompt_obj[\"system_prompt\"]\n",
    "    user_prompt = format_user_prompt_multi_textual(user_prompt=prompt_obj[\"user_prompt\"], text=text, qa_pairs=qa_pairs)\n",
    "\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_for_textual_multi_v02(doc_id: int, query_ids: List[int]) -> Tuple:\n",
    "    prompt_obj = read_prompt(\"../prompts/json/manipulations/manipulation_multi_textual_v02.json\")\n",
    "    text = get_doc_text(doc_id)\n",
    "    qa_pairs = []\n",
    "    for query_id in query_ids:\n",
    "        question, answer = get_query_properties(query_id, [\"query.content\", \"ground_truth.content\"])\n",
    "        qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    system_prompt = prompt_obj[\"system_prompt\"]\n",
    "    user_prompt = format_user_prompt_multi_textual(user_prompt=prompt_obj[\"user_prompt\"], text=text, qa_pairs=qa_pairs)\n",
    "\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_id_for_manipulated_doc_or_query(original_doc_id: int, prefix_number=1) -> int:\n",
    "    id_str = str(prefix_number) + str(original_doc_id).zfill(5)\n",
    "    return int(id_str)\n",
    "\n",
    "\n",
    "def save_manipulated_doc(filename: os.PathLike | str, fieldnames: List[str], **kwargs):\n",
    "    \"\"\"Saves a manipulated doc to csv.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        raise RuntimeError(\"Must specify a filename!\")\n",
    "\n",
    "    print(f\"Saving Doc with ID '{kwargs[\"doc_id\"]}'\")\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=fieldnames)\n",
    "            ids_present = {int(row[\"doc_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(kwargs[\"doc_id\"]) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {kwargs[\"doc_id\"]} already exists. Did not write new document to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(kwargs)\n",
    "\n",
    "\n",
    "def save_manipulated_query(filename: os.PathLike | str, fieldnames: List[str], **kwargs):\n",
    "    \"\"\"Saves a manipulated query to csv.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        raise RuntimeError(\"Must specify a filename!\")\n",
    "\n",
    "    print(f\"Saving Query with ID '{kwargs[\"query.query_id\"]}'\")\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=fieldnames)\n",
    "            ids_present = {int(row[\"query.query_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(kwargs[\"query.query_id\"]) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(\n",
    "                f\"WARN: Row with ID {kwargs[\"query.query_id\"]} already exists. Did not write new query to '{filename}'.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ef2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents:\n",
      " Index(['hospital_patient_name', 'language', 'doc_id', 'domain', 'content',\n",
      "       'company_name', 'court_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Queries:\n",
      " Index(['domain', 'ground_truth.content', 'ground_truth.doc_ids',\n",
      "       'ground_truth.keypoints', 'ground_truth.references', 'language',\n",
      "       'prediction', 'query.content', 'query.query_id', 'query.query_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### describe documents and queries\n",
    "\n",
    "print(\"Documents:\\n\", DOCUMENTS.columns)\n",
    "print()\n",
    "print(\"Queries:\\n\", QUERIES.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205f0e4",
   "metadata": {},
   "source": [
    "## Single Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents (textual)\n",
    "def save_single_textual(doc_entry, query_entry, completion_parsed):\n",
    "    # -- doc\n",
    "    original_doc_id = doc_entry.doc_id\n",
    "    manipulated_doc_entry = doc_entry.copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(original_doc_id)\n",
    "    manipulated_doc_entry.content = completion_parsed.text_new\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([original_doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)\n",
    "\n",
    "    # -- query\n",
    "    original_query_id = query_entry[\"query.query_id\"]\n",
    "    manipulated_query_entry = query_entry.copy()\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = completion_parsed.answer_new\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = completion_parsed.references_new\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "    manipulated_query_entry.index = manipulated_query_entry.index.str.replace(\".\", \"__\", regex=False)\n",
    "\n",
    "    save_manipulated_query(**manipulated_query_entry)\n",
    "\n",
    "\n",
    "doc_query_mapping = get_doc_query_mapping_single()\n",
    "\n",
    "for mapping in doc_query_mapping:\n",
    "    doc_id = mapping[\"doc_id\"]\n",
    "    query_id = mapping[\"query_id\"]\n",
    "\n",
    "    doc_entry = get_doc_by_id(doc_id)\n",
    "    query_entry = get_query_by_id(query_id)\n",
    "\n",
    "    system_prompt, user_prompt = get_prompts_for_textual_single(doc_id, query_id)\n",
    "\n",
    "    # call openai\n",
    "    completion_parsed = openai_interface(system_prompt, user_prompt)\n",
    "\n",
    "    save_single_textual(doc_entry, query_entry, completion_parsed)\n",
    "    print(f\"Finished processing doc {doc_id} and query {query_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd70e1",
   "metadata": {},
   "source": [
    "## Single Tabular Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents (tabular) and save rows\n",
    "mapping = get_doc_query_mapping_single(\"tabular\")\n",
    "\n",
    "doc_entries = []\n",
    "\n",
    "for id_pair in mapping:\n",
    "    doc_id = id_pair[\"doc_id\"]\n",
    "    query_id = id_pair[\"query_id\"]\n",
    "    system_prompt, user_prompt = get_prompts_for_tabular_single(query_id, doc_id)\n",
    "\n",
    "    response: SingleTabularManipulationResponse = openai_interface(\n",
    "        system_prompt, user_prompt, SingleTabularManipulationResponse\n",
    "    )\n",
    "\n",
    "    manipulated_doc_entry = get_doc_by_id(doc_id).copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(doc_id, prefix_number=2)\n",
    "    manipulated_doc_entry.content = \" | \".join([response.description, response.value])\n",
    "    additional_fields = pd.Series(\n",
    "        [doc_id, query_id, response.answer_new],\n",
    "        index=[\"original_doc_id\", \"query.original_query_id\", \"ground_truth.content\"],\n",
    "    )\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, additional_fields])\n",
    "\n",
    "    save_manipulated_doc(\n",
    "        filename=\"additional_data/docs/tabular_manipulations_result_rows.csv\",\n",
    "        fieldnames=COLUMNS_DOCS_MANIPULATED_TABULAR_ROW,\n",
    "        **manipulated_doc_entry,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate tabular rows and save docs\n",
    "tabular_docs = pd.read_csv(\"additional_data/docs/tabular_manipulations_result_rows.csv\")\n",
    "\n",
    "\n",
    "def list_or_none(series):\n",
    "    if series.dropna().empty:\n",
    "        return None\n",
    "    return series.tolist()\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    "    \"doc_id\": lambda x: 0,\n",
    "    \"language\": \"first\",\n",
    "    \"content\": \"\\n\".join,\n",
    "    \"company_name\": list_or_none,\n",
    "    \"court_name\": list_or_none,\n",
    "    \"hospital_patient_name\": list_or_none,\n",
    "    \"original_doc_id\": list_or_none,\n",
    "    \"query.original_query_id\": lambda x: None,\n",
    "    \"ground_truth.content\": lambda x: None,\n",
    "}\n",
    "\n",
    "aggregation = tabular_docs.groupby(\"domain\").agg(agg_funcs).reset_index()\n",
    "aggregation[\"doc_id\"] = [get_id_for_manipulated_doc_or_query(id, prefix_number=3) for id in [1, 2, 3]]\n",
    "aggregation.rename(\n",
    "    columns={\n",
    "        \"company_name\": \"company_names\",\n",
    "        \"court_name\": \"court_names\",\n",
    "        \"hospital_patient_name\": \"hospital_patient_names\",\n",
    "        \"original_doc_id\": \"original_doc_ids\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "for row_dict in aggregation.to_dict(orient=\"records\"):\n",
    "    save_manipulated_doc(\n",
    "        \"additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        fieldnames=COLUMNS_DOCS_MANIPULATED_TABULAR,\n",
    "        **row_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d16476",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save manipulated queries for aggregated tabular docs\n",
    "tabular_docs = pd.read_csv(\"additional_data/docs/tabular_manipulations_result_rows.csv\")\n",
    "\n",
    "mapping_domain_doc_id = pd.read_csv(\n",
    "    \"additional_data/docs/tabular_manipulations_result.csv\", usecols=[\"domain\", \"doc_id\"]\n",
    ")\n",
    "mapping_dict = mapping_domain_doc_id.set_index(\"domain\")[\"doc_id\"].to_dict()\n",
    "\n",
    "for row_dict in tabular_docs.to_dict(orient=\"records\"):\n",
    "    original_query_id = row_dict[\"query.original_query_id\"]\n",
    "    manipulated_query_entry = get_query_by_id(original_query_id).copy()\n",
    "\n",
    "    manipulated_query_entry[\"ground_truth.doc_ids\"] = [mapping_dict[row_dict[\"domain\"]]]\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = row_dict[\"ground_truth.content\"]\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = row_dict[\"content\"]\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id, prefix_number=3)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "\n",
    "    save_manipulated_query(\n",
    "        filename=\"additional_data/queries/tabular_manipulations_result.csv\",\n",
    "        fieldnames=COLUMNS_QUERIES_MANIPULATED,\n",
    "        **manipulated_query_entry\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4244b02",
   "metadata": {},
   "source": [
    "## Multi Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4facae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper methods\n",
    "from utils import data_helpers\n",
    "\n",
    "reload(data_helpers)\n",
    "\n",
    "\n",
    "def make_manipulated_query(query, qa_pairs):\n",
    "    manipulated_query = query.copy()\n",
    "    qa_pair = next(\n",
    "        pair for pair in qa_pairs if pair.question.lower().strip() == query[\"query.content\"].lower().strip()\n",
    "    )\n",
    "    manipulated_query.update(\n",
    "        {\n",
    "            \"query.query_id\": data_helpers.get_id_for_manipulated_doc_or_query(query[\"query.query_id\"], 4),\n",
    "            \"ground_truth.content\": qa_pair.answer,\n",
    "            \"ground_truth.references\": [qa_pair.quote],\n",
    "        }\n",
    "    )\n",
    "    manipulated_query[\"query.original_query_id\"] = query[\"query.query_id\"]\n",
    "    return manipulated_query\n",
    "\n",
    "\n",
    "def make_manipulated_doc(doc: pd.Series, text_new: str):\n",
    "    manipulated_doc = doc.copy()\n",
    "    manipulated_doc.update(\n",
    "        {\n",
    "            \"doc_id\": data_helpers.get_id_for_manipulated_doc_or_query(doc[\"doc_id\"], 4),\n",
    "            \"content\": text_new,\n",
    "        }\n",
    "    )\n",
    "    manipulated_doc[\"original_doc_ids\"] = [doc[\"doc_id\"]]\n",
    "    return manipulated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e4c545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with ID '128' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '132' has been manipulated and saved before. Skipping this one.\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n"
     ]
    }
   ],
   "source": [
    "### Test multi manipulation prompts\n",
    "from utils import io_helpers, data_helpers\n",
    "\n",
    "FILENAME = \"multi_textual_manipulations\"\n",
    "\n",
    "reload(io_helpers)\n",
    "reload(data_helpers)\n",
    "reload(llm)\n",
    "\n",
    "documents = io_helpers.get_documents()\n",
    "queries = io_helpers.get_queries()\n",
    "\n",
    "\n",
    "doc_ids = io_helpers.get_documents_to_manipulate(\"multi_textual_manipulation\")\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    if io_helpers.file_has_been_manipulated(\n",
    "        \"doc\", FILENAME, data_helpers.get_id_for_manipulated_doc_or_query(doc_id, 4)\n",
    "    ):\n",
    "        print(f\"Document with ID '{doc_id}' has been manipulated and saved before. Skipping this one.\")\n",
    "        continue\n",
    "    doc: pd.Series = get_doc_by_id(doc_id)\n",
    "    entity = get_entity_by_doc_id(doc_id)\n",
    "    text = doc[\"content\"]\n",
    "\n",
    "    related_queries: pd.DataFrame = data_helpers.get_queries_by_doc_id(doc_id, queries)\n",
    "    qa_pairs = data_helpers.make_qa_pairs(related_queries)\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_multi_textual_v03\")\n",
    "    user_prompt = llm.format_user_prompt_multi_textual_v02(user_prompt, entity, text, qa_pairs)\n",
    "\n",
    "    llm_response: llm.MultiTextualManipulationResponseV02 = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4o\",\n",
    "        response_format_pydantic=llm.MultiTextualManipulationResponseV02,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "\n",
    "    manipulated_doc: pd.Series = make_manipulated_doc(doc, llm_response.text_new)\n",
    "    manipulated_queries: pd.DataFrame = related_queries.apply(\n",
    "        make_manipulated_query, args=(llm_response.qa_pairs_new,), axis=1\n",
    "    )\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, manipulated_doc)\n",
    "    for _, manipulated_query in manipulated_queries.iterrows():\n",
    "        io_helpers.easy_save_manipulated_query(FILENAME, manipulated_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
