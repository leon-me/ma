{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6703517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import ast\n",
    "import importlib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205f0e4",
   "metadata": {},
   "source": [
    "## Single Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import io_helpers, data_helpers, llm\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "\n",
    "FILENAME = \"single_textual_manipulations\"\n",
    "\n",
    "doc_ids = io_helpers.get_documents_to_manipulate(\"single_textual_manipulation\")\n",
    "doc_query_mapping: pd.DataFrame = io_helpers.get_doc_query_mapping(\"textual\")\n",
    "\n",
    "if len(set(doc_ids).symmetric_difference(set(doc_query_mapping[\"doc_id\"]))) > 0:\n",
    "    raise RuntimeError(\"Doc IDs don't match!\")\n",
    "\n",
    "documents = io_helpers.get_documents()\n",
    "queries = io_helpers.get_queries()\n",
    "\n",
    "\n",
    "def execute_manipulation(df_row):\n",
    "    doc_id = df_row[\"doc_id\"]\n",
    "    query_id = df_row[\"query_id\"]\n",
    "\n",
    "    doc_id_new = data_helpers.get_id_for_manipulated_doc_or_query(doc_id, prefix_number=1)\n",
    "    query_id_new = data_helpers.get_id_for_manipulated_doc_or_query(query_id, prefix_number=1)\n",
    "\n",
    "    if io_helpers.file_has_been_manipulated(\"doc\", FILENAME, doc_id_new) or io_helpers.file_has_been_manipulated(\n",
    "        \"query\", FILENAME, query_id_new\n",
    "    ):\n",
    "        print(f\"Doc with ID '{doc_id} has been manipulated before.\")\n",
    "        return None\n",
    "\n",
    "    doc_entry = documents.loc[documents[\"doc_id\"] == doc_id].squeeze()\n",
    "    query_entry = queries.loc[queries[\"query.query_id\"] == query_id].squeeze()\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_single_textual\")\n",
    "    user_prompt = llm.format_user_prompt_single_textual(\n",
    "        user_prompt,\n",
    "        text=doc_entry[\"content\"],\n",
    "        question=query_entry[\"query.content\"],\n",
    "        answer=query_entry[\"ground_truth.content\"],\n",
    "        references=query_entry[\"ground_truth.references\"],\n",
    "    )\n",
    "    response = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4.1\",\n",
    "        response_format_pydantic=llm.SingleTextualManipulationResponse,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    doc_entry_new = doc_entry.copy()\n",
    "    doc_entry_new.update({\"doc_id\": doc_id_new, \"content\": response.text_new})\n",
    "    doc_entry_new[\"original_doc_ids\"] = [doc_id]\n",
    "\n",
    "    query_entry_new = query_entry.copy()\n",
    "    query_entry_new.update(\n",
    "        {\n",
    "            \"query.query_id\": query_id_new,\n",
    "            \"ground_truth.content\": response.answer_new,\n",
    "            \"ground_truth.doc_ids\": [doc_id_new],\n",
    "            \"ground_truth.references\": response.references_new,\n",
    "            \"ground_truth.keypoints\": [],\n",
    "        }\n",
    "    )\n",
    "    query_entry_new[\"query.original_query_id\"] = query_id\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, doc_entry_new)\n",
    "    io_helpers.easy_save_manipulated_query(FILENAME, query_entry_new)\n",
    "\n",
    "\n",
    "# _ = doc_query_mapping.apply(func=execute_manipulation, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd70e1",
   "metadata": {},
   "source": [
    "## Single Tabular Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manipulate documents and save rows and queries\n",
    "from utils import io_helpers, data_helpers, llm\n",
    "\n",
    "importlib.reload(io_helpers)\n",
    "FILENAME = \"single_tabular_manipulations_rows\"\n",
    "\n",
    "DOMAIN_TO_ID = {\"Medical\": 300001, \"Finance\": 300002, \"Law\": 300003}\n",
    "\n",
    "doc_ids = io_helpers.get_documents_to_manipulate(\"single_tabular_manipulation\")\n",
    "doc_query_mapping: pd.DataFrame = io_helpers.get_doc_query_mapping(\"tabular\")\n",
    "\n",
    "if len(set(doc_ids).symmetric_difference(set(doc_query_mapping[\"doc_id\"]))) > 0:\n",
    "    raise RuntimeError(\"Doc IDs don't match!\")\n",
    "\n",
    "documents = io_helpers.get_documents()\n",
    "queries = io_helpers.get_queries()\n",
    "\n",
    "\n",
    "new_documents = pd.DataFrame()\n",
    "\n",
    "\n",
    "def execute_manipulation(df_row):\n",
    "    doc_id = df_row[\"doc_id\"]\n",
    "    query_id = df_row[\"query_id\"]\n",
    "\n",
    "    doc_entry = documents.loc[documents[\"doc_id\"] == doc_id].squeeze()\n",
    "    query_entry = queries.loc[queries[\"query.query_id\"] == query_id].squeeze()\n",
    "\n",
    "    doc_id_new = DOMAIN_TO_ID[doc_entry[\"domain\"]]\n",
    "    query_id_new = data_helpers.get_id_for_manipulated_doc_or_query(query_id, prefix_number=3)\n",
    "\n",
    "    if io_helpers.file_has_been_manipulated(\"query\", \"single_tabular_manipulations\", query_id_new):\n",
    "        print(f\"Doc with ID '{doc_id} has been manipulated before.\")\n",
    "        return None\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_single_tabular\")\n",
    "    entity = data_helpers.get_entity_by_doc_id(doc_id, documents)\n",
    "    user_prompt = llm.format_user_prompt_single_tabular(\n",
    "        user_prompt=user_prompt,\n",
    "        question=query_entry[\"query.content\"],\n",
    "        answer=query_entry[\"ground_truth.content\"],\n",
    "        entity=entity,\n",
    "    )\n",
    "\n",
    "    response: llm.SingleTabularManipulationResponse = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4o\",\n",
    "        response_format_pydantic=llm.SingleTabularManipulationResponse,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    reference = f\"{response.description} | {response.value}\"\n",
    "\n",
    "    doc_entry_new = doc_entry.copy()\n",
    "    doc_entry_new.update({\"doc_id\": doc_id_new, \"content\": reference})\n",
    "    doc_entry_new[\"original_doc_ids\"] = [doc_id]\n",
    "\n",
    "    query_entry_new = query_entry.copy()\n",
    "    query_entry_new.update(\n",
    "        {\n",
    "            \"query.query_id\": query_id_new,\n",
    "            \"ground_truth.content\": response.answer_new,\n",
    "            \"ground_truth.doc_ids\": [doc_id_new],\n",
    "            \"ground_truth.references\": [reference],\n",
    "            \"ground_truth.keypoints\": [],\n",
    "        }\n",
    "    )\n",
    "    query_entry_new[\"query.original_query_id\"] = query_id\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, doc_entry_new)\n",
    "    io_helpers.easy_save_manipulated_query(\"single_tabular_manipulations\", query_entry_new)\n",
    "\n",
    "\n",
    "_ = doc_query_mapping.apply(func=execute_manipulation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83fa5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate tabular rows and save docs\n",
    "import ast\n",
    "\n",
    "tabular_docs = pd.read_csv(\n",
    "    \"additional_data/docs/single_tabular_manipulations_rows.csv\", converters={\"original_doc_ids\": ast.literal_eval}\n",
    ")\n",
    "\n",
    "\n",
    "def to_list(series):\n",
    "    if series.dropna().empty:\n",
    "        return []\n",
    "    return series.tolist()\n",
    "\n",
    "\n",
    "def flatten_lists(series):\n",
    "    return [item for sublist in series if isinstance(sublist, list) for item in sublist]\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    "    \"doc_id\": \"first\",\n",
    "    \"content\": \"\\n\".join,\n",
    "    \"company_name\": to_list,\n",
    "    \"court_name\": to_list,\n",
    "    \"hospital_patient_name\": to_list,\n",
    "    \"original_doc_ids\": flatten_lists,\n",
    "}\n",
    "\n",
    "aggregation = tabular_docs.groupby(\"domain\").agg(agg_funcs).reset_index()\n",
    "aggregation.rename(\n",
    "    columns={\n",
    "        \"company_name\": \"company_names\",\n",
    "        \"court_name\": \"court_names\",\n",
    "        \"hospital_patient_name\": \"hospital_patient_names\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "aggregation.to_csv(\"additional_data/docs/single_tabular_manipulations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4244b02",
   "metadata": {},
   "source": [
    "## Multi Textual Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4facae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### helper methods\n",
    "from utils import data_helpers\n",
    "\n",
    "reload(data_helpers)\n",
    "\n",
    "\n",
    "def make_manipulated_query(query, qa_pairs):\n",
    "    manipulated_query = query.copy()\n",
    "    qa_pair = next(\n",
    "        pair for pair in qa_pairs if pair.question.lower().strip() == query[\"query.content\"].lower().strip()\n",
    "    )\n",
    "    manipulated_query.update(\n",
    "        {\n",
    "            \"query.query_id\": data_helpers.get_id_for_manipulated_doc_or_query(query[\"query.query_id\"], 4),\n",
    "            \"ground_truth.content\": qa_pair.answer,\n",
    "            \"ground_truth.references\": [qa_pair.quote],\n",
    "        }\n",
    "    )\n",
    "    manipulated_query[\"query.original_query_id\"] = query[\"query.query_id\"]\n",
    "    return manipulated_query\n",
    "\n",
    "\n",
    "def make_manipulated_doc(doc: pd.Series, text_new: str):\n",
    "    manipulated_doc = doc.copy()\n",
    "    manipulated_doc.update(\n",
    "        {\n",
    "            \"doc_id\": data_helpers.get_id_for_manipulated_doc_or_query(doc[\"doc_id\"], 4),\n",
    "            \"content\": text_new,\n",
    "        }\n",
    "    )\n",
    "    manipulated_doc[\"original_doc_ids\"] = [doc[\"doc_id\"]]\n",
    "    return manipulated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8e4c545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulate and save\n",
    "from utils import io_helpers, data_helpers, llm\n",
    "from importlib import reload\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "\n",
    "FILENAME = \"multi_textual_manipulations\"\n",
    "\n",
    "reload(io_helpers)\n",
    "reload(data_helpers)\n",
    "reload(llm)\n",
    "\n",
    "\n",
    "# for doc_id in doc_ids:\n",
    "def manipulate_and_save(doc_id: int, on_exist: Literal[\"skip\", \"override\"] = \"skip\"):\n",
    "    documents = io_helpers.get_documents()\n",
    "    queries = io_helpers.get_queries()\n",
    "\n",
    "    doc_has_been_manipulated = io_helpers.file_has_been_manipulated(\n",
    "        \"doc\", FILENAME, data_helpers.get_id_for_manipulated_doc_or_query(doc_id, 4)\n",
    "    )\n",
    "    if doc_has_been_manipulated & (on_exist == \"skip\"):\n",
    "        print(f\"Document with ID '{doc_id}' has been manipulated and saved before. Skipping this one.\")\n",
    "        return\n",
    "\n",
    "    doc: pd.Series = data_helpers.get_doc_by_id(doc_id, documents)\n",
    "    entity = data_helpers.get_entity_by_doc_id(doc_id, documents)\n",
    "    text = doc[\"content\"]\n",
    "\n",
    "    related_queries: pd.DataFrame = data_helpers.get_queries_by_doc_id(doc_id, queries)\n",
    "    qa_pairs = data_helpers.make_qa_pairs(related_queries)\n",
    "\n",
    "    system_prompt, user_prompt = io_helpers.get_prompt(\"manipulations/manipulation_multi_textual_v03\")\n",
    "    user_prompt = llm.format_user_prompt_multi_textual_v02(user_prompt, entity, text, qa_pairs)\n",
    "\n",
    "    llm_response: llm.MultiTextualManipulationResponseV02 = llm.call_openai(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        model=\"gpt-4o\",\n",
    "        response_format_pydantic=llm.MultiTextualManipulationResponseV02,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "\n",
    "    manipulated_doc: pd.Series = make_manipulated_doc(doc, llm_response.text_new)\n",
    "    manipulated_queries: pd.DataFrame = related_queries.apply(\n",
    "        make_manipulated_query, args=(llm_response.qa_pairs_new,), axis=1\n",
    "    )\n",
    "\n",
    "    if doc_has_been_manipulated & (on_exist == \"override\"):\n",
    "        # delete existing doc and queries\n",
    "        doc_id_new = data_helpers.get_id_for_manipulated_doc_or_query(doc_id, 4)\n",
    "        query_ids_new = [\n",
    "            data_helpers.get_id_for_manipulated_doc_or_query(id, 4)\n",
    "            for id in related_queries[\"query.query_id\"].to_list()\n",
    "        ]\n",
    "        io_helpers.delete_existing_doc_and_queries(doc_id_new, query_ids_new, FILENAME)\n",
    "\n",
    "    io_helpers.easy_save_manipulated_doc(FILENAME, manipulated_doc)\n",
    "    for _, manipulated_query in manipulated_queries.iterrows():\n",
    "        io_helpers.easy_save_manipulated_query(FILENAME, manipulated_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c739498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_iter = iter(io_helpers.get_documents_to_manipulate(\"multi_textual_manipulation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e64e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with ID '128' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '132' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '133' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '134' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '136' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '205' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '139' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '40' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '42' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '52' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '53' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '183' has been manipulated and saved before. Skipping this one.\n",
      "Saved document to 'additional_data/docs/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Saved Query to 'additional_data/queries/multi_textual_manipulations.csv'\n",
      "Document with ID '188' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '192' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '65' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '194' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '198' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '199' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '74' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '202' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '204' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '75' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '78' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '79' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '207' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '213' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '214' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '110' has been manipulated and saved before. Skipping this one.\n",
      "Document with ID '116' has been manipulated and saved before. Skipping this one.\n"
     ]
    }
   ],
   "source": [
    "# for doc_id in id_iter:\n",
    "#     manipulate_and_save(doc_id, on_exist=\"skip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
