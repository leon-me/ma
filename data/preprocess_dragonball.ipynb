{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff863d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "#\n",
    "# --- Process Documents ---\n",
    "#\n",
    "\n",
    "# Set your file paths\n",
    "input_file = \"data/dragonball/jsonl/dragonball_docs.jsonl\"\n",
    "output_file = \"data/dragonball/docs_en.csv\"\n",
    "\n",
    "data = []\n",
    "field_names = set()\n",
    "\n",
    "# Read the JSONL file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        obj = json.loads(line)\n",
    "        if obj[\"language\"] == \"en\":\n",
    "            data.append(obj)\n",
    "            field_names.update(obj.keys())\n",
    "            # field_names |= obj.keys() # same effect like line above\n",
    "\n",
    "# Write to CSV\n",
    "if data:\n",
    "    with open(output_file, \"x\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "else:\n",
    "    print(\"No data found in the input file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbe814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "#\n",
    "# --- Process Queries ---\n",
    "#\n",
    "\n",
    "\n",
    "# Set your file paths\n",
    "input_file = \"data/dragonball/jsonl/dragonball_queries.jsonl\"\n",
    "output_file = \"data/dragonball/queries_en.csv\"\n",
    "\n",
    "data = []\n",
    "field_names = set()\n",
    "\n",
    "# Read the JSONL file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        obj = json.loads(line)\n",
    "        if obj[\"language\"] == \"en\":\n",
    "            data.append(obj)\n",
    "            field_names.update(obj.keys())\n",
    "            # field_names |= obj.keys() # same effect like line above\n",
    "\n",
    "# Write to CSV\n",
    "if data:\n",
    "    with open(output_file, \"x\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "else:\n",
    "    print(\"No data found in the input file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# --- Flatten Queries ---\n",
    "#\n",
    "\n",
    "\n",
    "# Set your file paths\n",
    "input_file = \"data/dragonball/jsonl/dragonball_queries.jsonl\"\n",
    "output_file = \"data/dragonball/queries_en_flattened.csv\"\n",
    "\n",
    "data = []\n",
    "field_names = set()\n",
    "\n",
    "# Read the JSONL file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        obj = json.loads(line)\n",
    "        if obj[\"language\"] != \"en\":\n",
    "            continue\n",
    "\n",
    "        # get nested json objects and remove\n",
    "        gt_json = obj.pop(\"ground_truth\")\n",
    "        query_json = obj.pop(\"query\")\n",
    "\n",
    "        # insert flattened objects into high-level json\n",
    "        for key, value in gt_json.items():\n",
    "            obj[f\"ground_truth.{key}\"] = value\n",
    "        for key, value in query_json.items():\n",
    "            obj[f\"query.{key}\"] = value\n",
    "\n",
    "        data.append(obj)\n",
    "        field_names.update(obj.keys())\n",
    "        # field_names |= obj.keys() # same effect like line above\n",
    "\n",
    "# Write to CSV\n",
    "if data:\n",
    "    field_names_list = list(field_names)\n",
    "    field_names_list.sort()\n",
    "    with open(output_file, \"x\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names_list)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "else:\n",
    "    print(\"No data found in the input file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190567c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# --- add token count to docs ---\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "# Load the tokenizer. Encoding for gpt-4.1-mini is not yet released but is likely to be \"o200k_base\"\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"data/dragonball/en/docs.csv\")\n",
    "\n",
    "\n",
    "# Tokenize each row in the 'content' column\n",
    "df[\"num_tokens\"] = (\n",
    "    df[\"content\"].astype(str).apply(lambda x: encoding.encode(x)).apply(len)\n",
    ")\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(\"data/dragonball/en/docs_with_tokens.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
