{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f6c8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import ast\n",
    "import os\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b738f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions\n",
    "DOCUMENTS = pd.read_csv(\"DRAGONball/en/docs.csv\")\n",
    "QUERIES = pd.read_csv(\n",
    "    \"DRAGONball/en/queries_flattened.csv\",\n",
    "    converters={\n",
    "        \"ground_truth.doc_ids\": ast.literal_eval,\n",
    "        \"ground_truth.keypoints\": ast.literal_eval,\n",
    "        \"ground_truth.references\": ast.literal_eval,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def get_query_ids_for_doc(doc_id: int, query_types: list[str] = [\"Factual Question\"]) -> list[int]:\n",
    "    \"\"\"Selects query_ids for queries related to that doc and with a specified type.\"\"\"\n",
    "    return QUERIES[\n",
    "        QUERIES[\"ground_truth.doc_ids\"].apply(lambda doc_ids: int(doc_id) in doc_ids)\n",
    "        & QUERIES[\"query.query_type\"].isin(query_types)\n",
    "    ][\"query.query_id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0628e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"docs_to_manipulate.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d43579b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to sample new IDs\n"
     ]
    }
   ],
   "source": [
    "### Select docs and queries to manipulate\n",
    "\n",
    "NUM_SINGLE_TEXTUAL = 30\n",
    "NUM_SINGLE_TABULAR = 30  # must be less or equal to NUM_SINGLE_TEXTUAL\n",
    "NUM_MULTI_TEXTUAL = 30\n",
    "\n",
    "FIELDNAMES = [\n",
    "    \"doc_id\",\n",
    "    \"single_textual_manipulation\",\n",
    "    \"single_tabular_manipulation\",\n",
    "    \"multi_textual_manipulation\",\n",
    "]\n",
    "\n",
    "ids_by_domain = {}\n",
    "for row in DOCUMENTS.itertuples(index=False):\n",
    "    new_list = ids_by_domain.get(row.domain, [])\n",
    "    new_list.append(row.doc_id)\n",
    "    ids_by_domain[row.domain] = new_list\n",
    "\n",
    "ids = {\"single_textual\": [], \"single_tabular\": [], \"multi_textual\": [], \"all\": set()}\n",
    "\n",
    "try:\n",
    "    with open(FILENAME, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = [row for row in reader]\n",
    "        ids[\"single_textual\"] = [\n",
    "            int(row[\"doc_id\"]) for row in rows if row[\"single_textual_manipulation\"] != \"0\"\n",
    "        ]\n",
    "        ids[\"single_tabular\"] = [\n",
    "            int(row[\"doc_id\"]) for row in rows if row[\"single_tabular_manipulation\"] != \"0\"\n",
    "        ]\n",
    "        ids[\"multi_textual\"] = [int(row[\"doc_id\"]) for row in rows if row[\"multi_textual_manipulation\"] != \"0\"]\n",
    "        ids[\"all\"] = set(ids[\"single_textual\"]) | set(ids[\"single_tabular\"]) | set(ids[\"multi_textual\"])\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File '{e.filename}' not found. Will be created.\")\n",
    "    pass\n",
    "\n",
    "skip_sampling = False\n",
    "if (len(ids[\"single_textual\"]) >= NUM_SINGLE_TEXTUAL) and (len(ids[\"single_tabular\"]) >= NUM_SINGLE_TABULAR) and (len(ids[\"multi_textual\"]) >= NUM_MULTI_TEXTUAL):\n",
    "    print(\"No need to sample new IDs\")\n",
    "    skip_sampling = True\n",
    "\n",
    "def sample_new_doc_ids(num_ids: int, existing_ids: List[int], sample_for_tabular: bool = False) -> List[int]:\n",
    "    if len(existing_ids) < num_ids:\n",
    "        k = num_ids - len(existing_ids)\n",
    "        domains = {0: \"Finance\", 1: \"Medical\", 2: \"Law\"}\n",
    "        while k > 0:\n",
    "            i = k % 3\n",
    "            candidates = set(ids_by_domain[domains[i]]) - ids[\"all\"]\n",
    "            if sample_for_tabular:\n",
    "                candidates = set(ids[\"single_textual\"]) - set(ids[\"single_tabular\"])\n",
    "            if len(candidates) == 0:\n",
    "                error_message = f\"No candidate doc_ids left for domain {domains[i]}.\"\n",
    "                raise RuntimeError(error_message)\n",
    "            choice = random.sample(sorted(candidates), 1)[0]\n",
    "            existing_ids.append(choice)\n",
    "            ids[\"all\"].add(choice)\n",
    "            k = num_ids - len(existing_ids)\n",
    "    return existing_ids\n",
    "\n",
    "if skip_sampling == False:\n",
    "    ids[\"single_textual\"] = sample_new_doc_ids(num_ids=NUM_SINGLE_TEXTUAL, existing_ids=ids[\"single_textual\"])\n",
    "    ids[\"single_tabular\"] = sample_new_doc_ids(\n",
    "        num_ids=NUM_SINGLE_TABULAR, existing_ids=ids[\"single_tabular\"], sample_for_tabular=True\n",
    "    )\n",
    "    ids[\"multi_textual\"] = sample_new_doc_ids(num_ids=NUM_MULTI_TEXTUAL, existing_ids=ids[\"multi_textual\"])\n",
    "\n",
    "    for key in list(ids):\n",
    "        print(f\"{key}: {len(ids[key])}\")\n",
    "\n",
    "    print(f\"Available: {len(set(DOCUMENTS[\"doc_id\"].to_list()) - ids[\"all\"])}\")\n",
    "\n",
    "    with open(FILENAME, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=FIELDNAMES, extrasaction=\"ignore\")\n",
    "        writer.writeheader()\n",
    "        for id in ids[\"all\"]:\n",
    "            row = {\n",
    "                \"doc_id\": id,\n",
    "                \"single_textual_manipulation\": 1 if id in ids[\"single_textual\"] else 0,\n",
    "                \"single_tabular_manipulation\": 1 if id in ids[\"single_tabular\"] else 0,\n",
    "                \"multi_textual_manipulation\": 1 if id in ids[\"multi_textual\"] else 0,\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6efb00cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'doc_query_mapping_single.csv' exists. Did nothing\n"
     ]
    }
   ],
   "source": [
    "### Create doc-query mapping forsingle_textual & single_tabular\n",
    "\n",
    "doc_ids_to_manipulate = []\n",
    "with open(FILENAME, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    doc_ids_to_manipulate = [row for row in reader if int(row[\"single_textual_manipulation\"]) == 1 or int(row[\"single_tabular_manipulation\"]) == 1]\n",
    "\n",
    "FIELDNAMES = [\"doc_id\", \"query_id_textual_manipulation\", \"query_id_tabular_manipulation\"]\n",
    "\n",
    "# with open(\"doc_query_mapping.csv\", \"r\", newline=\"\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     doc_queries_mapping = [row for row in reader]\n",
    "\n",
    "mappings = []\n",
    "\n",
    "for id_with_manipulation_type in doc_ids_to_manipulate:\n",
    "    options = get_query_ids_for_doc(id_with_manipulation_type[\"doc_id\"], query_types=[\"Factual Question\"])\n",
    "    try:\n",
    "        query_ids = random.sample(options, 2)\n",
    "    except ValueError:\n",
    "        print(f\"Only {len(options)} options found for doc_id '{id_with_manipulation_type[\"doc_id\"]}'\")\n",
    "\n",
    "    doc_queries_mapping = {\n",
    "        \"doc_id\": id_with_manipulation_type[\"doc_id\"],\n",
    "        \"query_id_textual_manipulation\": query_ids[0],\n",
    "        \"query_id_tabular_manipulation\": query_ids[1]\n",
    "    }\n",
    "    mappings.append(doc_queries_mapping)\n",
    "\n",
    "mappings.sort(key=lambda x: x[\"doc_id\"])\n",
    "\n",
    "try:\n",
    "    with open(\"doc_query_mapping_single.csv\", \"x\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(mappings)\n",
    "except FileExistsError as e:\n",
    "    print(f\"File '{e.filename}' exists. Did nothing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
