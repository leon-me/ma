{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38682486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original docs: 108\n",
      "# manipulated textual docs: 30\n",
      "# manipulated tabular docs: 3\n",
      "# manipulated textual multi docs: 30\n"
     ]
    }
   ],
   "source": [
    "### helper functions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_documents(print_info: bool = False) -> pd.DataFrame:\n",
    "    docs_original = pd.read_csv(\"data/DRAGONball/en/docs.csv\", usecols=[\"doc_id\", \"domain\", \"content\"])\n",
    "    docs_manipulated_single_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/textual_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    docs_manipulated_single_textual[\"original_doc_id\"] = docs_manipulated_single_textual[\"original_doc_id\"].apply(\n",
    "        lambda i: [i] if pd.notna(i) else []\n",
    "    )\n",
    "    docs_manipulated_single_textual.rename(columns={\"original_doc_id\": \"original_doc_ids\"}, inplace=True)\n",
    "\n",
    "    docs_manipulated_single_tabular = pd.read_csv(\n",
    "        \"data/additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_ids\"],\n",
    "        converters={\"original_doc_ids\": ast.literal_eval},\n",
    "    )\n",
    "\n",
    "    docs_manipulated_multi_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/multi_textual_manipulations.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    docs_manipulated_multi_textual[\"original_doc_id\"] = docs_manipulated_multi_textual[\"original_doc_id\"].apply(\n",
    "        lambda i: [i] if pd.notna(i) else []\n",
    "    )\n",
    "    docs_manipulated_multi_textual.rename(columns={\"original_doc_id\": \"original_doc_ids\"}, inplace=True)\n",
    "\n",
    "    if print_info == True:\n",
    "        print(f\"# original docs: {len(docs_original)}\")\n",
    "        print(f\"# manipulated textual docs: {len(docs_manipulated_single_textual)}\")\n",
    "        print(f\"# manipulated tabular docs: {len(docs_manipulated_single_tabular)}\")\n",
    "        print(f\"# manipulated textual multi docs: {len(docs_manipulated_multi_textual)}\")\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            docs_original,\n",
    "            docs_manipulated_single_textual,\n",
    "            docs_manipulated_multi_textual,\n",
    "            docs_manipulated_single_tabular,\n",
    "        ],\n",
    "        sort=False,\n",
    "    )\n",
    "\n",
    "\n",
    "documents = get_documents(print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2277b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get embeddings\n",
    "from openai import OpenAI, RateLimitError\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, retry_if_exception_type, wait_random, stop_after_attempt\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "FILEPATH = \"data/additional_data/docs/embeddings.csv\"\n",
    "FIELDNAMES = [\"doc_id\", \"content\", \"embedding\"]\n",
    "\n",
    "\n",
    "def get_embeddings(input: str) -> List[float]:\n",
    "    print(\"DEBUG: Getting embedding from OpenAI\")\n",
    "    embedding = client.embeddings.create(model=\"text-embedding-3-small\", input=input, encoding_format=\"float\")\n",
    "    print(f\"DEBUG: Got embedding. Usage: {embedding.usage.total_tokens} total tokens.\")\n",
    "    return embedding.data[0].embedding\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type(RateLimitError),\n",
    "    wait=wait_random(min=30, max=60),\n",
    "    stop=stop_after_attempt(6),\n",
    ")\n",
    "def get_and_save_emebeddings(row) -> None:\n",
    "    docs_processed = pd.read_csv(FILEPATH, usecols=[\"doc_id\"])[\"doc_id\"].to_list()\n",
    "    if row[\"doc_id\"] in docs_processed:\n",
    "        print(f\"Doc with ID '{row[\"doc_id\"]}' has been processed before.\")\n",
    "        return \n",
    "    \n",
    "    embedding = get_embeddings(row[\"content\"])\n",
    "    with open(FILEPATH, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n",
    "        writer.writerow({\n",
    "            \"doc_id\": row[\"doc_id\"],\n",
    "            \"content\": row[\"content\"],\n",
    "            \"embedding\": embedding\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fab41fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc with ID '40' has been processed before.\n",
      "Doc with ID '41' has been processed before.\n",
      "Doc with ID '42' has been processed before.\n",
      "Doc with ID '43' has been processed before.\n",
      "Doc with ID '44' has been processed before.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1664 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2776 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1749 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2033 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1704 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1958 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2672 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2242 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1714 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2005 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1780 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1735 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1820 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1816 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1673 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2196 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1807 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1958 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1825 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2185 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1809 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1776 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1931 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1466 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1507 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2523 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2009 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1641 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2190 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1287 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1718 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1913 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2344 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1959 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2207 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2076 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2435 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2182 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1516 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1616 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1703 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2068 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2208 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1900 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1475 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1599 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1700 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1610 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1916 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2188 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1652 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2006 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1506 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1575 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1719 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1418 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2332 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1765 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1959 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1507 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1434 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2034 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1892 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2147 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1555 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1627 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1341 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1338 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1372 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1100 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1388 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1309 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1477 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1125 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1333 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1277 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1438 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1630 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1300 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1308 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1460 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1404 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1196 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1253 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1446 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1489 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1499 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1154 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1223 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1386 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1483 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1407 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1237 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1435 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1343 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1154 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1428 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1386 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1335 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1306 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1385 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1153 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1030 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1507 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2035 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1561 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2776 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1749 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1341 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2242 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1371 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1673 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1776 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1489 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2009 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1641 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1499 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2344 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1959 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2207 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1154 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1425 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1343 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1237 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1306 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1335 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 2176 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1617 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1704 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1475 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1915 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1652 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 1504 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 653 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 665 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 588 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 699 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 676 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 535 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 602 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 607 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 595 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 607 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 589 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 574 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 556 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 545 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 625 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 678 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 594 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 516 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 628 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 555 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 611 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 628 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 591 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 678 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 521 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 597 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 620 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 617 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 619 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 633 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 206 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 239 total tokens.\n",
      "DEBUG: Getting embedding from OpenAI\n",
      "DEBUG: Got embedding. Usage: 248 total tokens.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "_ = documents.apply(get_and_save_emebeddings, axis=1)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfd467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def kmeans_cluster_embeddings(df: pd.DataFrame, n_clusters: int = 108) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies KMeans clustering to a column of document embeddings in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the embeddings.\n",
    "    - n_clusters: int, number of clusters to form (default is 108).\n",
    "\n",
    "    Returns:\n",
    "    - df: original DataFrame with an added column 'cluster' containing cluster labels.\n",
    "    \"\"\"\n",
    "    # Extract embeddings and convert to NumPy array\n",
    "    embeddings = np.vstack(df[\"embedding\"].values)\n",
    "\n",
    "    # Run KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Add the labels back to the DataFrame\n",
    "    df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4ff6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cluster_hitrate(row):\n",
    "    if not isinstance(row[\"original_doc_ids\"], list):\n",
    "        return None\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for id in row[\"original_doc_ids\"]:\n",
    "        org_row = documents.loc[documents[\"doc_id\"].astype(int) == int(id)].iloc[0]\n",
    "        org_cluster = org_row[\"cluster\"]\n",
    "        res.append(row[\"cluster\"] == org_cluster)\n",
    "\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5bb391e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>original_doc_ids</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_hitrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100134</td>\n",
       "      <td>Law</td>\n",
       "      <td>**IN THE DANBURY, PINEHURST COURT**\\n\\n**CRIMI...</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[0.015011516, 0.03634062, 0.0030247627, 0.0489...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100136</td>\n",
       "      <td>Law</td>\n",
       "      <td>**Upton, Georgetown, Court**\\n\\n*Criminal Divi...</td>\n",
       "      <td>[136]</td>\n",
       "      <td>[0.03939665, 0.058982093, 0.020784838, 0.05212...</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100139</td>\n",
       "      <td>Law</td>\n",
       "      <td>Glenwood, Quailwood Court\\n9th Judicial Circui...</td>\n",
       "      <td>[139]</td>\n",
       "      <td>[0.031122264, 0.0073628416, 0.042542476, 0.039...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100046</td>\n",
       "      <td>Finance</td>\n",
       "      <td>JetWing Aviation, established on April 15, 200...</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[-0.009702898, 0.0164151, 0.06840374, 0.018056...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100047</td>\n",
       "      <td>Finance</td>\n",
       "      <td>CleanCo Housekeeping Services is a housekeepin...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[0.05300756, 0.0015094227, 0.03901874, 0.04113...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>400110</td>\n",
       "      <td>Law</td>\n",
       "      <td>In a significant ruling that has reverberated ...</td>\n",
       "      <td>[110]</td>\n",
       "      <td>[0.04030493, 0.02091089, -0.0038811294, 0.0674...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>400116</td>\n",
       "      <td>Law</td>\n",
       "      <td>In a dramatic courtroom showdown that has rive...</td>\n",
       "      <td>[116]</td>\n",
       "      <td>[0.058137763, -0.011234419, 0.0049859015, 0.04...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Changes that occurred in senior management of ...</td>\n",
       "      <td>[46, 47, 52, 59, 66, 71, 72, 77, 78, 79]</td>\n",
       "      <td>[-0.004240031, -0.007925675, 0.018725948, 0.03...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>Law</td>\n",
       "      <td>Chief judge according to the court judgment of...</td>\n",
       "      <td>[134, 136, 139, 112, 114, 115, 119, 123, 125, ...</td>\n",
       "      <td>[-0.0014971758, 0.015988875, 0.023612805, 0.02...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Past disease history of Y. Evans according to ...</td>\n",
       "      <td>[179, 181, 198, 199, 208, 209, 207, 205, 212, ...</td>\n",
       "      <td>[-0.003927286, -0.017222933, 0.008311565, 0.01...</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id   domain                                            content  \\\n",
       "0   100134      Law  **IN THE DANBURY, PINEHURST COURT**\\n\\n**CRIMI...   \n",
       "1   100136      Law  **Upton, Georgetown, Court**\\n\\n*Criminal Divi...   \n",
       "2   100139      Law  Glenwood, Quailwood Court\\n9th Judicial Circui...   \n",
       "3   100046  Finance  JetWing Aviation, established on April 15, 200...   \n",
       "4   100047  Finance  CleanCo Housekeeping Services is a housekeepin...   \n",
       "..     ...      ...                                                ...   \n",
       "28  400110      Law  In a significant ruling that has reverberated ...   \n",
       "29  400116      Law  In a dramatic courtroom showdown that has rive...   \n",
       "0   300001  Finance  Changes that occurred in senior management of ...   \n",
       "1   300002      Law  Chief judge according to the court judgment of...   \n",
       "2   300003  Medical  Past disease history of Y. Evans according to ...   \n",
       "\n",
       "                                     original_doc_ids  \\\n",
       "0                                               [134]   \n",
       "1                                               [136]   \n",
       "2                                               [139]   \n",
       "3                                                [46]   \n",
       "4                                                [47]   \n",
       "..                                                ...   \n",
       "28                                              [110]   \n",
       "29                                              [116]   \n",
       "0            [46, 47, 52, 59, 66, 71, 72, 77, 78, 79]   \n",
       "1   [134, 136, 139, 112, 114, 115, 119, 123, 125, ...   \n",
       "2   [179, 181, 198, 199, 208, 209, 207, 205, 212, ...   \n",
       "\n",
       "                                            embedding  cluster  \\\n",
       "0   [0.015011516, 0.03634062, 0.0030247627, 0.0489...        0   \n",
       "1   [0.03939665, 0.058982093, 0.020784838, 0.05212...       38   \n",
       "2   [0.031122264, 0.0073628416, 0.042542476, 0.039...       11   \n",
       "3   [-0.009702898, 0.0164151, 0.06840374, 0.018056...       17   \n",
       "4   [0.05300756, 0.0015094227, 0.03901874, 0.04113...       25   \n",
       "..                                                ...      ...   \n",
       "28  [0.04030493, 0.02091089, -0.0038811294, 0.0674...       43   \n",
       "29  [0.058137763, -0.011234419, 0.0049859015, 0.04...       51   \n",
       "0   [-0.004240031, -0.007925675, 0.018725948, 0.03...       65   \n",
       "1   [-0.0014971758, 0.015988875, 0.023612805, 0.02...       24   \n",
       "2   [-0.003927286, -0.017222933, 0.008311565, 0.01...       44   \n",
       "\n",
       "    cluster_hitrate  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "..              ...  \n",
       "28              0.0  \n",
       "29              0.0  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = get_documents()\n",
    "doc_embeddings = pd.read_csv(FILEPATH, usecols=[\"doc_id\", \"embedding\"], converters={\"embedding\": ast.literal_eval})\n",
    "documents = documents.join(other=doc_embeddings.set_index(\"doc_id\"), on=\"doc_id\", how=\"left\")\n",
    "\n",
    "documents = kmeans_cluster_embeddings(df=documents)\n",
    "documents[\"cluster_hitrate\"] = documents.apply(calc_cluster_hitrate, axis=1)\n",
    "\n",
    "documents_filtered = documents.loc[documents[\"cluster_hitrate\"].notna()]\n",
    "documents_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
