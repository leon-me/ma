{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6703517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a800bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions/classes for manipulation\n",
    "from typing import Tuple, List, Dict\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from utils.utils import read_prompt\n",
    "\n",
    "doc_columns_ordered = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "DOCUMENTS = pd.read_csv(\"data/DRAGONball/en/docs.csv\")\n",
    "QUERIES = pd.read_csv(\n",
    "    \"data/DRAGONball/en/queries_flattened.csv\",\n",
    "    converters={\n",
    "        \"ground_truth.doc_ids\": ast.literal_eval,\n",
    "        \"ground_truth.keypoints\": ast.literal_eval,\n",
    "        \"ground_truth.references\": ast.literal_eval,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "class FactualQuestionResponse(BaseModel):\n",
    "    text_new: str\n",
    "    answer_new: str\n",
    "    references_new: list[str]\n",
    "\n",
    "\n",
    "class TabularDataResponse(BaseModel):\n",
    "    description: str\n",
    "    value: str\n",
    "\n",
    "\n",
    "def format_prompt_man_factual(user_prompt: str, text: str, question: str, answer: str, references: str) -> str:\n",
    "    \"\"\"Inserts dynamic information into the user prompt.\"\"\"\n",
    "    return user_prompt.format(text=text, question=question, answer=answer, references=references)\n",
    "\n",
    "\n",
    "def format_prompt_keypoints(user_prompt: str, question: str, answer: str) -> str:\n",
    "    return user_prompt.format(question=question, ground_truth=answer)\n",
    "\n",
    "\n",
    "def format_prompt_tabular(user_prompt: str, question: str, answer: str, entity: str) -> str:\n",
    "    return user_prompt.format(question=question, answer=answer, entity=entity)\n",
    "\n",
    "\n",
    "def get_query_ids_for_doc(doc_id: int, query_types: list[str] = [\"Factual Question\"]) -> list[int]:\n",
    "    \"\"\"Selects query_ids for queries related to that doc and with a specified type.\"\"\"\n",
    "    return QUERIES[\n",
    "        QUERIES[\"ground_truth.doc_ids\"].apply(lambda doc_ids: doc_id in doc_ids)\n",
    "        & QUERIES[\"query.query_type\"].isin(query_types)\n",
    "    ][\"query.query_id\"].to_list()\n",
    "\n",
    "\n",
    "def get_doc_query_mapping() -> List[Dict[str, int]]:\n",
    "    with open(\"doc_query_mapping.csv\", \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [{\"doc_id\": int(row[\"doc_id\"]), \"query_id\": int(row[\"query_id\"])} for row in reader]\n",
    "\n",
    "\n",
    "def get_query_properties(\n",
    "    query_id,\n",
    "    properties: list = [\"ground_truth.content\", \"ground_truth.keypoints\", \"ground_truth.references\", \"query.content\"],\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for query_id from queries dataframe.\"\"\"\n",
    "    row = QUERIES[QUERIES[\"query.query_id\"] == query_id]\n",
    "    return tuple(row[prop].iloc[0] for prop in properties)\n",
    "\n",
    "\n",
    "def get_doc_properties(\n",
    "    doc_id,\n",
    "    properties,\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for doc_id from docs dataframe.\"\"\"\n",
    "    row: pd.DataFrame = DOCUMENTS[DOCUMENTS[\"doc_id\"] == doc_id].dropna(axis=1)\n",
    "    return tuple(row[prop].iloc[0] for prop in properties if prop in row.columns)\n",
    "\n",
    "\n",
    "def get_doc_text(doc_id: int) -> str:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"] == doc_id][\"content\"].iloc[0]\n",
    "\n",
    "\n",
    "def get_docs_to_manipulate() -> List[int]:\n",
    "    with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        reader.__next__()\n",
    "\n",
    "        doc_ids_for_man = set()\n",
    "        for row in reader:\n",
    "            doc_ids_for_man.add(int(row[0]))\n",
    "    return list(doc_ids_for_man)\n",
    "\n",
    "\n",
    "def get_query_by_id(query_id: int) -> pd.Series:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int) == query_id].iloc[0]\n",
    "\n",
    "\n",
    "def get_queries_by_id(query_ids: List[int]) -> pd.DataFrame:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int).isin(query_ids)]\n",
    "\n",
    "\n",
    "def get_doc_by_id(doc_id: int) -> pd.Series:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"].astype(int) == doc_id].iloc[0]\n",
    "\n",
    "\n",
    "def openai_interface(system_prompt, user_prompt, response_format_pydantic=FactualQuestionResponse):\n",
    "    \"\"\"execute openai LLM call\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        response_format=response_format_pydantic,\n",
    "        temperature=0,\n",
    "    ).choices[0]\n",
    "\n",
    "    return completion.message.parsed\n",
    "\n",
    "\n",
    "def get_prompts_man_fact_single(doc_id: int, query_id: int) -> Tuple:\n",
    "    PROMPT_TYPE = \"manipulation_factual\"\n",
    "    prompt = [\n",
    "        prompt for prompt in read_prompt(\"prompts/json/manipulate_docs.json\") if prompt[\"prompt_type\"] == PROMPT_TYPE\n",
    "    ][0]\n",
    "\n",
    "    text = get_doc_text(doc_id)\n",
    "    answer, keypoints, references, question = get_query_properties(query_id)\n",
    "\n",
    "    system_prompt = prompt[\"system_prompt\"]\n",
    "    user_prompt = format_prompt_man_factual(\n",
    "        user_prompt=prompt[\"user_prompt\"], text=text, answer=answer, question=question, references=references\n",
    "    )\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_man_tabular(query_id: int, doc_id: int) -> Tuple:\n",
    "    user_prompt = read_prompt(\"prompts/json/create_tabular_docs.json\")[\"prompt\"]\n",
    "    system_prompt = \"You are an expert in manipulation and transformation of textual data.\"\n",
    "    answer, question = get_query_properties(query_id, properties=[\"ground_truth.content\", \"query.content\"])\n",
    "    (entity,) = get_doc_properties(doc_id, [\"hospital_patient_name\", \"company_name\", \"court_name\"])\n",
    "    user_prompt = format_prompt_tabular(user_prompt, question, answer, entity)\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_id_for_manipulated_doc_or_query(original_doc_id: int, prefix_number=1) -> int:\n",
    "    id_str = str(prefix_number) + str(original_doc_id).zfill(5)\n",
    "    return int(id_str)\n",
    "\n",
    "\n",
    "def save_manipulated_doc(\n",
    "    hospital_patient_name: str,\n",
    "    language: str,\n",
    "    doc_id: int,\n",
    "    domain: str,\n",
    "    content: str,\n",
    "    company_name: str,\n",
    "    court_name: str,\n",
    "    original_doc_id: int,\n",
    "):\n",
    "    \"\"\"Saves a manipulated doc to csv. Adds column \"original_doc_id.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    params = locals()  # all params\n",
    "\n",
    "    # change filename\n",
    "    filename = \"data/additional_data/docs/fact_multi_manipulations.csv\"\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=doc_columns_ordered + [\"original_doc_id\"])\n",
    "            ids_present = {int(row[\"doc_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(doc_id) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {doc_id} already exists. Did not write new document to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=doc_columns_ordered + [\"original_doc_id\"], extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(params)\n",
    "\n",
    "\n",
    "def save_manipulated_query(\n",
    "    domain: str,\n",
    "    ground_truth__content: str,\n",
    "    ground_truth__doc_ids: List[int],\n",
    "    ground_truth__keypoints: List[str],\n",
    "    ground_truth__references: List[str],\n",
    "    language: str,\n",
    "    prediction: str,\n",
    "    query__content: str,\n",
    "    query__query_id: int,\n",
    "    query__query_type: str,\n",
    "    query__original_query_id: int,\n",
    "):\n",
    "    \"\"\"Saves a manipulated doc to csv. Adds column \"original_doc_id.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    params = {key.replace(\"__\", \".\"): locals()[key] for key in locals().copy().keys()}  # all params\n",
    "\n",
    "    filename = \"data/additional_data/queries/fact_single_manipulations.csv\"\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=params.keys())\n",
    "            ids_present = {int(row[\"query.query_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(query__query_id) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {query__query_id} already exists. Did not write new query to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=params.keys(), extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f9ef2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents:\n",
      " Index(['hospital_patient_name', 'language', 'doc_id', 'domain', 'content',\n",
      "       'company_name', 'court_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Queries:\n",
      " Index(['domain', 'ground_truth.content', 'ground_truth.doc_ids',\n",
      "       'ground_truth.keypoints', 'ground_truth.references', 'language',\n",
      "       'prediction', 'query.content', 'query.query_id', 'query.query_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### describe documents and queries\n",
    "\n",
    "print(\"Documents:\\n\", DOCUMENTS.columns)\n",
    "print()\n",
    "print(\"Queries:\\n\", QUERIES.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a2e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Randomly select documents from corpus\n",
    "import random\n",
    "import csv\n",
    "\n",
    "documents = pd.read_csv(\"data/DRAGONball/en/docs.csv\")\n",
    "\n",
    "ids_by_domain = {}\n",
    "\n",
    "\n",
    "for row in documents.itertuples(index=False):\n",
    "    new_list = ids_by_domain.get(row.domain, [])\n",
    "    new_list.append(row.doc_id)\n",
    "    ids_by_domain[row.domain] = new_list\n",
    "\n",
    "try:\n",
    "    with open(\"docs_to_manipulate.csv\", \"x\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        all_rand_ids = []\n",
    "\n",
    "        for domain, id_list in ids_by_domain.items():\n",
    "            print(f\"{domain}: {len(id_list)}\")\n",
    "            rand_ids = random.sample(id_list, k=10)\n",
    "            print(f\"\\t{rand_ids}\")\n",
    "            all_rand_ids += rand_ids\n",
    "\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"doc_id\"]\n",
    "        writer.writerow(header)\n",
    "        for id in all_rand_ids:\n",
    "            writer.writerow([id])\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c4d2f8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to 'docs_to_manipulate_all_info.csv'\n"
     ]
    }
   ],
   "source": [
    "### Describe documents to manipulate\n",
    "with open(\"docs_to_manipulate.csv\", \"r\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header\n",
    "    ids = set()\n",
    "    for row in reader:\n",
    "        ids.add(int(row[0]))\n",
    "\n",
    "documents_to_manipulate = documents[documents[\"doc_id\"].isin(ids)]\n",
    "documents_to_manipulate.to_csv(\"docs_to_manipulate_all_info.csv\", index=False, columns=doc_columns_ordered)\n",
    "print(f\"Output written to 'docs_to_manipulate_all_info.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e800283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Create doc-query-query mapping\n",
    "try:\n",
    "    if os.path.exists(\"doc_query_mapping_multi.csv\"):\n",
    "        raise FileExistsError\n",
    "    with open(\"doc_query_mapping.csv\", \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, fieldnames=[\"doc_id\", \"query_id\"])\n",
    "        next(reader)  # skip headers+\n",
    "        doc_queries_mapping = []\n",
    "        for row in reader:\n",
    "            doc_id = int(row[\"doc_id\"])\n",
    "            query_id = int(row[\"query_id\"])\n",
    "            additional_query_id = int(query_id)\n",
    "\n",
    "            options = get_query_ids_for_doc(doc_id, query_types=[\"Factual Question\"])\n",
    "            while additional_query_id == query_id:\n",
    "                if len(options) <= 1:\n",
    "                    print(f\"WARN: For doc '{doc_id}', only {len(options)} options are available.\")\n",
    "                    break\n",
    "                additional_query_id = random.sample(options, 1)[0]\n",
    "            keys = [\"doc_id\", \"query_id_single\", \"query_id_multi\"]\n",
    "            values = [doc_id, query_id, additional_query_id]\n",
    "            doc_queries_mapping.append(dict(zip(keys, values)))\n",
    "            doc_queries_mapping.sort(key=lambda x: x[\"doc_id\"])\n",
    "\n",
    "    with open(\"doc_query_mapping_multi.csv\", \"x\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(doc_queries_mapping)\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b4aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Select a single query per document of type \"Factual Question\"\n",
    "\n",
    "\n",
    "doc_ids_for_man = set()\n",
    "\n",
    "with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    reader.__next__()\n",
    "\n",
    "    for row in reader:\n",
    "        doc_ids_for_man.add(int(row[0]))\n",
    "\n",
    "doc_query_mapping = []\n",
    "\n",
    "for doc_id in doc_ids_for_man:\n",
    "    factual_questions = get_query_ids_for_doc(doc_id, query_types=[\"Factual Question\"])\n",
    "    doc_query_mapping.append({\"doc_id\": doc_id, \"query_id\": random.sample(factual_questions, 1)[0]})\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"doc_query_mapping.csv\", \"x\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=doc_query_mapping[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(doc_query_mapping)\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Row with ID 104620 already exists. Did not write new query to 'data/additional_data/queries/fact_single_manipulations.csv'.\n",
      "Finished processing doc 134 and query 4620.\n"
     ]
    }
   ],
   "source": [
    "### manipuale documents (fact single)\n",
    "def save_doc_and_query(doc_entry, query_entry, completion_parsed):\n",
    "    # -- doc\n",
    "    original_doc_id = doc_entry.doc_id\n",
    "    manipulated_doc_entry = doc_entry.copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(original_doc_id)\n",
    "    manipulated_doc_entry.content = completion_parsed.text_new\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([original_doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)\n",
    "\n",
    "    # -- query\n",
    "    original_query_id = query_entry[\"query.query_id\"]\n",
    "    manipulated_query_entry = query_entry.copy()\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = completion_parsed.answer_new\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = completion_parsed.references_new\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "    manipulated_query_entry.index = manipulated_query_entry.index.str.replace(\".\", \"__\", regex=False)\n",
    "\n",
    "    save_manipulated_query(**manipulated_query_entry)\n",
    "\n",
    "\n",
    "doc_query_mapping = get_doc_query_mapping()\n",
    "\n",
    "for mapping in doc_query_mapping:\n",
    "    doc_id = mapping[\"doc_id\"]\n",
    "    query_id = mapping[\"query_id\"]\n",
    "\n",
    "    doc_entry = get_doc_by_id(doc_id)\n",
    "    query_entry = get_query_by_id(query_id)\n",
    "\n",
    "    system_prompt, user_prompt = get_prompts_man_fact_single(doc_id, query_id)\n",
    "\n",
    "    # call openai\n",
    "    completion_parsed = openai_interface(system_prompt, user_prompt)\n",
    "\n",
    "    save_doc_and_query(doc_entry, query_entry, completion_parsed)\n",
    "    print(f\"Finished processing doc {doc_id} and query {query_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Danbury, Pinehurst, Court\n",
      "Entity: Upton, Georgetown, Court\n",
      "Entity: Glenwood, Quailwood, Court\n",
      "Entity: JetWing Aviation\n",
      "WARN: Row with ID 200046 already exists. Did not write new document to 'data/additional_data/docs/fact_multi_manipulations.csv'.\n",
      "Entity: CleanCo Housekeeping Services\n",
      "Entity: Parker General Hospital_Y. Evans\n",
      "Entity: EduCorp\n",
      "Entity: Farmington General Hospital_J. Brooks\n",
      "Entity: Retail Emporium\n",
      "Entity: Buildcorp Holdings\n",
      "Entity: Southport General Hospital_K. Mendoza\n",
      "Entity: ABC Education Corporation\n",
      "Entity: MediaCorp\n",
      "Entity: Wilton General Hospital_H. Flores\n",
      "Entity: Energen Solutions Ltd\n",
      "Entity: InnovateTech, Inc.\n",
      "Entity: Elevate Retail Inc.\n",
      "Entity: Newport General Hospital_V. Lewis\n",
      "Entity: Knoxville City Hospital_S. Moore\n",
      "Entity: Kingsport Medical Center_E. Chavez\n",
      "Entity: Oxford General Hospital_G. Gonzalez\n",
      "Entity: Bridgewater General Hospital_J. Reyes\n",
      "Entity: Tremont City Hospital_X. Price\n",
      "Entity: Bayside, Roseville, Court\n",
      "Entity: Trenton, Eastwood, Court\n",
      "Entity: Urbana, Belmont, Court\n",
      "Entity: Riverton, Hamilton, Court\n",
      "Entity: Sterling, Quarryville, Court\n",
      "Entity: Hartford, Ashland, Court\n",
      "Entity: Hamilton, Harrison, Court\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "with open(\"doc_query_mapping_multi.csv\", \"r\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f, fieldnames=[\"doc_id\", \"query_id_single\", \"query_id_multi\"])\n",
    "    next(reader)\n",
    "    mapping = [{\"doc_id\": int(row[\"doc_id\"]), \"query_id\": int(row[\"query_id_multi\"])} for row in reader]\n",
    "\n",
    "\n",
    "for id_pair in mapping:\n",
    "    doc_id = id_pair[\"doc_id\"]\n",
    "    query_id = id_pair[\"query_id\"]\n",
    "    system_prompt, user_prompt = get_prompts_man_tabular(query_id, doc_id)\n",
    "\n",
    "    response: TabularDataResponse = openai_interface(system_prompt, user_prompt, TabularDataResponse)\n",
    "\n",
    "    manipulated_doc_entry = get_doc_by_id(doc_id).copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(doc_id, prefix_number=2)\n",
    "    manipulated_doc_entry.content = \" | \".join([response.description, response.value])\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
