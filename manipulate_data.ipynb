{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6703517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/leon/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a800bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions/classes for manipulation\n",
    "from typing import Tuple, List, Dict\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from utils.utils import read_prompt\n",
    "\n",
    "doc_columns_ordered = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "DOCUMENTS = pd.read_csv(\"data/DRAGONball/en/docs.csv\")\n",
    "QUERIES = pd.read_csv(\n",
    "    \"data/DRAGONball/en/queries_flattened.csv\",\n",
    "    converters={\n",
    "        \"ground_truth.doc_ids\": ast.literal_eval,\n",
    "        \"ground_truth.keypoints\": ast.literal_eval,\n",
    "        \"ground_truth.references\": ast.literal_eval,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "class FactualQuestionResponse(BaseModel):\n",
    "    text_new: str\n",
    "    answer_new: str\n",
    "    references_new: list[str]\n",
    "\n",
    "\n",
    "class TabularDataResponse(BaseModel):\n",
    "    description: str\n",
    "    value: str\n",
    "\n",
    "\n",
    "def format_prompt_man_factual(user_prompt: str, text: str, question: str, answer: str, references: str) -> str:\n",
    "    \"\"\"Inserts dynamic information into the user prompt.\"\"\"\n",
    "    return user_prompt.format(text=text, question=question, answer=answer, references=references)\n",
    "\n",
    "\n",
    "def format_prompt_keypoints(user_prompt: str, question: str, answer: str) -> str:\n",
    "    return user_prompt.format(question=question, ground_truth=answer)\n",
    "\n",
    "\n",
    "def format_prompt_tabular(user_prompt: str, question: str, answer: str) -> str:\n",
    "    return user_prompt.format(question=question, answer=answer)\n",
    "\n",
    "\n",
    "def get_query_ids_for_doc(doc_id: int, query_types: list[str] = [\"Factual Question\"]) -> list[int]:\n",
    "    \"\"\"Selects query_ids for queries related to that doc and with a specified type.\"\"\"\n",
    "    return QUERIES[\n",
    "        QUERIES[\"ground_truth.doc_ids\"].apply(lambda doc_ids: doc_id in doc_ids)\n",
    "        & QUERIES[\"query.query_type\"].isin(query_types)\n",
    "    ][\"query.query_id\"].to_list()\n",
    "\n",
    "\n",
    "def get_doc_query_mapping() -> List[Dict[str, int]]:\n",
    "    with open(\"doc_query_mapping.csv\", \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [{\"doc_id\": int(row[\"doc_id\"]), \"query_id\": int(row[\"query_id\"])} for row in reader]\n",
    "\n",
    "\n",
    "def get_query_properties(\n",
    "    query_id,\n",
    "    properties: list = [\"ground_truth.content\", \"ground_truth.keypoints\", \"ground_truth.references\", \"query.content\"],\n",
    ") -> Tuple:\n",
    "    \"\"\"Select columns for query_id from queries dataframe.\"\"\"\n",
    "    row = QUERIES[QUERIES[\"query.query_id\"] == query_id]\n",
    "    # print(row[properties[0]])\n",
    "    return tuple(row[prop].iloc[0] for prop in properties)\n",
    "    # row[prop].iloc[0] returns a scalar value (at position 0) instead of a Series\n",
    "\n",
    "\n",
    "def get_doc_text(doc_id: int) -> str:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"] == doc_id][\"content\"].iloc[0]\n",
    "\n",
    "\n",
    "def get_docs_to_manipulate() -> List[int]:\n",
    "    with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        reader.__next__()\n",
    "\n",
    "        doc_ids_for_man = set()\n",
    "        for row in reader:\n",
    "            doc_ids_for_man.add(int(row[0]))\n",
    "    return list(doc_ids_for_man)\n",
    "\n",
    "\n",
    "def get_query_by_id(query_id: int) -> pd.Series:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int) == query_id].iloc[0]\n",
    "\n",
    "\n",
    "def get_queries_by_id(query_ids: List[int]) -> pd.DataFrame:\n",
    "    return QUERIES[QUERIES[\"query.query_id\"].astype(int).isin(query_ids)]\n",
    "\n",
    "\n",
    "def get_doc_by_id(doc_id: int) -> pd.Series:\n",
    "    return DOCUMENTS[DOCUMENTS[\"doc_id\"].astype(int) == doc_id].iloc[0]\n",
    "\n",
    "\n",
    "def openai_interface(system_prompt, user_prompt, response_format_pydantic=FactualQuestionResponse):\n",
    "    \"\"\"execute openai LLM call\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        response_format=response_format_pydantic,\n",
    "        temperature=0,\n",
    "    ).choices[0]\n",
    "\n",
    "    return completion.message.parsed\n",
    "\n",
    "\n",
    "def get_prompts_man_fact_single(doc_id: int, query_id: int) -> Tuple:\n",
    "    PROMPT_TYPE = \"manipulation_factual\"\n",
    "    prompt = [\n",
    "        prompt for prompt in read_prompt(\"prompts/json/manipulate_docs.json\") if prompt[\"prompt_type\"] == PROMPT_TYPE\n",
    "    ][0]\n",
    "\n",
    "    text = get_doc_text(doc_id)\n",
    "    answer, keypoints, references, question = get_query_properties(query_id)\n",
    "\n",
    "    system_prompt = prompt[\"system_prompt\"]\n",
    "    user_prompt = format_prompt_man_factual(\n",
    "        user_prompt=prompt[\"user_prompt\"], text=text, answer=answer, question=question, references=references\n",
    "    )\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_prompts_man_tabular(query_id: int) -> Tuple:\n",
    "    user_prompt = read_prompt(\"prompts/json/create_tabular_docs.json\")[\"prompt\"]\n",
    "    system_prompt = \"You are an expert in manipulation and transformation of textual data.\"\n",
    "    answer, question = get_query_properties(query_id, properties=[\"ground_truth.content\", \"query.content\"])\n",
    "    user_prompt = format_prompt_tabular(user_prompt, question, answer)\n",
    "    return (system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "def get_id_for_manipulated_doc_or_query(original_doc_id: int, prefix_number=1) -> int:\n",
    "    id_str = str(prefix_number) + str(original_doc_id).zfill(5)\n",
    "    return int(id_str)\n",
    "\n",
    "\n",
    "def save_manipulated_doc(\n",
    "    hospital_patient_name: str,\n",
    "    language: str,\n",
    "    doc_id: int,\n",
    "    domain: str,\n",
    "    content: str,\n",
    "    company_name: str,\n",
    "    court_name: str,\n",
    "    original_doc_id: int,\n",
    "):\n",
    "    \"\"\"Saves a manipulated doc to csv. Adds column \"original_doc_id.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    params = locals()  # all params\n",
    "\n",
    "    # change filename\n",
    "    filename = \"data/additional_data/docs/fact_multi_manipulations.csv\"\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=params.keys())\n",
    "            ids_present = {int(row[\"doc_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(doc_id) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {doc_id} already exists. Did not write new document to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=params.keys(), extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(params)\n",
    "\n",
    "\n",
    "def save_manipulated_query(\n",
    "    domain: str,\n",
    "    ground_truth__content: str,\n",
    "    ground_truth__doc_ids: List[int],\n",
    "    ground_truth__keypoints: List[str],\n",
    "    ground_truth__references: List[str],\n",
    "    language: str,\n",
    "    prediction: str,\n",
    "    query__content: str,\n",
    "    query__query_id: int,\n",
    "    query__query_type: str,\n",
    "    query__original_query_id: int,\n",
    "):\n",
    "    \"\"\"Saves a manipulated doc to csv. Adds column \"original_doc_id.\n",
    "    If an entry with that doc_id already exists in the csv, the new entry is NOT saved.\n",
    "    \"\"\"\n",
    "    params = {key.replace(\"__\", \".\"): locals()[key] for key in locals().copy().keys()}  # all params\n",
    "\n",
    "    filename = \"data/additional_data/queries/fact_single_manipulations.csv\"\n",
    "    is_empty = not os.path.exists(filename) or os.stat(filename).st_size == 0\n",
    "    id_exists = False\n",
    "    with open(filename, \"a+\", newline=\"\") as f:\n",
    "        if not is_empty:\n",
    "            f.seek(0)\n",
    "            reader = csv.DictReader(f, fieldnames=params.keys())\n",
    "            ids_present = {int(row[\"query.query_id\"]) for row in list(reader)[1:]}\n",
    "            id_exists = int(query__query_id) in ids_present\n",
    "\n",
    "        if id_exists == True:\n",
    "            print(f\"WARN: Row with ID {query__query_id} already exists. Did not write new query to '{filename}'.\")\n",
    "            return\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames=params.keys(), extrasaction=\"ignore\")\n",
    "        if is_empty:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f9ef2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents:\n",
      " Index(['hospital_patient_name', 'language', 'doc_id', 'domain', 'content',\n",
      "       'company_name', 'court_name'],\n",
      "      dtype='object')\n",
      "\n",
      "Queries:\n",
      " Index(['domain', 'ground_truth.content', 'ground_truth.doc_ids',\n",
      "       'ground_truth.keypoints', 'ground_truth.references', 'language',\n",
      "       'prediction', 'query.content', 'query.query_id', 'query.query_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### describe documents and queries\n",
    "\n",
    "print(\"Documents:\\n\", DOCUMENTS.columns)\n",
    "print()\n",
    "print(\"Queries:\\n\", QUERIES.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a2e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Randomly select documents from corpus\n",
    "import random\n",
    "import csv\n",
    "\n",
    "documents = pd.read_csv(\"data/DRAGONball/en/docs.csv\")\n",
    "\n",
    "ids_by_domain = {}\n",
    "\n",
    "\n",
    "for row in documents.itertuples(index=False):\n",
    "    new_list = ids_by_domain.get(row.domain, [])\n",
    "    new_list.append(row.doc_id)\n",
    "    ids_by_domain[row.domain] = new_list\n",
    "\n",
    "try:\n",
    "    with open(\"docs_to_manipulate.csv\", \"x\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        all_rand_ids = []\n",
    "\n",
    "        for domain, id_list in ids_by_domain.items():\n",
    "            print(f\"{domain}: {len(id_list)}\")\n",
    "            rand_ids = random.sample(id_list, k=10)\n",
    "            print(f\"\\t{rand_ids}\")\n",
    "            all_rand_ids += rand_ids\n",
    "\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"doc_id\"]\n",
    "        writer.writerow(header)\n",
    "        for id in all_rand_ids:\n",
    "            writer.writerow([id])\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c4d2f8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to 'docs_to_manipulate_all_info.csv'\n"
     ]
    }
   ],
   "source": [
    "### Describe documents to manipulate\n",
    "with open(\"docs_to_manipulate.csv\", \"r\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header\n",
    "    ids = set()\n",
    "    for row in reader:\n",
    "        ids.add(int(row[0]))\n",
    "\n",
    "documents_to_manipulate = documents[documents[\"doc_id\"].isin(ids)]\n",
    "documents_to_manipulate.to_csv(\"docs_to_manipulate_all_info.csv\", index=False, columns=doc_columns_ordered)\n",
    "print(f\"Output written to 'docs_to_manipulate_all_info.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e800283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Create doc-query-query mapping\n",
    "try:\n",
    "    if os.path.exists(\"doc_query_mapping_multi.csv\"):\n",
    "        raise FileExistsError\n",
    "    with open(\"doc_query_mapping.csv\", \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, fieldnames=[\"doc_id\", \"query_id\"])\n",
    "        next(reader)  # skip headers+\n",
    "        doc_queries_mapping = []\n",
    "        for row in reader:\n",
    "            doc_id = int(row[\"doc_id\"])\n",
    "            query_id = int(row[\"query_id\"])\n",
    "            additional_query_id = int(query_id)\n",
    "\n",
    "            options = get_query_ids_for_doc(doc_id, query_types=[\"Factual Question\"])\n",
    "            while additional_query_id == query_id:\n",
    "                if len(options) <= 1:\n",
    "                    print(f\"WARN: For doc '{doc_id}', only {len(options)} options are available.\")\n",
    "                    break\n",
    "                additional_query_id = random.sample(options, 1)[0]\n",
    "            keys = [\"doc_id\", \"query_id_single\", \"query_id_multi\"]\n",
    "            values = [doc_id, query_id, additional_query_id]\n",
    "            doc_queries_mapping.append(dict(zip(keys, values)))\n",
    "            doc_queries_mapping.sort(key=lambda x: x[\"doc_id\"])\n",
    "\n",
    "    with open(\"doc_query_mapping_multi.csv\", \"x\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(doc_queries_mapping)\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b4aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Select a single query per document of type \"Factual Question\"\n",
    "\n",
    "\n",
    "doc_ids_for_man = set()\n",
    "\n",
    "with open(\"docs_to_manipulate.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    reader.__next__()\n",
    "\n",
    "    for row in reader:\n",
    "        doc_ids_for_man.add(int(row[0]))\n",
    "\n",
    "doc_query_mapping = []\n",
    "\n",
    "for doc_id in doc_ids_for_man:\n",
    "    factual_questions = get_query_ids_for_doc(doc_id, query_types=[\"Factual Question\"])\n",
    "    doc_query_mapping.append({\"doc_id\": doc_id, \"query_id\": random.sample(factual_questions, 1)[0]})\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"doc_query_mapping.csv\", \"x\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=doc_query_mapping[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(doc_query_mapping)\n",
    "except FileExistsError:\n",
    "    print(\"File exists. Did nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Row with ID 100134 already exists. Did not write new document to 'data/additional_data/docs/fact_single_manipulations.csv'.\n",
      "WARN: Row with ID 104620 already exists. Did not write new document to 'data/additional_data/queries/fact_single_manipulations.csv'.\n",
      "Finished processing doc 134 and query 4620.\n",
      "Finished processing doc 136 and query 4612.\n",
      "Finished processing doc 139 and query 4643.\n",
      "Finished processing doc 46 and query 2856.\n",
      "Finished processing doc 47 and query 2246.\n",
      "Finished processing doc 179 and query 5959.\n",
      "Finished processing doc 52 and query 2509.\n",
      "Finished processing doc 181 and query 5978.\n",
      "Finished processing doc 59 and query 2698.\n",
      "Finished processing doc 66 and query 2933.\n",
      "Finished processing doc 198 and query 6143.\n",
      "Finished processing doc 71 and query 2538.\n",
      "Finished processing doc 72 and query 3189.\n",
      "Finished processing doc 199 and query 6149.\n",
      "Finished processing doc 77 and query 2378.\n",
      "Finished processing doc 78 and query 2833.\n",
      "Finished processing doc 79 and query 2728.\n",
      "Finished processing doc 208 and query 6225.\n",
      "Finished processing doc 209 and query 6234.\n",
      "Finished processing doc 207 and query 6215.\n",
      "Finished processing doc 205 and query 6192.\n",
      "Finished processing doc 212 and query 6268.\n",
      "Finished processing doc 211 and query 6243.\n",
      "Finished processing doc 112 and query 4370.\n",
      "Finished processing doc 114 and query 4390.\n",
      "Finished processing doc 115 and query 4402.\n",
      "Finished processing doc 119 and query 4466.\n",
      "Finished processing doc 123 and query 4480.\n",
      "Finished processing doc 125 and query 4530.\n",
      "Finished processing doc 127 and query 4521.\n"
     ]
    }
   ],
   "source": [
    "### manipuale documents (fact single)\n",
    "def save_doc_and_query(doc_entry, query_entry, completion_parsed):\n",
    "    # -- doc\n",
    "    original_doc_id = doc_entry.doc_id\n",
    "    manipulated_doc_entry = doc_entry.copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(original_doc_id)\n",
    "    manipulated_doc_entry.content = completion_parsed.text_new\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([original_doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)\n",
    "\n",
    "    # -- query\n",
    "    original_query_id = query_entry[\"query.query_id\"]\n",
    "    manipulated_query_entry = query_entry.copy()\n",
    "    manipulated_query_entry[\"ground_truth.content\"] = completion_parsed.answer_new\n",
    "    manipulated_query_entry[\"ground_truth.references\"] = completion_parsed.references_new\n",
    "    manipulated_query_entry[\"ground_truth.keypoints\"] = []\n",
    "    manipulated_query_entry[\"query.query_id\"] = get_id_for_manipulated_doc_or_query(original_query_id)\n",
    "    manipulated_query_entry = pd.concat(\n",
    "        [manipulated_query_entry, pd.Series([original_query_id], index=[\"query.original_query_id\"])]\n",
    "    )\n",
    "    manipulated_query_entry.index = manipulated_query_entry.index.str.replace(\".\", \"__\", regex=False)\n",
    "\n",
    "    save_manipulated_query(**manipulated_query_entry)\n",
    "\n",
    "\n",
    "doc_query_mapping = get_doc_query_mapping()\n",
    "\n",
    "for mapping in doc_query_mapping:\n",
    "    doc_id = mapping[\"doc_id\"]\n",
    "    query_id = mapping[\"query_id\"]\n",
    "\n",
    "    doc_entry = get_doc_by_id(doc_id)\n",
    "    query_entry = get_query_by_id(query_id)\n",
    "\n",
    "    system_prompt, user_prompt = get_prompts_man_fact_single(doc_id, query_id)\n",
    "\n",
    "    # call openai\n",
    "    completion_parsed = openai_interface(system_prompt, user_prompt)\n",
    "\n",
    "    save_doc_and_query(doc_entry, query_entry, completion_parsed)\n",
    "    print(f\"Finished processing doc {doc_id} and query {query_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"doc_query_mapping_multi.csv\", \"r\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f, fieldnames=[\"doc_id\", \"query_id_single\", \"query_id_multi\"])\n",
    "    next(reader)\n",
    "    mapping = [{\"doc_id\": int(row[\"doc_id\"]), \"query_id\": int(row[\"query_id_multi\"])} for row in reader]\n",
    "\n",
    "\n",
    "for id_pair in mapping[1:]:\n",
    "    doc_id = id_pair[\"doc_id\"]\n",
    "    query_id = id_pair[\"query_id\"]\n",
    "    system_prompt, user_prompt = get_prompts_man_tabular(query_id)\n",
    "    response: TabularDataResponse = openai_interface(system_prompt, user_prompt, TabularDataResponse)\n",
    "\n",
    "    manipulated_doc_entry = get_doc_by_id(doc_id).copy()\n",
    "    manipulated_doc_entry.doc_id = get_id_for_manipulated_doc_or_query(doc_id, prefix_number=2)\n",
    "    manipulated_doc_entry.content = \" | \".join([response.description, response.value])\n",
    "    manipulated_doc_entry = pd.concat([manipulated_doc_entry, pd.Series([doc_id], index=[\"original_doc_id\"])])\n",
    "\n",
    "    save_manipulated_doc(**manipulated_doc_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
