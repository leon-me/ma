{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1256c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### static variables\n",
    "\n",
    "COLUMNS_DOCS = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TEXTUAL = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_names\",\n",
    "    \"court_names\",\n",
    "    \"hospital_patient_names\",\n",
    "    \"original_doc_ids\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd890fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_documents() -> pd.DataFrame:\n",
    "    docs_original = pd.read_csv(\"data/DRAGONball/en/docs.csv\", usecols=[\"doc_id\", \"domain\", \"content\"])\n",
    "    docs_manipulated_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/textual_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    docs_manipulated_tabular = pd.read_csv(\n",
    "        \"data/additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_ids\"],\n",
    "        converters={\"original_doc_ids\": ast.literal_eval},\n",
    "    )\n",
    "    print(f\"# original docs: {len(docs_original)}\")\n",
    "    print(f\"# manipulated textual docs: {len(docs_manipulated_textual)}\")\n",
    "    print(f\"# manipulated tabular docs: {len(docs_manipulated_tabular)}\")\n",
    "\n",
    "    return pd.concat([docs_original, docs_manipulated_textual, docs_manipulated_tabular], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa26b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original docs: 108\n",
      "# manipulated textual docs: 30\n",
      "# manipulated tabular docs: 3\n",
      "Size of vocabulary: 6791\n"
     ]
    }
   ],
   "source": [
    "docs_df = get_documents()\n",
    "docs_list = docs_df[\"content\"].to_list()\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, stop_words=\"english\")\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(docs_list)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"Size of vocabulary: {len(tfidf_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL: Numerals that do not fall under another type\n",
      "DATE: Absolute or relative dates or periods\n",
      "EVENT: Named hurricanes, battles, wars, sports events, etc.\n",
      "FAC: Buildings, airports, highways, bridges, etc.\n",
      "GPE: Countries, cities, states\n",
      "LANGUAGE: Any named language\n",
      "LAW: Named documents made into laws.\n",
      "LOC: Non-GPE locations, mountain ranges, bodies of water\n",
      "MONEY: Monetary values, including unit\n",
      "NORP: Nationalities or religious or political groups\n",
      "ORDINAL: \"first\", \"second\", etc.\n",
      "ORG: Companies, agencies, institutions, etc.\n",
      "PERCENT: Percentage, including \"%\"\n",
      "PERSON: People, including fictional\n",
      "PRODUCT: Objects, vehicles, foods, etc. (not services)\n",
      "QUANTITY: Measurements, as of weight or distance\n",
      "TIME: Times smaller than a day\n",
      "WORK_OF_ART: Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "### Spacy load\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "labels = [\n",
    "    \"CARDINAL\",\n",
    "    \"DATE\",\n",
    "    \"EVENT\",\n",
    "    \"FAC\",\n",
    "    \"GPE\",\n",
    "    \"LANGUAGE\",\n",
    "    \"LAW\",\n",
    "    \"LOC\",\n",
    "    \"MONEY\",\n",
    "    \"NORP\",\n",
    "    \"ORDINAL\",\n",
    "    \"ORG\",\n",
    "    \"PERCENT\",\n",
    "    \"PERSON\",\n",
    "    \"PRODUCT\",\n",
    "    \"QUANTITY\",\n",
    "    \"TIME\",\n",
    "    \"WORK_OF_ART\",\n",
    "]\n",
    "for label in labels:\n",
    "    print(f\"{label}: {spacy.explain(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NER\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Extract named entities from each document\n",
    "entity_lists = []\n",
    "for doc in docs_list:\n",
    "    spacy_doc = nlp(doc)\n",
    "    # entities = [ent.text.lower() for ent in spacy_doc.ents if ent.label_ in {\"PERSON\", \"ORG\", \"GPE\", \"PRODUCT\", \"EVENT\", \"LAW\", \"LOC\", \"WORK_OF_ART\"}]\n",
    "    entities = [\n",
    "        ent.text.lower().strip().replace(\"\\n\", \"\")\n",
    "        for ent in spacy_doc.ents\n",
    "        if ent.label_ in {\"PERSON\", \"ORG\", \"GPE\", \"PRODUCT\"}\n",
    "    ]\n",
    "    entity_lists.append(Counter(dict(Counter(entities).most_common(100))))\n",
    "\n",
    "entity_vectorizer = DictVectorizer()\n",
    "X_entities = entity_vectorizer.fit_transform(entity_lists)\n",
    "entity_feature_names = entity_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "15ff0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine TF-IDF with NER\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_combined = hstack([tfidf_features, X_entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fd35bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NMF\n",
    "nmf = NMF(n_components=80, init=\"nndsvda\", max_iter=400)\n",
    "# nmf = nmf.fit(tfidf_features[:-3])\n",
    "# nmf_data = nmf.transform(tfidf_features)\n",
    "nmf_data = nmf.fit_transform(X_combined)\n",
    "nmf_data_normalised = normalize(nmf_data, norm=\"l1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "37eca537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: educorp | ai | johnson | alpha schools | collins | global education solutions | lisa collins | project smartlearn | steven johnson | the city of education\n",
      "Topic #2: jetwing aviation | jetwing aviation's | aerotech avionics | miami | skyflight airlines | project skylink | florida | united states | aviation | jetwing\n",
      "Topic #3: mediacorp | big pictures | big pictures' | digital media solutions | project vision | whistleblower protection program | nyse | united states | new york | mediacorp\n",
      "Topic #4: elevate retail inc. | elevate retail | ar | sustainable packaging program | manhattan | sustainability task force | logistics solutions inc. | elevate retail's | the united states | sustainable fashion organizations\n",
      "Topic #5: innovatetech | ipo | inc. | john smith | nasdaq | artificial intelligence (ai | socialconnect, inc. | project ampere | code of ethics and conduct | initial public offering\n",
      "Topic #6: energen solutions ltd | energen solutions ltd's | energen solutions ltd. | cfo | esl | linda anderson | seattle | sunpower corp | windtech inc | david thompson\n",
      "Topic #7: j. hall | r. johnson | urbana | e. johnson | m. stevens | w. flores | belmont | belmont procuratorate | r. johnson's | clerk\n",
      "Topic #8: abc education corporation | abc education | abc education's | john smith | doe | alpha academy | k-12 | usa | smith | board of directors\n",
      "Topic #9: innovatetech solutions | innovatetech solutions' | ai | california | project x | cfo | innovatetech | global innovations ltd. | innovatesoft inc. | james peterson\n",
      "Topic #10: buildcorp holdings | buildcorp holdings' | a&b construction | the board of directors | the environmental department | x constructions | jane smith | united kingdom | london | john doe\n",
      "Topic #11: evergreen consumer goods co. | evergreen | evergreen consumer goods co.'s | john smith | cfo | green health products | greenwaves inc. | project everfresh | emily johnson | lisa anderson\n",
      "Topic #12: retail emporium | retail emporium's | homegoods corporation | fancy apparel company | sarah johnson | usa | new york | emporium | retail | overall, retail emporium's\n",
      "Topic #13: entertainment enterprises inc. | california | dream studios | entertainment enterprises inc.'s | jennifer adams | michael collins | overall, entertainment enterprises inc. | music productions inc. | los angeles | sarah johnson\n",
      "Topic #14: healthpro innovations | healthpro innovations' | medtech solutions | sarah thompson | johnson | ai | alex johnson | board | the new york stock exchange | new york\n",
      "Topic #15: adams | n. adams | brighton | the sterling public works department | sterling procuratorate | sterling court | the crime of embezzlement under | sterling | procuratorate | judgment result\n",
      "Topic #16: ecoguard solutions | project cleanwater | ecoguard solutions' | the board of directors | robert johnson | san francisco | michael thompson | the research and development (r&d) department | energyeco inc. | aqualife inc.\n",
      "Topic #17: white | franklin | q. white | jewel haven | court | clerk | q. bennett | l. cox | summerville | z. ruiz\n",
      "Topic #18: cleanco | cleanco housekeeping services | chicago | david anderson | emily carter | evans | fresh breeze cleaning services | michael evans | project green clean | sparkle cleaners\n",
      "Topic #19: anderson | p. anderson | def services | abc manufacturing | xyz construction co. | ghi corporation | cfo | clerk | john doe | ghi corporation’s\n",
      "Topic #20: healthlife solutions | the board of directors | healthlife solutions' | project medtech | san francisco | williams | henderson | jane henderson | medtech innovations | michael williams\n",
      "Topic #21: c. king | j. doe | z. davis | eastwood procuratorate | n. mendoza | eastwood court | eastwood | ford | trenton | case filing\n",
      "Topic #22: y. nelson | :* hon | e. collins | clerk:* k. kelly | quailwood procuratorate | quailwood | quailwood court | glenwood, | the crime of picking quarrels | clerk\n",
      "Topic #23: culture innovators ltd. | artex | new york | culture innovators ltd.'s | jane smith | united kingdom | london | john davis | united states | board of directors\n",
      "Topic #24: franklin williams | williams | georgetown | upton | f. williams | the crime of bending the law for personal | procuratorate | o. nelson | h. alvarez | clerk of court\n",
      "Topic #25: green fields agriculture co. | erp | fertile land farms | smith farms | fair trade certification | fresh field farms | ruralville | project green harvest | agriculture | fields\n",
      "Topic #26: accutech solutions inc. | accutech | accutech solutions inc.'s | ai | globalsocial | san francisco | united kingdom | trendanalytica | accutech solutions' | influencer connect\n",
      "Topic #27: v. martin | roseville | martin | procuratorate | elite brands' | the crime of embezzlement | n. harris | court | bank withdrawal records:** records | clerk a. wood\n",
      "Topic #28: acme government solutions | acme government solutions' | the board of directors | shareholders | d.c. | nationwide security services | the board of directors election | the modernizing public infrastructure | an ethics committee | washington\n",
      "Topic #29: sparkling clean housekeeping services | clean housekeeping services | crm | customer relationship management | city centre | sparkling clean housekeeping services' | london | sparkling | housekeeping | clean\n",
      "Topic #30: thompson | james thompson | yorktown | quarryville | clerk | the crime of embezzlement under | r. gutierrez | the yorktown municipal office | the yorktown municipal office's | yorktown federal bank\n",
      "Topic #31: skyquest airlines | skyquest | palm city | florida | the board of directors | aerovia | skylease | faa | wingsaway airlines | boeing\n",
      "Topic #32: j. gonzalez | ashton | the clarksville tax department | sunrise construction inc. | riven pharmaceuticals | clarksville court | clarksville | clerk | a. brown | clarksville procuratorate\n",
      "Topic #33: green fields agriculture ltd. | nasdaq | california | green harvest farm | sunnydale | project greenhouse | freshpro | agriculture | fields | green\n",
      "Topic #34: innovatech solutions | innovatech | innovatech solutions' | nasdaq | texas | austin | innovate robotics | optigen corporation | innovatepro | ca\n",
      "Topic #35: c. taylor | norwood | nike | unionville court | chanel | gucci | louis vuitton | selling counterfeit registered trademark goods | unionville | unionville procuratorate\n",
      "Topic #36: strongbuild construction | strongbuild construction's | john smith | the board of directors | elite construction firm | jane johnson | metropolis city | state of progress | summit construction | summit construction's\n",
      "Topic #37: i. hill | brighton | cedarwood | hill | procuratorate | cctv | court | w. hall  court | nelson & associates law firm | the crime of theft\n",
      "Topic #38: cbc | trauma history | surgery | lymph nodes | rectum | marital history | mucous membranes | working conditions | marital | limbs\n",
      "Topic #39: fabrikon manufacturing ltd. | fabrikon | the board of directors | technoparts ltd. | precision tools inc. | project phoenix | cityville | board of directors | fabrikon | company\n",
      "Topic #40: grand adventures tourism ltd. | exotic resorts | ipo | touristland | holiday escapes ltd. | project dream holidays | adventure sport ltd. | bali | paris | grand adventures tourism ltd.'s\n",
      "Topic #41: t. collins | white | james white | charleston | ashland | alan turner | julia reed | julia reed’s | l. nguyen | negligent homicide\n",
      "Topic #42: vanguard media group | vanguard | vanguard media group's | silver screen studios | california | mediatech productions | digital channel inc. | ambient digital | xyz studios | los angeles\n",
      "Topic #43: capital finance group | capital finance group's | united states | xyz wealth management | john anderson | julia thompson | alpha financial services | new york | finance | group\n",
      "Topic #44: g. torres | smith | vandalia | bayside court | trenton | l. johnson | r. lee | k. wu | jet auto repair | camry\n",
      "Topic #45: z. torres | torres | apple | samsung | quarryville | clerk | z. taylor | description | n. harris | iphones\n",
      "Topic #46: acme financial services | acme financial services' | new york | united states | acme | company | services | financial | 2020 | corporate\n",
      "Topic #47: stellar entertainment holdings ltd. | stellar entertainment | stellar entertainment's | california | alpha productions inc. | overall, stellar entertainment holdings ltd. | xyz films | los angeles | entertainment | stellar\n",
      "Topic #48: innovate tech solutions | innovate tech solutions' | nextgen technologies | nasdaq | shareholders | california | innovate | tech | 2017 | solutions\n",
      "Topic #49: artistic creations inc. | overall, artistic creations inc. | united states | project mosaic | artistic creations inc.'s | new york | artistic | creations | company | indicator\n",
      "Topic #50: j. smith | the hartford ashland procuratorate | court | clerk | j. smith's | m. davis | the hartford ashland court | * z. kelly | ashland | j. harris's\n",
      "Topic #51: ruiz | z. ruiz | oakwood | clerk | arlington procuratorate | arlington court | the crime of evading tax arrears recovery | * h. hill | j. bennett | ruiz enterprises\n",
      "Topic #52: greentech solutions inc. | liberty energy solutions | nasdaq | california | emily anderson | michael roberts | project cleanair | research and development (r&d) department | san francisco | greentech\n",
      "Topic #53: s. taylor | richmond | northwood | the crime of counterfeiting currency | m. johnson | eagleton street | clerk | m. johnson’s | o. edwards | s. taylor's\n",
      "Topic #54: x. morgan | morgan & co. consulting | morgan & co. | the riverside glenwood procuratorate | clerk | f. gutierrez | green oaks | m. sanchez | y. jackson | county police\n",
      "Topic #55: sunrise holidays | sunrise holidays' | the board of directors | board of directors change | sunnyville | sustainability and social responsibility initiatives | compliance and regulatory | project destinations | ocean breeze hotels | sunshine tours\n",
      "Topic #56: walker | h. walker | hamilton | walker’s | hamilton procuratorate | h. walker's | the crime of counterfeiting currency | clerk | riverton | hamilton defense associates\n",
      "Topic #57: m. harris | j. thompson | j. thompson's | lancaster | m. harris's | the crime of intentional homicide | lancaster, court | preston | w. smith | procuratorate\n",
      "Topic #58: q. ruiz | springfield | trenton | techworld | l. douglas | y. gonzalez | m. johnson | cctv | samsung | clerk\n",
      "Topic #59: hudson consumer goods co. | united states | employee wellness program | greenfield cosmetics | blueline appliances | the green manufacturing program | project phoenix | new york | hudson | consumer\n",
      "Topic #60: hematuria | ct | spain | menarche age | lymph nodes | dysmenorrhea | rectum | limbs | marital history | surgery\n",
      "Topic #61: bennett | m. bennett | bac | procuratorate | a. alvarez  court | lakewood | clerk | b. mitchell | bennett’s van | blood alcohol content\n",
      "Topic #62: f. james | clerk | caucasian | collins & associates law firm | f. james' | f. james's | q. collins | q. lewis- * | retail store | windsor\n",
      "Topic #63: harrison | hamilton | m. ward | m. ward's | s. harris | h. spencer | t. rivera | j. olsen | reference article | i. richardsonlaw firm:\n",
      "Topic #64: energex corporation | the board of directors | smith | james smith | emily davis | overall, energex corporation | houston | texas | supervisory board | the new york stock exchange\n",
      "Topic #65: m. cooper | the hartford ashland procuratorate | court | ashland | the hartford ashland court | m. davis | * z. kelly | m. cooper's | clerk | the crime of negligent homicide\n",
      "Topic #66: h. price | greenfield | fairview court | clerk | fairview procuratorate | h. price's | h. price’s | n. scott | sunnyvale street | t. scott\n",
      "Topic #67: national development corporation | the national development corporation | the board of directors | green energy power | john smith | shareholders | davis | jane davis | project momentum | smart city\n",
      "Topic #68: csf | crp | critically ill patient care records: none | working conditions | handover records | marital history | trauma history | allergic | ct | wilton general hospital\n",
      "Topic #69: t. bennett | vandalia | farmington | procuratorate | w. brooks | clerk | v. smith | x. sanders  law firm: | j. martin | t. bennett  gender\n",
      "Topic #70: j. gonzalez | linden | charleston | john smith | robert brown | the crime of picking quarrels | smith | procuratorate | jane doe | procuratorate  **court\n",
      "Topic #71: risperidone | metabolic | cbt | complete | normocephalic | discharge records | marital | marital history | rectum | surgery\n",
      "Topic #72: mayfield | x. alvarez | court | alvarez | h. white | w. hernandez | lakewood | the crime of traffic accident | john doe | procuratorate\n",
      "Topic #73: bradykinesia | resp | tremor | working conditions: works | normocephalic | marital history | ii-xii | critically ill patient care records | marital | mucous membranes: moist\n",
      "Topic #74: anesthesia | a. smith | farmington | u/l | mucous membranes | ct | lymph nodes | birthplace | limbs | trauma history\n",
      "Topic #75: preeclampsia | pregnancy-induced hypertension syndrome | bp | greenfield | anesthesia | menarche age | birthplace | mucous membranes | dysmenorrhea | marital history\n",
      "Topic #76: knoxville | allergic | newport street | laryngotracheomalacia | resp | limbs | mucous membranes | working conditions | rectum | marital history\n",
      "Topic #77: court | georgetown | hamilton | j. smith | trenton | sterling | upton | quarryville | danbury | quailwood, court\n",
      "Topic #78: advanced manufacturing solutions inc. | ipo | sustainability report | techland | advanced manufacturing solutions inc.'s | precision components ltd. | project automate | tech tools ltd. | cityville | initial public offering\n",
      "Topic #79: t4 | t3 | tsh | anesthesia | working conditions | menarche age | rectum | surgery | trauma history | lymph nodes\n",
      "Topic #80: ct | nasal | nasopharyngeal | biopsy | ashland | tb | allergic | organomegaly | spouse's health condition: healthychildren's condition | handover records\n"
     ]
    }
   ],
   "source": [
    "def print_top_terms_per_topic(nmf_model, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(nmf_model.components_):\n",
    "        top_indices = topic.argsort()[::-1][:n_top_words]\n",
    "        top_terms = [feature_names[i] for i in top_indices]\n",
    "        print(f\"Topic #{topic_idx + 1}: {' | '.join(top_terms)}\")\n",
    "\n",
    "\n",
    "print_top_terms_per_topic(nmf, list(tfidf_feature_names) + list(entity_feature_names), n_top_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6c35c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSA\n",
    "lsa = TruncatedSVD(n_components=108)\n",
    "lsa_data = lsa.fit_transform(tfidf_features)\n",
    "lsa_data_normalised = normalize(lsa_data, norm=\"l2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f6592352",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA\n",
    "lda = LatentDirichletAllocation(n_components=108)\n",
    "lda_data_normalised = lda.fit_transform(tfidf_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617e9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /Users/leon/.cache/kagglehub/models/google/universal-sentence-encoder/tensorFlow2/cmlm-en-base/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"google/universal-sentence-encoder/tensorFlow2/cmlm-en-base\")\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d299ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:25:55,950 - top2vec - INFO - Pre-processing documents for training\n",
      "2025-05-18 17:25:56,568 - top2vec - INFO - Creating joint document/word embedding\n",
      "2025-05-18 17:26:01,688 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "/Users/leon/miniconda3/envs/ma/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-18 17:26:11,220 - top2vec - INFO - Finding dense areas of documents\n",
      "/Users/leon/miniconda3/envs/ma/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/leon/miniconda3/envs/ma/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-05-18 17:26:11,240 - top2vec - INFO - Finding topics\n"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec\n",
    "\n",
    "model = Top2Vec(documents=docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2553110",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (1/2)\n",
    "def merge_original_ids(row):\n",
    "    if isinstance(row[\"original_doc_ids_tmp\"], list):\n",
    "        return row[\"original_doc_ids_tmp\"]\n",
    "    elif pd.notna(row[\"original_doc_id_tmp\"]):\n",
    "        return [row[\"original_doc_id_tmp\"]]\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "def calc_topics(row):\n",
    "    if isinstance(row[\"original_doc_ids\"], list):\n",
    "        if len(row[\"original_doc_ids\"]) > 1:\n",
    "            return np.argsort(row[\"doc_vector\"])[-10:][::-1].tolist()\n",
    "    return [np.argmax(row[\"doc_vector\"])]\n",
    "\n",
    "\n",
    "def calc_topics_for_cumulative_threshold(row, threshold=0.9):\n",
    "    sorted_indices = np.argsort(row)[::-1]\n",
    "\n",
    "    # Sort the probabilities accordingly\n",
    "    sorted_probs = row[sorted_indices]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative = np.cumsum(sorted_probs)\n",
    "\n",
    "    # Find the cutoff index where cumulative sum first exceeds threshold\n",
    "    cutoff = np.searchsorted(cumulative, threshold)\n",
    "\n",
    "    # Select the indices up to and including that point\n",
    "    selected_indices = sorted_indices[: cutoff + 1]\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "280b51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (2/2)\n",
    "def calc_topic_hitrate(row):\n",
    "    if not isinstance(row[\"original_doc_ids\"], list):\n",
    "        return None\n",
    "\n",
    "    original_doc_ids: List[int] = row[\"original_doc_ids\"]\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for id in original_doc_ids:\n",
    "        topics_row = set(row[\"topics\"])\n",
    "        original_row = docs.loc[docs[\"doc_id\"].astype(int) == int(id)].iloc[0]\n",
    "        topics_original = set(original_row[\"topics\"])\n",
    "        res.append(len(topics_row.intersection(topics_original)) > 0)\n",
    "\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4b4cd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. number of topics: 2.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_vector</th>\n",
       "      <th>original_doc_ids</th>\n",
       "      <th>topics</th>\n",
       "      <th>len(topics)</th>\n",
       "      <th>topic_hitrate</th>\n",
       "      <th>num_non-zeros_in_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>100134</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[18]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100136</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[136]</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>100139</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[139]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100046</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>100047</td>\n",
       "      <td>[0.9855, 0.0077, 0.0025, 0.0016, 0.001, 0.0006...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>100179</td>\n",
       "      <td>[0.973, 0.0249, 0.0014, 0.0006, 0.0001, 0.0, 0...</td>\n",
       "      <td>[179]</td>\n",
       "      <td>[79]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>100052</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[52]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>100181</td>\n",
       "      <td>[0.9671, 0.0328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[181]</td>\n",
       "      <td>[73]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>100059</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[59]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>100066</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>100198</td>\n",
       "      <td>[0.9999, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[198]</td>\n",
       "      <td>[72]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>100071</td>\n",
       "      <td>[0.9921, 0.0035, 0.0028, 0.0009, 0.0006, 0.0, ...</td>\n",
       "      <td>[71]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>100072</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[72]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>100199</td>\n",
       "      <td>[0.9942, 0.0052, 0.0006, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[199]</td>\n",
       "      <td>[67]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>100077</td>\n",
       "      <td>[0.9999, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[77]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>100078</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[78]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>100079</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[79]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>100208</td>\n",
       "      <td>[0.2785, 0.2469, 0.1598, 0.1211, 0.0584, 0.043...</td>\n",
       "      <td>[208]</td>\n",
       "      <td>[37, 75, 78, 49, 67, 79, 59, 74]</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>100209</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[75]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>100207</td>\n",
       "      <td>[0.9534, 0.0466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[207]</td>\n",
       "      <td>[78]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>100205</td>\n",
       "      <td>[0.9938, 0.0062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[205]</td>\n",
       "      <td>[59]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100212</td>\n",
       "      <td>[0.827, 0.1519, 0.0184, 0.0006, 0.0002, 0.0002...</td>\n",
       "      <td>[212]</td>\n",
       "      <td>[37, 79]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>100211</td>\n",
       "      <td>[0.9094, 0.0448, 0.0181, 0.0088, 0.0064, 0.003...</td>\n",
       "      <td>[211]</td>\n",
       "      <td>[37, 69]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100112</td>\n",
       "      <td>[0.9936, 0.0016, 0.001, 0.0004, 0.0003, 0.0003...</td>\n",
       "      <td>[112]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>100114</td>\n",
       "      <td>[0.9287, 0.0668, 0.0017, 0.0016, 0.0011, 0.0, ...</td>\n",
       "      <td>[114]</td>\n",
       "      <td>[20, 49]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>100115</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[115]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>100119</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[119]</td>\n",
       "      <td>[55]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>100123</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[123]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>100125</td>\n",
       "      <td>[0.9468, 0.0381, 0.0125, 0.0016, 0.0004, 0.000...</td>\n",
       "      <td>[125]</td>\n",
       "      <td>[49, 76]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>100127</td>\n",
       "      <td>[0.9998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[127]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>300001</td>\n",
       "      <td>[0.1095, 0.1044, 0.0911, 0.0892, 0.0829, 0.076...</td>\n",
       "      <td>[46, 47, 52, 59, 66, 71, 72, 77, 78, 79]</td>\n",
       "      <td>[9, 11, 5, 4, 2, 17, 7, 3, 1, 0, 66, 69, 63, 38]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>300002</td>\n",
       "      <td>[0.9725, 0.0185, 0.005, 0.0022, 0.0007, 0.0006...</td>\n",
       "      <td>[134, 136, 139, 112, 114, 115, 119, 123, 125, ...</td>\n",
       "      <td>[76]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>300003</td>\n",
       "      <td>[0.1998, 0.1698, 0.1492, 0.1275, 0.1128, 0.096...</td>\n",
       "      <td>[179, 181, 198, 199, 208, 209, 207, 205, 212, ...</td>\n",
       "      <td>[78, 75, 72, 67, 79, 73, 76, 59]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                         doc_vector  \\\n",
       "108  100134  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "109  100136  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "110  100139  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "111  100046  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "112  100047  [0.9855, 0.0077, 0.0025, 0.0016, 0.001, 0.0006...   \n",
       "113  100179  [0.973, 0.0249, 0.0014, 0.0006, 0.0001, 0.0, 0...   \n",
       "114  100052  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "115  100181  [0.9671, 0.0328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "116  100059  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "117  100066  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "118  100198  [0.9999, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "119  100071  [0.9921, 0.0035, 0.0028, 0.0009, 0.0006, 0.0, ...   \n",
       "120  100072  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "121  100199  [0.9942, 0.0052, 0.0006, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "122  100077  [0.9999, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "123  100078  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "124  100079  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "125  100208  [0.2785, 0.2469, 0.1598, 0.1211, 0.0584, 0.043...   \n",
       "126  100209  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "127  100207  [0.9534, 0.0466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "128  100205  [0.9938, 0.0062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "129  100212  [0.827, 0.1519, 0.0184, 0.0006, 0.0002, 0.0002...   \n",
       "130  100211  [0.9094, 0.0448, 0.0181, 0.0088, 0.0064, 0.003...   \n",
       "131  100112  [0.9936, 0.0016, 0.001, 0.0004, 0.0003, 0.0003...   \n",
       "132  100114  [0.9287, 0.0668, 0.0017, 0.0016, 0.0011, 0.0, ...   \n",
       "133  100115  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "134  100119  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "135  100123  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "136  100125  [0.9468, 0.0381, 0.0125, 0.0016, 0.0004, 0.000...   \n",
       "137  100127  [0.9998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "138  300001  [0.1095, 0.1044, 0.0911, 0.0892, 0.0829, 0.076...   \n",
       "139  300002  [0.9725, 0.0185, 0.005, 0.0022, 0.0007, 0.0006...   \n",
       "140  300003  [0.1998, 0.1698, 0.1492, 0.1275, 0.1128, 0.096...   \n",
       "\n",
       "                                      original_doc_ids  \\\n",
       "108                                              [134]   \n",
       "109                                              [136]   \n",
       "110                                              [139]   \n",
       "111                                               [46]   \n",
       "112                                               [47]   \n",
       "113                                              [179]   \n",
       "114                                               [52]   \n",
       "115                                              [181]   \n",
       "116                                               [59]   \n",
       "117                                               [66]   \n",
       "118                                              [198]   \n",
       "119                                               [71]   \n",
       "120                                               [72]   \n",
       "121                                              [199]   \n",
       "122                                               [77]   \n",
       "123                                               [78]   \n",
       "124                                               [79]   \n",
       "125                                              [208]   \n",
       "126                                              [209]   \n",
       "127                                              [207]   \n",
       "128                                              [205]   \n",
       "129                                              [212]   \n",
       "130                                              [211]   \n",
       "131                                              [112]   \n",
       "132                                              [114]   \n",
       "133                                              [115]   \n",
       "134                                              [119]   \n",
       "135                                              [123]   \n",
       "136                                              [125]   \n",
       "137                                              [127]   \n",
       "138           [46, 47, 52, 59, 66, 71, 72, 77, 78, 79]   \n",
       "139  [134, 136, 139, 112, 114, 115, 119, 123, 125, ...   \n",
       "140  [179, 181, 198, 199, 208, 209, 207, 205, 212, ...   \n",
       "\n",
       "                                               topics  len(topics)  \\\n",
       "108                                              [18]            1   \n",
       "109                                              [23]            1   \n",
       "110                                              [21]            1   \n",
       "111                                               [1]            1   \n",
       "112                                              [17]            1   \n",
       "113                                              [79]            1   \n",
       "114                                               [0]            1   \n",
       "115                                              [73]            1   \n",
       "116                                              [11]            1   \n",
       "117                                               [9]            1   \n",
       "118                                              [72]            1   \n",
       "119                                               [7]            1   \n",
       "120                                               [2]            1   \n",
       "121                                              [67]            1   \n",
       "122                                               [5]            1   \n",
       "123                                               [4]            1   \n",
       "124                                               [3]            1   \n",
       "125                  [37, 75, 78, 49, 67, 79, 59, 74]            8   \n",
       "126                                              [75]            1   \n",
       "127                                              [78]            1   \n",
       "128                                              [59]            1   \n",
       "129                                          [37, 79]            2   \n",
       "130                                          [37, 69]            2   \n",
       "131                                              [26]            1   \n",
       "132                                          [20, 49]            2   \n",
       "133                                               [6]            1   \n",
       "134                                              [55]            1   \n",
       "135                                              [44]            1   \n",
       "136                                          [49, 76]            2   \n",
       "137                                              [62]            1   \n",
       "138  [9, 11, 5, 4, 2, 17, 7, 3, 1, 0, 66, 69, 63, 38]           14   \n",
       "139                                              [76]            1   \n",
       "140                  [78, 75, 72, 67, 79, 73, 76, 59]            8   \n",
       "\n",
       "     topic_hitrate  num_non-zeros_in_vector  \n",
       "108            1.0                       26  \n",
       "109            1.0                       18  \n",
       "110            1.0                       10  \n",
       "111            1.0                       10  \n",
       "112            1.0                       14  \n",
       "113            1.0                        5  \n",
       "114            1.0                        7  \n",
       "115            1.0                       10  \n",
       "116            1.0                        3  \n",
       "117            1.0                       10  \n",
       "118            1.0                        5  \n",
       "119            1.0                       12  \n",
       "120            1.0                       15  \n",
       "121            1.0                        3  \n",
       "122            1.0                       11  \n",
       "123            1.0                       13  \n",
       "124            1.0                        5  \n",
       "125            1.0                       13  \n",
       "126            1.0                        1  \n",
       "127            1.0                        5  \n",
       "128            1.0                        4  \n",
       "129            1.0                       42  \n",
       "130            1.0                       10  \n",
       "131            1.0                       54  \n",
       "132            1.0                        5  \n",
       "133            1.0                        6  \n",
       "134            1.0                        4  \n",
       "135            1.0                        7  \n",
       "136            0.0                        9  \n",
       "137            1.0                       47  \n",
       "138            1.0                       25  \n",
       "139            0.0                        9  \n",
       "140            0.9                       51  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### evaluate method\n",
    "transformed_data = nmf_data_normalised\n",
    "\n",
    "docs = pd.DataFrame(\n",
    "    {\n",
    "        \"doc_id\": docs_df[\"doc_id\"].to_list(),\n",
    "        \"original_doc_id_tmp\": docs_df[\"original_doc_id\"].to_list(),\n",
    "        \"original_doc_ids_tmp\": docs_df[\"original_doc_ids\"].to_list(),\n",
    "        \"doc_vector\": list([doc for doc in transformed_data]),\n",
    "    }\n",
    ")\n",
    "\n",
    "docs[\"original_doc_ids\"] = docs.apply(merge_original_ids, axis=1)\n",
    "docs = docs.drop([\"original_doc_id_tmp\", \"original_doc_ids_tmp\"], axis=1)\n",
    "\n",
    "\n",
    "docs[\"topics\"] = docs[\"doc_vector\"].apply(calc_topics_for_cumulative_threshold, args=(0.95,))\n",
    "docs[\"len(topics)\"] = docs[\"topics\"].apply(len)\n",
    "docs[\"topic_hitrate\"] = docs.apply(calc_topic_hitrate, axis=1)\n",
    "docs[\"num_non-zeros_in_vector\"] = docs[\"doc_vector\"].apply(lambda v: sum(i > 0 for i in v))\n",
    "\n",
    "print(f\"Avg. number of topics: {round(docs[\"len(topics)\"].mean(), 2)}\")\n",
    "docs[\"doc_vector\"] = docs[\"doc_vector\"].apply(lambda v: np.sort(v)[::-1]).apply(lambda v: [round(i, 4) for i in v])\n",
    "\n",
    "docs.loc[docs[\"original_doc_ids\"].notna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
