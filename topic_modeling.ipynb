{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1256c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### static variables\n",
    "\n",
    "COLUMNS_DOCS = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_name\",\n",
    "    \"court_name\",\n",
    "    \"hospital_patient_name\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TEXTUAL = [\n",
    "    *COLUMNS_DOCS,\n",
    "    \"original_doc_id\",\n",
    "]\n",
    "\n",
    "COLUMNS_DOCS_MANIPULATED_TABULAR = [\n",
    "    \"doc_id\",\n",
    "    \"language\",\n",
    "    \"domain\",\n",
    "    \"content\",\n",
    "    \"company_names\",\n",
    "    \"court_names\",\n",
    "    \"hospital_patient_names\",\n",
    "    \"original_doc_ids\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd890fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_documents() -> pd.DataFrame:\n",
    "    docs_original = pd.read_csv(\"data/DRAGONball/en/docs.csv\", usecols=[\"doc_id\", \"domain\", \"content\"])\n",
    "    docs_manipulated_single_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/textual_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    docs_manipulated_single_tabular = pd.read_csv(\n",
    "        \"data/additional_data/docs/tabular_manipulations_result.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_ids\"],\n",
    "        converters={\"original_doc_ids\": ast.literal_eval},\n",
    "    )\n",
    "    docs_manipulated_multi_textual = pd.read_csv(\n",
    "        \"data/additional_data/docs/multi_textual_manipulations.csv\",\n",
    "        usecols=[\"doc_id\", \"domain\", \"content\", \"original_doc_id\"],\n",
    "        dtype={\"original_doc_id\": \"Int64\"},\n",
    "    )\n",
    "    print(f\"# original docs: {len(docs_original)}\")\n",
    "    print(f\"# manipulated textual docs: {len(docs_manipulated_single_textual)}\")\n",
    "    print(f\"# manipulated tabular docs: {len(docs_manipulated_single_tabular)}\")\n",
    "    print(f\"# manipulated textual multi docs: {len(docs_manipulated_multi_textual)}\")\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            docs_original,\n",
    "            docs_manipulated_single_textual,\n",
    "            docs_manipulated_single_tabular,\n",
    "            docs_manipulated_multi_textual,\n",
    "        ],\n",
    "        sort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa26b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original docs: 108\n",
      "# manipulated textual docs: 30\n",
      "# manipulated tabular docs: 3\n",
      "# manipulated textual multi docs: 30\n",
      "Size of vocabulary: 7581\n"
     ]
    }
   ],
   "source": [
    "docs_df = get_documents()\n",
    "docs_list = docs_df[\"content\"].to_list()\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, stop_words=\"english\")\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(docs_list)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"Size of vocabulary: {len(tfidf_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd35bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NMF\n",
    "nmf = NMF(n_components=108, init=\"nndsvda\", max_iter=400)\n",
    "nmf = nmf.fit(tfidf_features[:108])\n",
    "nmf_data = nmf.transform(tfidf_features)\n",
    "# nmf_data = nmf.fit_transform(tfidf_features)\n",
    "nmf_data_normalised = normalize(nmf_data, norm=\"l1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c35c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSA\n",
    "lsa = TruncatedSVD(n_components=108)\n",
    "lsa_data = lsa.fit_transform(tfidf_features)\n",
    "lsa_data_normalised = normalize(lsa_data, norm=\"l2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6592352",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA\n",
    "lda = LatentDirichletAllocation(n_components=108)\n",
    "lda_data_normalised = lda.fit_transform(tfidf_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2553110",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (1/2)\n",
    "def merge_original_ids(row):\n",
    "    if isinstance(row[\"original_doc_ids_tmp\"], list):\n",
    "        return row[\"original_doc_ids_tmp\"]\n",
    "    elif pd.notna(row[\"original_doc_id_tmp\"]):\n",
    "        return [row[\"original_doc_id_tmp\"]]\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "def calc_topics(row):\n",
    "    if isinstance(row[\"original_doc_ids\"], list):\n",
    "        if len(row[\"original_doc_ids\"]) > 1:\n",
    "            return np.argsort(row[\"doc_vector\"])[-10:][::-1].tolist()\n",
    "    return [np.argmax(row[\"doc_vector\"])]\n",
    "\n",
    "\n",
    "def calc_topics_for_cumulative_threshold(row, threshold=0.9):\n",
    "    sorted_indices = np.argsort(row)[::-1]\n",
    "\n",
    "    # Sort the probabilities accordingly\n",
    "    sorted_probs = row[sorted_indices]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative = np.cumsum(sorted_probs)\n",
    "\n",
    "    # Find the cutoff index where cumulative sum first exceeds threshold\n",
    "    cutoff = np.searchsorted(cumulative, threshold)\n",
    "\n",
    "    # Select the indices up to and including that point\n",
    "    selected_indices = sorted_indices[: cutoff + 1]\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "280b51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions (2/2)\n",
    "def calc_topic_hitrate(row):\n",
    "    if not isinstance(row[\"original_doc_ids\"], list):\n",
    "        return None\n",
    "\n",
    "    original_doc_ids: List[int] = row[\"original_doc_ids\"]\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for id in original_doc_ids:\n",
    "        topics_row = set(row[\"topics\"])\n",
    "        original_row = docs.loc[docs[\"doc_id\"].astype(int) == int(id)].iloc[0]\n",
    "        topics_original = set(original_row[\"topics\"])\n",
    "        res.append(len(topics_row.intersection(topics_original)) > 0)\n",
    "\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b4cd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. number of topics: 3.01\n",
      "Recall: 0.97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_vector</th>\n",
       "      <th>original_doc_ids</th>\n",
       "      <th>topics</th>\n",
       "      <th>len(topics)</th>\n",
       "      <th>topic_hitrate</th>\n",
       "      <th>num_non-zeros_in_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>100134</td>\n",
       "      <td>[0.9294, 0.0359, 0.0137, 0.0062, 0.0035, 0.002...</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[37, 98]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100136</td>\n",
       "      <td>[0.9968, 0.0016, 0.0007, 0.0003, 0.0003, 0.000...</td>\n",
       "      <td>[136]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>100139</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[139]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100046</td>\n",
       "      <td>[0.9989, 0.0003, 0.0003, 0.0002, 0.0001, 0.000...</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>100047</td>\n",
       "      <td>[0.8849, 0.0932, 0.0082, 0.0035, 0.0034, 0.002...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[17, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>400207</td>\n",
       "      <td>[0.4945, 0.2989, 0.0514, 0.0268, 0.0251, 0.023...</td>\n",
       "      <td>[207]</td>\n",
       "      <td>[9, 103, 101, 85, 64, 23, 60, 40]</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>400213</td>\n",
       "      <td>[0.5692, 0.0653, 0.0509, 0.0461, 0.0431, 0.040...</td>\n",
       "      <td>[213]</td>\n",
       "      <td>[72, 98, 73, 13, 11, 40, 101, 60, 23, 2, 17, 69]</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>400214</td>\n",
       "      <td>[0.5735, 0.1258, 0.0654, 0.0547, 0.0431, 0.036...</td>\n",
       "      <td>[214]</td>\n",
       "      <td>[27, 89, 60, 100, 23, 87, 101, 13, 51]</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>400110</td>\n",
       "      <td>[0.7654, 0.0411, 0.0283, 0.0271, 0.0244, 0.023...</td>\n",
       "      <td>[110]</td>\n",
       "      <td>[76, 71, 100, 95, 26, 23, 59, 25, 3]</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>400116</td>\n",
       "      <td>[0.8383, 0.0748, 0.0428, 0.0265, 0.0128, 0.001...</td>\n",
       "      <td>[116]</td>\n",
       "      <td>[73, 88, 65]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                         doc_vector  \\\n",
       "108  100134  [0.9294, 0.0359, 0.0137, 0.0062, 0.0035, 0.002...   \n",
       "109  100136  [0.9968, 0.0016, 0.0007, 0.0003, 0.0003, 0.000...   \n",
       "110  100139  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "111  100046  [0.9989, 0.0003, 0.0003, 0.0002, 0.0001, 0.000...   \n",
       "112  100047  [0.8849, 0.0932, 0.0082, 0.0035, 0.0034, 0.002...   \n",
       "..      ...                                                ...   \n",
       "166  400207  [0.4945, 0.2989, 0.0514, 0.0268, 0.0251, 0.023...   \n",
       "167  400213  [0.5692, 0.0653, 0.0509, 0.0461, 0.0431, 0.040...   \n",
       "168  400214  [0.5735, 0.1258, 0.0654, 0.0547, 0.0431, 0.036...   \n",
       "169  400110  [0.7654, 0.0411, 0.0283, 0.0271, 0.0244, 0.023...   \n",
       "170  400116  [0.8383, 0.0748, 0.0428, 0.0265, 0.0128, 0.001...   \n",
       "\n",
       "    original_doc_ids                                            topics  \\\n",
       "108            [134]                                          [37, 98]   \n",
       "109            [136]                                              [35]   \n",
       "110            [139]                                              [62]   \n",
       "111             [46]                                              [29]   \n",
       "112             [47]                                           [17, 1]   \n",
       "..               ...                                               ...   \n",
       "166            [207]                 [9, 103, 101, 85, 64, 23, 60, 40]   \n",
       "167            [213]  [72, 98, 73, 13, 11, 40, 101, 60, 23, 2, 17, 69]   \n",
       "168            [214]            [27, 89, 60, 100, 23, 87, 101, 13, 51]   \n",
       "169            [110]              [76, 71, 100, 95, 26, 23, 59, 25, 3]   \n",
       "170            [116]                                      [73, 88, 65]   \n",
       "\n",
       "     len(topics)  topic_hitrate  num_non-zeros_in_vector  \n",
       "108            2            1.0                       14  \n",
       "109            1            1.0                       16  \n",
       "110            1            1.0                       10  \n",
       "111            1            1.0                        9  \n",
       "112            2            1.0                       16  \n",
       "..           ...            ...                      ...  \n",
       "166            8            1.0                       19  \n",
       "167           12            1.0                       19  \n",
       "168            9            1.0                       22  \n",
       "169            9            1.0                       22  \n",
       "170            3            1.0                        8  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### evaluate method\n",
    "transformed_data = nmf_data_normalised\n",
    "\n",
    "docs = pd.DataFrame(\n",
    "    {\n",
    "        \"doc_id\": docs_df[\"doc_id\"].to_list(),\n",
    "        \"original_doc_id_tmp\": docs_df[\"original_doc_id\"].to_list(),\n",
    "        \"original_doc_ids_tmp\": docs_df[\"original_doc_ids\"].to_list(),\n",
    "        \"doc_vector\": list([doc for doc in transformed_data]),\n",
    "    }\n",
    ")\n",
    "\n",
    "docs[\"original_doc_ids\"] = docs.apply(merge_original_ids, axis=1)\n",
    "docs = docs.drop([\"original_doc_id_tmp\", \"original_doc_ids_tmp\"], axis=1)\n",
    "\n",
    "\n",
    "docs[\"topics\"] = docs[\"doc_vector\"].apply(calc_topics_for_cumulative_threshold, args=(0.95,))\n",
    "docs[\"len(topics)\"] = docs[\"topics\"].apply(len)\n",
    "docs[\"topic_hitrate\"] = docs.apply(calc_topic_hitrate, axis=1)\n",
    "docs[\"num_non-zeros_in_vector\"] = docs[\"doc_vector\"].apply(lambda v: sum(i > 0 for i in v))\n",
    "\n",
    "print(f\"Avg. number of topics: {round(docs[\"len(topics)\"].mean(), 2)}\")\n",
    "docs[\"doc_vector\"] = docs[\"doc_vector\"].apply(lambda v: np.sort(v)[::-1]).apply(lambda v: [round(i, 4) for i in v])\n",
    "\n",
    "filtered_docs = docs.loc[docs[\"original_doc_ids\"].notna()]\n",
    "print(f\"Recall: {round(filtered_docs[\"topic_hitrate\"].mean(), 2)}\")\n",
    "\n",
    "filtered_docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
